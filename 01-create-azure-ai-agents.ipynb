{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to c:\\Users\\pablosal\\Desktop\\azure-ai-agent-services-demo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = os.getcwd()  # change your directory here\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Azure AI Agent with SharePoint Integration \n",
    "\n",
    "SharePoint as a data source allows you to ground your Azure AI Agents with documents stored in SharePoint securely. You can connect to your SharePoint site, such as `contoso.sharepoint.com/sites/policies`. When a user sends a query, Azure AI Agents will determine if SharePoint should be leveraged or not. If so, it will send the query via the SharePoint tool, which checks if the user has an M365 Copilot license and uses the end user’s identity to retrieve relevant documents they have access to. The scope of retrieval includes all supported documents in this SharePoint site. Lastly, Azure AI Agents will generate responses based on the retrieved information.\n",
    "\n",
    "With SharePoint integration, we will support **OBO (On-Behalf-Of) authentication**, which allows the SharePoint tool to retrieve relevant documents based on the end user’s identity and access.\n",
    "\n",
    "**Prerequisites**\n",
    "- Existing SharePoint site, and ensure developers have access to this SharePoint site.\n",
    "- Developers and end users must have an M365 Copilot license.\n",
    "- Ensure your AOAI resource and AI project are in one of the following regions: `westus`, `japaneast`, `francecentral`.\n",
    "\n",
    "+ **RBAC Roles**\n",
    "    - To CRUD a SharePoint tool in Azure AI Agent, ensure you have the **AI Developer** role.\n",
    "    - Ensure end users have the **AI Developer** role to enable OBO authentication.\n",
    "\n",
    "> Please visit [how-to\\setup-sharepoint-azure-ai-agentmd](how-to/setup-sharepoint-azure-ai-agentmd).\n",
    "\n",
    "**Supported Capabilities**\n",
    "- Grounding with all supported documents in a SharePoint site.\n",
    "- Supported document types: PDF, Word, PPT, TXT, .aspx (text data only).\n",
    "- Automatic indexing of updated documents.\n",
    "- Responses based on the end user’s document access.\n",
    "- Connection to a maximum of 1 SharePoint site.\n",
    "\n",
    "**Known Limitations**\n",
    "- Retrieval and grounding quality issues, especially with complex formatting, tables, columns, and images.\n",
    "- Text-sparse file types (e.g., PPT) may return poorer results than text-rich types (e.g., DOCX).\n",
    "- Grounding with specific libraries or multiple sites is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import SharepointTool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import MessageTextContent\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from utils.ml_logging import get_logger\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# The connection string format should be: <HostName>;<AzureSubscriptionId>;<ResourceGroup>;<HubName>\n",
    "conn_str = os.environ[\"AZURE_AI_AGENT_PROJECT_CONNECTION_STRING\"]\n",
    "\n",
    "# Create the AIProjectClient using the connection string and explicit credential\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=conn_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 11:24:49,971 - micro - MainProcess - INFO     SharePoint Connection ID: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-zhuoqunliai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-1959/connections/ContosoAgentDemoSharepoint (614259051.py:<module>:24)\n",
      "2025-03-19 11:24:53,850 - micro - MainProcess - INFO     Created Agent ID: asst_jtJEpWJTbepxD3XLGrFK6zVF (614259051.py:<module>:66)\n",
      "2025-03-19 11:24:53,852 - micro - MainProcess - INFO     Agent Metadata: {'use_case': 'Enterprise SharePoint Search', 'data_source': 'SharePoint', 'response_validation': 'Must include source link'} (614259051.py:<module>:67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Agent Creation Summary ===\n",
      "Agent Name    : my-sharepoint-assistant\n",
      "Agent ID      : asst_jtJEpWJTbepxD3XLGrFK6zVF\n",
      "Agent Metadata:\n",
      "  - use_case: Enterprise SharePoint Search\n",
      "  - data_source: SharePoint\n",
      "  - response_validation: Must include source link\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from utils.utilityfucntions import print_agent_summary\n",
    "\n",
    "# 1. Set up the model name from environment variable\n",
    "deployment_name = os.environ.get(\"AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME\")\n",
    "if not deployment_name:\n",
    "    logger.error(\"Environment variable 'AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME' is not set.\")\n",
    "    exit(1)\n",
    "\n",
    "# 2. Initialize the AI Project Client (assumed to be done in a previous cell)\n",
    "# 2a. Initialize the SharePoint tool using the connection ID.\n",
    "# For connection setup details, please refer to `how-to/setup-tools-in-ai-foundry.md`\n",
    "try:\n",
    "    sharepoint_connection = project_client.connections.get(\n",
    "        connection_name=os.environ[\"TOOL_CONNECTION_NAME_SHAREPOINT\"]\n",
    "    )\n",
    "except KeyError:\n",
    "    logger.error(\"Environment variable 'TOOL_CONNECTION_NAME_SHAREPOINT' is not set.\")\n",
    "    exit(1)\n",
    "\n",
    "conn_id = sharepoint_connection.id\n",
    "logger.info(f\"SharePoint Connection ID: {conn_id}\")\n",
    "\n",
    "# Create a SharePointTool instance with the connection ID\n",
    "sharepoint = SharepointTool(connection_id=conn_id)\n",
    "\n",
    "# 3. Create a SharePoint-powered AI Agent\n",
    "try:\n",
    "    sharepoint_agent = project_client.agents.create_agent(\n",
    "        model=deployment_name,\n",
    "        name=\"my-sharepoint-assistant\",\n",
    "        description=(\n",
    "            \"A SharePoint-integrated AI assistant designed to search, retrieve, \"\n",
    "            \"and summarize documents stored in SharePoint. This assistant helps users \"\n",
    "            \"quickly find relevant information while ensuring responses include \"\n",
    "            \"document references for validation.\"\n",
    "        ),\n",
    "        instructions=(\n",
    "            \"You are an AI-powered assistant specialized in searching and retrieving \"\n",
    "            \"documents from SharePoint. Your primary role is to find the most relevant \"\n",
    "            \"documents based on user queries and provide clear, concise summaries.\\n\\n\"\n",
    "            \"**Response Guidelines:**\\n\"\n",
    "            \"1. Always retrieve the most relevant document(s) from SharePoint.\\n\"\n",
    "            \"2. Provide a summary of the key information from the retrieved document(s).\\n\"\n",
    "            \"3. Every response **must include the link** to the original document for reference.\\n\"\n",
    "            \"4. If no relevant document is found, respond with: 'No matching documents found in SharePoint.'\\n\"\n",
    "            \"5. Use professional, structured language, and avoid speculation.\\n\\n\"\n",
    "            \"**Example Responses:**\\n\"\n",
    "            \"✅ 'The requested policy document is available here: [Document Link]. Based on its content, \"\n",
    "            \"the key points are...'\\n\"\n",
    "            \"❌ 'I think this might be what you're looking for...' (Avoid speculation.)\"\n",
    "        ),\n",
    "        tools=sharepoint.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"},\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        metadata={\n",
    "            \"use_case\": \"Enterprise SharePoint Search\",\n",
    "            \"data_source\": \"SharePoint\",\n",
    "            \"response_validation\": \"Must include source link\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Created Agent ID: {sharepoint_agent.id}\")\n",
    "    logger.info(f\"Agent Metadata: {sharepoint_agent.metadata}\")\n",
    "\n",
    "except HttpResponseError as e:\n",
    "    try:\n",
    "        error_json = json.loads(e.response.content)\n",
    "        logger.error(f\"Error Message: {error_json.get('Message')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"Non-JSON Error Content: {e.response.content}\")\n",
    "    exit(1)\n",
    "\n",
    "print_agent_summary(sharepoint_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 11:28:55,554 - micro - MainProcess - INFO     Created Thread ID: thread_Tx06SIbCcvjHTGnk9L3DtMdV (1549044826.py:<module>:4)\n",
      "2025-03-19 11:28:56,001 - micro - MainProcess - INFO     Created User Message ID: msg_H7bI9S1tN7taCxVYCsgVoN4b (1549044826.py:<module>:12)\n",
      "2025-03-19 11:28:58,794 - micro - MainProcess - INFO     Run created. Polling for status... (1549044826.py:<module>:18)\n",
      "2025-03-19 11:28:59,858 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:28:59,860 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:00,741 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:00,742 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:01,689 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:01,691 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:02,831 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:02,833 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:03,695 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:03,696 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:04,567 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:04,569 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:05,442 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:05,444 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:06,307 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:06,308 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:07,158 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:07,159 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:08,091 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:08,091 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:08,961 - micro - MainProcess - INFO     Current run ID: run_siUPGO6DyMI28DfUV9f4563M (1549044826.py:<module>:24)\n",
      "2025-03-19 11:29:08,963 - micro - MainProcess - INFO     Current run status: RunStatus.COMPLETED (1549044826.py:<module>:25)\n",
      "2025-03-19 11:29:08,965 - micro - MainProcess - INFO     Run finished with status: RunStatus.COMPLETED (1549044826.py:<module>:27)\n",
      "2025-03-19 11:29:09,307 - micro - MainProcess - INFO     ----- Conversation History ----- (1549044826.py:<module>:31)\n",
      "2025-03-19 11:29:09,308 - micro - MainProcess - INFO     ASSISTANT: The key features of the Dexcom G7 CGM (Continuous Glucose Monitoring) System, which was cleared by the FDA in December 2022, are:\n",
      "\n",
      "- **Integrated Design**: The Dexcom G7 system combines the transmitter and CGM sensor into a single device, which simplifies its usage.\n",
      "- **One-Click Applicator**: This system comes with a simplified one-click applicator for ease of application.\n",
      "- **Size**: The G7 sensor is significantly smaller than the previous G6 sensor, making it more comfortable and less obtrusive for users.\n",
      "- **Warm-Up Time**: The warm-up time for the G7 sensor is reduced to 30 minutes, compared to the 2-hour warm-up time required for the G6 model.\n",
      "- **Age Compatibility**: It is approved for individuals aged 2 years and older. For users aged 7 and above, the device can be worn on the back of the upper arm, while for users aged 2 to 6 years, it can be used on the back of the upper arm or on the upper buttocks.\n",
      "\n",
      "The document also discusses the importance of the CGM's accuracy, minimal calibration requirements, and ability to share real-time data with other diabetes management devices.\n",
      "\n",
      "For further details, you can access the document here: [Dexcom G7 CGM System Details](#). (1549044826.py:<module>:34)\n",
      "2025-03-19 11:29:09,311 - micro - MainProcess - INFO     USER: What are the key features from Dexcom G7 CGM System? (1549044826.py:<module>:34)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1. Create a thread for the conversation\n",
    "    thread = project_client.agents.create_thread()\n",
    "    logger.info(f\"Created Thread ID: {thread.id}\")\n",
    "\n",
    "    # 2. Create a user message on that thread\n",
    "    user_message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"What are the key features from Dexcom G7 CGM System?\"\n",
    "    )\n",
    "    logger.info(f\"Created User Message ID: {user_message.id}\")\n",
    "\n",
    "    # 3. Create a run to process the conversation\n",
    "    run = project_client.agents.create_run(\n",
    "        thread_id=thread.id, agent_id=sharepoint_agent.id\n",
    "    )\n",
    "    logger.info(\"Run created. Polling for status...\")\n",
    "\n",
    "    # 4. Poll until run completes or fails\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        time.sleep(0.5)\n",
    "        run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "        logger.info(f\"Current run ID: {run.id}\")\n",
    "        logger.info(f\"Current run status: {run.status}\")\n",
    "\n",
    "    logger.info(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    # 5. Retrieve and display the conversation history (oldest to newest)\n",
    "    conversation_history = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    logger.info(\"----- Conversation History -----\")\n",
    "    for msg in conversation_history.data:\n",
    "        if msg.content and isinstance(msg.content[-1], MessageTextContent):\n",
    "            logger.info(f\"{msg.role.upper()}: {msg.content[-1].text.value}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during agent processing: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Azure AI Agent with Fabric Integration \n",
    "\n",
    "SharePoint as a data source allows you to ground your Azure AI Agents with documents stored in SharePoint securely. You can connect to your SharePoint site, such as `contoso.sharepoint.com/sites/policies`. When a user sends a query, Azure AI Agents will determine if SharePoint should be leveraged or not. If so, it will send the query via the SharePoint tool, which checks if the user has an M365 Copilot license and uses the end user’s identity to retrieve relevant documents they have access to. The scope of retrieval includes all supported documents in this SharePoint site. Lastly, Azure AI Agents will generate responses based on the retrieved information.\n",
    "\n",
    "With SharePoint integration, we will support **OBO (On-Behalf-Of) authentication**, which allows the SharePoint tool to retrieve relevant documents based on the end user’s identity and access.\n",
    "\n",
    "**Prerequisites**\n",
    "- Existing SharePoint site, and ensure developers have access to this SharePoint site.\n",
    "- Developers and end users must have an M365 Copilot license.\n",
    "- Ensure your AOAI resource and AI project are in one of the following regions: `westus`, `japaneast`, `francecentral`.\n",
    "\n",
    "+ **RBAC Roles**\n",
    "    - To CRUD a SharePoint tool in Azure AI Agent, ensure you have the **AI Developer** role.\n",
    "    - Ensure end users have the **AI Developer** role to enable OBO authentication.\n",
    "\n",
    "> Please visit [how-to\\setup-sharepoint-azure-ai-agentmd](how-to/setup-sharepoint-azure-ai-agentmd).\n",
    "\n",
    "**Supported Capabilities**\n",
    "- Grounding with all supported documents in a SharePoint site.\n",
    "- Supported document types: PDF, Word, PPT, TXT, .aspx (text data only).\n",
    "- Automatic indexing of updated documents.\n",
    "- Responses based on the end user’s document access.\n",
    "- Connection to a maximum of 1 SharePoint site.\n",
    "\n",
    "**Known Limitations**\n",
    "- Retrieval and grounding quality issues, especially with complex formatting, tables, columns, and images.\n",
    "- Text-sparse file types (e.g., PPT) may return poorer results than text-rich types (e.g., DOCX).\n",
    "- Grounding with specific libraries or multiple sites is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 11:35:35,525 - micro - MainProcess - INFO     Created Agent ID: asst_fewEhoM0W9x3yKocx09JincX (3394478606.py:<module>:46)\n",
      "2025-03-19 11:35:35,527 - micro - MainProcess - INFO     Agent Metadata: {'use_case': 'Microsoft Fabric Data Analysis', 'data_source': 'Fabric', 'response_validation': 'Must include source link'} (3394478606.py:<module>:47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Agent Creation Summary ===\n",
      "Agent Name    : fabric-intelligence-agent\n",
      "Agent ID      : asst_fewEhoM0W9x3yKocx09JincX\n",
      "Agent Metadata:\n",
      "  - use_case: Microsoft Fabric Data Analysis\n",
      "  - data_source: Fabric\n",
      "  - response_validation: Must include source link\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import FabricTool\n",
    "\n",
    "conn_id = project_client.connections.get(\n",
    "    connection_name=os.environ[\"TOOL_CONNECTION_NAME_FABRIC\"],\n",
    ")\n",
    "\n",
    "# 4. Initialize Fabric Tool\n",
    "fabric_tool = FabricTool(connection_id=conn_id.id)\n",
    "\n",
    "# 5. Create the Fabric AI Agent\n",
    "try:\n",
    "    fabric_agent = project_client.agents.create_agent(\n",
    "        model=deployment_name,\n",
    "        name=\"fabric-intelligence-agent\",\n",
    "        description=(\n",
    "            \"An AI-powered assistant designed to interact with Microsoft Fabric, \"\n",
    "            \"fetch relevant data, analyze insights, and ensure structured responses \"\n",
    "            \"with validated references. The agent helps users extract valuable \"\n",
    "            \"business intelligence from Fabric data sources.\"\n",
    "        ),\n",
    "        instructions=(\n",
    "            \"You are an AI assistant specialized in retrieving and analyzing data \"\n",
    "            \"from Microsoft Fabric. Your primary goal is to help users extract insights \"\n",
    "            \"by querying structured and unstructured data sources within Fabric. \\n\\n\"\n",
    "            \"**Response Guidelines:**\\n\"\n",
    "            \"1. Always retrieve the most relevant dataset(s) from Fabric.\\n\"\n",
    "            \"2. Provide a structured summary of key findings, ensuring accuracy.\\n\"\n",
    "            \"3. Every response **must include a link** to the original data source for verification.\\n\"\n",
    "            \"4. If no relevant data is found, respond with: 'No relevant data found in Fabric.'\\n\"\n",
    "            \"5. Use precise, professional, and structured language; avoid speculation.\\n\\n\"\n",
    "            \"**Example Responses:**\\n\"\n",
    "            \"✅ *'The requested sales performance data is available here: [Dataset Link]. Key insights: ...'* \\n\"\n",
    "            \"❌ *'I think this might be useful...'* (Avoid vague responses.)\"\n",
    "        ),\n",
    "        tools=fabric_tool.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"},\n",
    "        temperature=0.7,\n",
    "        top_p=1,\n",
    "        metadata={\n",
    "            \"use_case\": \"Microsoft Fabric Data Analysis\",\n",
    "            \"data_source\": \"Fabric\",\n",
    "            \"response_validation\": \"Must include source link\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Created Agent ID: {fabric_agent.id}\")\n",
    "    logger.info(f\"Agent Metadata: {fabric_agent.metadata}\")\n",
    "\n",
    "except HttpResponseError as e:\n",
    "    try:\n",
    "        error_json = json.loads(e.response.content)\n",
    "        logger.error(f\"Error Message: {error_json.get('Message')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"Non-JSON Error Content: {e.response.content}\")\n",
    "    exit(1)\n",
    "\n",
    "print_agent_summary(fabric_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 11:34:29,805 - micro - MainProcess - INFO     Created Thread ID: thread_IIIZNRIyCyaDL0SvxbJQDj4G (621789375.py:<module>:4)\n",
      "2025-03-19 11:34:30,183 - micro - MainProcess - INFO     Created User Message ID: msg_02LAgHGC5CQRrbOtIoT49jpG (621789375.py:<module>:12)\n",
      "2025-03-19 11:34:32,838 - micro - MainProcess - INFO     Run created. Polling for status... (621789375.py:<module>:18)\n",
      "2025-03-19 11:34:33,841 - micro - MainProcess - INFO     Current run ID: run_rjjCBvDQhGP5BKto4yjSaY8S (621789375.py:<module>:24)\n",
      "2025-03-19 11:34:33,843 - micro - MainProcess - INFO     Current run status: RunStatus.FAILED (621789375.py:<module>:25)\n",
      "2025-03-19 11:34:33,845 - micro - MainProcess - INFO     Run finished with status: RunStatus.FAILED (621789375.py:<module>:27)\n",
      "2025-03-19 11:34:34,254 - micro - MainProcess - INFO     ----- Conversation History ----- (621789375.py:<module>:31)\n",
      "2025-03-19 11:34:34,258 - micro - MainProcess - INFO     USER: How does Product A compare to Product B in terms of MARD percentage across different glucose ranges? Use the tools to analyze the data and provide a summary. (621789375.py:<module>:34)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1. Create a thread for the conversation\n",
    "    thread = project_client.agents.create_thread()\n",
    "    logger.info(f\"Created Thread ID: {thread.id}\")\n",
    "\n",
    "    # 2. Create a user message on that thread\n",
    "    user_message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"How does Product A compare to Product B in terms of MARD percentage across different glucose ranges? Use the tools to analyze the data and provide a summary.\",\n",
    "    )\n",
    "    logger.info(f\"Created User Message ID: {user_message.id}\")\n",
    "\n",
    "    # 3. Create a run to process the conversation\n",
    "    run = project_client.agents.create_run(\n",
    "        thread_id=thread.id, agent_id=fabric_agent.id\n",
    "    )\n",
    "    logger.info(\"Run created. Polling for status...\")\n",
    "\n",
    "    # 4. Poll until run completes or fails\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        time.sleep(0.5)\n",
    "        run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "        logger.info(f\"Current run ID: {run.id}\")\n",
    "        logger.info(f\"Current run status: {run.status}\")\n",
    "\n",
    "    logger.info(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    # 5. Retrieve and display the conversation history (oldest to newest)\n",
    "    conversation_history = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    logger.info(\"----- Conversation History -----\")\n",
    "    for msg in conversation_history.data:\n",
    "        if msg.content and isinstance(msg.content[-1], MessageTextContent):\n",
    "            logger.info(f\"{msg.role.upper()}: {msg.content[-1].text.value}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during agent processing: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ai-agent-service-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
