{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime as pydatetime\n",
    "from typing import Any, List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Azure AI Projects\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import MessageTextContent\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.ai.projects.models import (\n",
    "    BingGroundingTool,\n",
    "    AzureAISearchTool,\n",
    "    SharepointTool,\n",
    "    FabricTool,\n",
    "    ToolSet,\n",
    ")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# configure logging\n",
    "from utils.ml_logging import get_logger\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "# helper functions\n",
    "from utils.utilityfucntions import print_agent_summary\n",
    "\n",
    "# set the directory to the location of the script\n",
    "try:\n",
    "    target_directory = os.getenv(\"TARGET_DIRECTORY\", os.getcwd())  # Use environment variable if available\n",
    "    if os.path.exists(target_directory):\n",
    "        os.chdir(target_directory)\n",
    "        logging.info(f\"Successfully changed directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        logging.error(f\"Directory does not exist: {target_directory}\")\n",
    "except Exception as e:\n",
    "    logging.exception(f\"An error occurred while changing directory: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Client and Load Azure AI Foundry**\n",
    "\n",
    "Here, we initialize the Azure AI client using DefaultAzureCredential. This allows us to authenticate and connect to the Azure AI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The connection string format should be: <HostName>;<AzureSubscriptionId>;<ResourceGroup>;<HubName>\n",
    "conn_str = os.environ[\"AZURE_AI_AGENT_PROJECT_CONNECTION_STRING\"]\n",
    "\n",
    "# Create the AIProjectClient using the connection string and explicit credential\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=conn_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Creating an Azure AI Agent with SharePoint Integration (Tool)**\n",
    "\n",
    "SharePoint as a data source allows you to ground your Azure AI Agents with documents stored in SharePoint securely. You can connect to your SharePoint site, such as `contoso.sharepoint.com/sites/policies`. When a user sends a query, Azure AI Agents will determine if SharePoint should be leveraged or not. If so, it will send the query via the SharePoint tool, which checks if the user has an M365 Copilot license and uses the end user’s identity to retrieve relevant documents they have access to. The scope of retrieval includes all supported documents in this SharePoint site. Lastly, Azure AI Agents will generate responses based on the retrieved information.\n",
    "\n",
    "With SharePoint integration, we will support **OBO (On-Behalf-Of) authentication**, which allows the SharePoint tool to retrieve relevant documents based on the end user’s identity and access.\n",
    "\n",
    "**Prerequisites**\n",
    "- Existing SharePoint site, and ensure developers have access to this SharePoint site.\n",
    "- Developers and end users must have an M365 Copilot license.\n",
    "- Ensure your AOAI resource and AI project are in one of the following regions: `westus`, `japaneast`, `francecentral`.\n",
    "\n",
    "+ **RBAC Roles**\n",
    "    - To CRUD a SharePoint tool in Azure AI Agent, ensure you have the **AI Developer** role.\n",
    "    - Ensure end users have the **AI Developer** role to enable OBO authentication.\n",
    "\n",
    "> Please visit [how-to\\setup-sharepoint-azure-ai-agentmd](how-to\\setup-sharepoint-azure-ai-agent.md) to lear how-to set Up Tools SharepointTool.\n",
    "\n",
    "**Supported Capabilities**\n",
    "- Grounding with all supported documents in a SharePoint site.\n",
    "- Supported document types: PDF, Word, PPT, TXT, .aspx (text data only).\n",
    "- Automatic indexing of updated documents.\n",
    "- Responses based on the end user’s document access.\n",
    "- Connection to a maximum of 1 SharePoint site.\n",
    "\n",
    "**Known Limitations**\n",
    "- Retrieval and grounding quality issues, especially with complex formatting, tables, columns, and images.\n",
    "- Text-sparse file types (e.g., PPT) may return poorer results than text-rich types (e.g., DOCX).\n",
    "- Grounding with specific libraries or multiple sites is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 20:05:58,594 - micro - MainProcess - INFO     SharePoint Connection ID: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-zhuoqunliai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-1959/connections/ContosoAgentDemoSharepoint (1095327310.py:<module>:19)\n",
      "INFO:micro:SharePoint Connection ID: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-zhuoqunliai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-1959/connections/ContosoAgentDemoSharepoint\n",
      "2025-03-19 20:06:01,606 - micro - MainProcess - INFO     Created Agent ID: asst_a07FA4kFCKoTEtEpn2RETeqX (1095327310.py:<module>:61)\n",
      "INFO:micro:Created Agent ID: asst_a07FA4kFCKoTEtEpn2RETeqX\n",
      "2025-03-19 20:06:01,611 - micro - MainProcess - INFO     Agent Metadata: {'use_case': 'Enterprise SharePoint Search', 'data_source': 'SharePoint', 'response_validation': 'Must include source link'} (1095327310.py:<module>:62)\n",
      "INFO:micro:Agent Metadata: {'use_case': 'Enterprise SharePoint Search', 'data_source': 'SharePoint', 'response_validation': 'Must include source link'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Agent Creation Summary ===\n",
      "Agent Name    : my-sharepoint-assistant\n",
      "Agent ID      : asst_a07FA4kFCKoTEtEpn2RETeqX\n",
      "Agent Metadata:\n",
      "  - use_case: Enterprise SharePoint Search\n",
      "  - data_source: SharePoint\n",
      "  - response_validation: Must include source link\n"
     ]
    }
   ],
   "source": [
    "# 1. Set up the model name from environment variable\n",
    "deployment_name = os.environ.get(\"AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME\")\n",
    "if not deployment_name:\n",
    "    logger.error(\"Environment variable 'AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME' is not set.\")\n",
    "    exit(1)\n",
    "\n",
    "# 2. Initialize the AI Project Client (assumed to be done in a previous cell)\n",
    "# 2a. Initialize the SharePoint tool using the connection ID.\n",
    "# For connection setup details, please refer to `how-to/setup-tools-in-ai-foundry.md`\n",
    "try:\n",
    "    sharepoint_connection = project_client.connections.get(\n",
    "        connection_name=os.environ[\"TOOL_CONNECTION_NAME_SHAREPOINT\"]\n",
    "    )\n",
    "except KeyError:\n",
    "    logger.error(\"Environment variable 'TOOL_CONNECTION_NAME_SHAREPOINT' is not set.\")\n",
    "    exit(1)\n",
    "\n",
    "conn_id = sharepoint_connection.id\n",
    "logger.info(f\"SharePoint Connection ID: {conn_id}\")\n",
    "\n",
    "# Create a SharePointTool instance with the connection ID\n",
    "sharepoint = SharepointTool(connection_id=conn_id)\n",
    "\n",
    "# 3. Create a SharePoint-powered AI Agent\n",
    "try:\n",
    "    sharepoint_agent = project_client.agents.create_agent(\n",
    "        model=deployment_name,\n",
    "        name=\"my-sharepoint-assistant\",\n",
    "        description=(\n",
    "            \"A SharePoint-integrated AI assistant designed to search, retrieve, \"\n",
    "            \"and summarize documents stored in SharePoint. This assistant helps users \"\n",
    "            \"quickly find relevant information while ensuring responses include \"\n",
    "            \"document references for validation.\"\n",
    "        ),\n",
    "        instructions=(\n",
    "            \"You are an AI-powered assistant specialized in searching and retrieving \"\n",
    "            \"documents from SharePoint. Your primary role is to find the most relevant \"\n",
    "            \"documents based on user queries and provide clear, concise summaries.\\n\\n\"\n",
    "            \"**Response Guidelines:**\\n\"\n",
    "            \"1. Always retrieve the most relevant document(s) from SharePoint.\\n\"\n",
    "            \"2. Provide a summary of the key information from the retrieved document(s).\\n\"\n",
    "            \"3. Every response **must include the link** to the original document for reference.\\n\"\n",
    "            \"4. If no relevant document is found, respond with: 'No matching documents found in SharePoint.'\\n\"\n",
    "            \"5. Use professional, structured language, and avoid speculation.\\n\\n\"\n",
    "            \"**Example Responses:**\\n\"\n",
    "            \"✅ 'The requested policy document is available here: [Document Link]. Based on its content, \"\n",
    "            \"the key points are...'\\n\"\n",
    "            \"❌ 'I think this might be what you're looking for...' (Avoid speculation.)\"\n",
    "        ),\n",
    "        tools=sharepoint.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"},\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        metadata={\n",
    "            \"use_case\": \"Enterprise SharePoint Search\",\n",
    "            \"data_source\": \"SharePoint\",\n",
    "            \"response_validation\": \"Must include source link\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Created Agent ID: {sharepoint_agent.id}\")\n",
    "    logger.info(f\"Agent Metadata: {sharepoint_agent.metadata}\")\n",
    "\n",
    "except HttpResponseError as e:\n",
    "    try:\n",
    "        error_json = json.loads(e.response.content)\n",
    "        logger.error(f\"Error Message: {error_json.get('Message')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"Non-JSON Error Content: {e.response.content}\")\n",
    "    exit(1)\n",
    "\n",
    "print_agent_summary(sharepoint_agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Trying to Find Information About Dexcom G7 CGM (Info Available in SharePoint)**\n",
    "\n",
    "  Our agent ha been configured with the necessary permissions and equipped with tools like `SharepointTool` to search for the relevant document, validate its existence, and parse its contents. Once the document is retrieved, the agent will extract critical features such as real-time glucose monitoring, compact design, improved accuracy, integration with smart devices, and customizable alerts, ensuring the information is accurate and formatted for digital use. This process requires robust error handling to manage scenarios where the document is missing or inaccessible, and the output should be structured for easy integration into other systems or reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 20:06:02,106 - micro - MainProcess - INFO     Created Thread ID: thread_waaxnu9VuHW7gvTjp783zLfb (127510436.py:<module>:4)\n",
      "INFO:micro:Created Thread ID: thread_waaxnu9VuHW7gvTjp783zLfb\n",
      "2025-03-19 20:06:02,585 - micro - MainProcess - INFO     Created User Message ID: msg_OMrxtcCvbP00neUqI2ZNRIka (127510436.py:<module>:12)\n",
      "INFO:micro:Created User Message ID: msg_OMrxtcCvbP00neUqI2ZNRIka\n",
      "2025-03-19 20:06:04,918 - micro - MainProcess - INFO     Run created. Polling for status... (127510436.py:<module>:18)\n",
      "INFO:micro:Run created. Polling for status...\n",
      "2025-03-19 20:06:07,337 - micro - MainProcess - INFO     Current run ID: run_Q91mAoNtPrkDO5CTnRJUd3DW (127510436.py:<module>:24)\n",
      "INFO:micro:Current run ID: run_Q91mAoNtPrkDO5CTnRJUd3DW\n",
      "2025-03-19 20:06:07,341 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (127510436.py:<module>:25)\n",
      "INFO:micro:Current run status: RunStatus.IN_PROGRESS\n",
      "2025-03-19 20:06:09,769 - micro - MainProcess - INFO     Current run ID: run_Q91mAoNtPrkDO5CTnRJUd3DW (127510436.py:<module>:24)\n",
      "INFO:micro:Current run ID: run_Q91mAoNtPrkDO5CTnRJUd3DW\n",
      "2025-03-19 20:06:09,774 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (127510436.py:<module>:25)\n",
      "INFO:micro:Current run status: RunStatus.IN_PROGRESS\n",
      "2025-03-19 20:06:12,476 - micro - MainProcess - INFO     Current run ID: run_Q91mAoNtPrkDO5CTnRJUd3DW (127510436.py:<module>:24)\n",
      "INFO:micro:Current run ID: run_Q91mAoNtPrkDO5CTnRJUd3DW\n",
      "2025-03-19 20:06:12,484 - micro - MainProcess - INFO     Current run status: RunStatus.COMPLETED (127510436.py:<module>:25)\n",
      "INFO:micro:Current run status: RunStatus.COMPLETED\n",
      "2025-03-19 20:06:12,490 - micro - MainProcess - INFO     Run finished with status: RunStatus.COMPLETED (127510436.py:<module>:27)\n",
      "INFO:micro:Run finished with status: RunStatus.COMPLETED\n",
      "2025-03-19 20:06:12,848 - micro - MainProcess - INFO     ----- Conversation History ----- (127510436.py:<module>:31)\n",
      "INFO:micro:----- Conversation History -----\n",
      "2025-03-19 20:06:12,856 - micro - MainProcess - INFO     ASSISTANT: The key features of the Dexcom G7 CGM (Continuous Glucose Monitoring) System are as follows:\n",
      "\n",
      "1. **Integrated Transmitter and Sensor**: The Dexcom G7 combines the transmitter and CGM sensor into one unit, simplifying the application process.\n",
      "   \n",
      "2. **Improved Application**: The system is applied with a simplified one-click applicator.\n",
      "\n",
      "3. **Smaller Size**: The G7 sensor is significantly smaller compared to the previous Dexcom G6 model.\n",
      "\n",
      "4. **Age Range**: Suitable for individuals aged 2 years and older. Those aged 7 years and older can use it on the back of their upper arm, while those aged 2 to 6 years can use it on both the back of their upper arm and the upper buttocks.\n",
      "\n",
      "5. **Faster Warm-up Time**: The G7 has a warm-up time of just 30 minutes, compared to the G6's 2-hour warm-up period.\n",
      "\n",
      "For more details, you can access the document here: [Dexcom G7 CGM System](#)【3:1†source】. (127510436.py:<module>:34)\n",
      "INFO:micro:ASSISTANT: The key features of the Dexcom G7 CGM (Continuous Glucose Monitoring) System are as follows:\n",
      "\n",
      "1. **Integrated Transmitter and Sensor**: The Dexcom G7 combines the transmitter and CGM sensor into one unit, simplifying the application process.\n",
      "   \n",
      "2. **Improved Application**: The system is applied with a simplified one-click applicator.\n",
      "\n",
      "3. **Smaller Size**: The G7 sensor is significantly smaller compared to the previous Dexcom G6 model.\n",
      "\n",
      "4. **Age Range**: Suitable for individuals aged 2 years and older. Those aged 7 years and older can use it on the back of their upper arm, while those aged 2 to 6 years can use it on both the back of their upper arm and the upper buttocks.\n",
      "\n",
      "5. **Faster Warm-up Time**: The G7 has a warm-up time of just 30 minutes, compared to the G6's 2-hour warm-up period.\n",
      "\n",
      "For more details, you can access the document here: [Dexcom G7 CGM System](#)【3:1†source】.\n",
      "2025-03-19 20:06:12,867 - micro - MainProcess - INFO     USER: What are the key features from Dexcom G7 CGM System? (127510436.py:<module>:34)\n",
      "INFO:micro:USER: What are the key features from Dexcom G7 CGM System?\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1. Create a thread for the conversation\n",
    "    thread = project_client.agents.create_thread()\n",
    "    logger.info(f\"Created Thread ID: {thread.id}\")\n",
    "\n",
    "    # 2. Create a user message on that thread\n",
    "    user_message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"What are the key features from Dexcom G7 CGM System?\"\n",
    "    )\n",
    "    logger.info(f\"Created User Message ID: {user_message.id}\")\n",
    "\n",
    "    # 3. Create a run to process the conversation\n",
    "    run = project_client.agents.create_run(\n",
    "        thread_id=thread.id, agent_id=sharepoint_agent.id\n",
    "    )\n",
    "    logger.info(\"Run created. Polling for status...\")\n",
    "\n",
    "    # 4. Poll until run completes or fails\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        time.sleep(2)\n",
    "        run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "        logger.info(f\"Current run ID: {run.id}\")\n",
    "        logger.info(f\"Current run status: {run.status}\")\n",
    "\n",
    "    logger.info(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    # 5. Retrieve and display the conversation history (oldest to newest)\n",
    "    conversation_history = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    logger.info(\"----- Conversation History -----\")\n",
    "    for msg in conversation_history.data:\n",
    "        if msg.content and isinstance(msg.content[-1], MessageTextContent):\n",
    "            logger.info(f\"{msg.role.upper()}: {msg.content[-1].text.value}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during agent processing: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great News! Our SharePoint Knowledge Retrieval Agent Successfully Found the Necessary Information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating an Azure AI Agent with Fabric Integration (Tool)**\n",
    "\n",
    "Integrate your Azure AI Agent with Fabric `Data agent` to unlock powerful data analysis capabilities. Fabric `Data Agent` transforms enterprise data into conversational Q&A systems, allowing users to interact with data through chat and uncover actionable insights effortlessly.\n",
    "\n",
    "When a user sends a query, the Azure AI Agent first determines if Fabric `Data agent` should be leveraged. If so, it uses the end user’s identity to generate queries over accessible data, and then returns responses based on the queried results. With **on-behalf-of (OBO) authorization**, this integration simplifies secure access to enterprise data in Fabric while ensuring robust protection and proper access control.\n",
    "\n",
    "**Prerequisites**\n",
    "- Published Fabric AI Skill: A published Fabric AI Skill is required (or use the provided Fabric link to access pre-created skills).\n",
    "- Permission/Role Assignment:\n",
    "    + Access to AI Skill: Users must have at least “Read” access to the AI Skill and connected data sources.\n",
    "    + RBAC of Foundry Project: End users need the AI Developer role.\n",
    "\n",
    "+ **RBAC Roles**\n",
    "    - To CRUD a SharePoint tool in Azure AI Agent, ensure you have the **AI Developer** role.\n",
    "    - Ensure end users have the **AI Developer** role to enable OBO authentication.\n",
    "\n",
    "> For detailed step-by-step instructions, please visit [How to Set Up Fabric Azure AI Agent](how-to\\setup-fabric-azure-ai-agent.md).\n",
    "\n",
    "**Known Limitations**\n",
    "- Please review the [Data Agent documentation](https://learn.microsoft.com/en-us/fabric/data-science/concept-ai-skill) for additional details and limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 20:06:13,485 - micro - MainProcess - INFO     Created Agent ID: asst_28CfsW8cEBVvG3HxNSporJMr (4065364071.py:<module>:44)\n",
      "INFO:micro:Created Agent ID: asst_28CfsW8cEBVvG3HxNSporJMr\n",
      "2025-03-19 20:06:13,490 - micro - MainProcess - INFO     Agent Metadata: {'use_case': 'Microsoft Fabric Data Analysis', 'data_source': 'Fabric', 'response_validation': 'Must include source link'} (4065364071.py:<module>:45)\n",
      "INFO:micro:Agent Metadata: {'use_case': 'Microsoft Fabric Data Analysis', 'data_source': 'Fabric', 'response_validation': 'Must include source link'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Agent Creation Summary ===\n",
      "Agent Name    : fabric-intelligence-agent\n",
      "Agent ID      : asst_28CfsW8cEBVvG3HxNSporJMr\n",
      "Agent Metadata:\n",
      "  - use_case: Microsoft Fabric Data Analysis\n",
      "  - data_source: Fabric\n",
      "  - response_validation: Must include source link\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn_id = project_client.connections.get(\n",
    "    connection_name=os.environ[\"TOOL_CONNECTION_NAME_FABRIC\"],\n",
    ")\n",
    "\n",
    "# 4. Initialize Fabric Tool\n",
    "fabric_tool = FabricTool(connection_id=conn_id.id)\n",
    "\n",
    "# 5. Create the Fabric AI Agent\n",
    "try:\n",
    "    fabric_agent = project_client.agents.create_agent(\n",
    "        model=deployment_name,\n",
    "        name=\"fabric-intelligence-agent\",\n",
    "        description=(\n",
    "            \"An AI-powered assistant designed to interact with Microsoft Fabric, \"\n",
    "            \"fetch relevant data, analyze insights, and ensure structured responses \"\n",
    "            \"with validated references. The agent helps users extract valuable \"\n",
    "            \"business intelligence from Fabric data sources.\"\n",
    "        ),\n",
    "        instructions=(\n",
    "            \"You are an AI assistant specialized in retrieving and analyzing data \"\n",
    "            \"from Microsoft Fabric. Your primary goal is to help users extract insights \"\n",
    "            \"by querying structured and unstructured data sources within Fabric. \\n\\n\"\n",
    "            \"**Response Guidelines:**\\n\"\n",
    "            \"1. Always retrieve the most relevant dataset(s) from Fabric.\\n\"\n",
    "            \"2. Provide a structured summary of key findings, ensuring accuracy.\\n\"\n",
    "            \"3. Every response **must include a link** to the original data source for verification.\\n\"\n",
    "            \"4. If no relevant data is found, respond with: 'No relevant data found in Fabric.'\\n\"\n",
    "            \"5. Use precise, professional, and structured language; avoid speculation.\\n\\n\"\n",
    "            \"**Example Responses:**\\n\"\n",
    "            \"✅ *'The requested sales performance data is available here: [Dataset Link]. Key insights: ...'* \\n\"\n",
    "            \"❌ *'I think this might be useful...'* (Avoid vague responses.)\"\n",
    "        ),\n",
    "        tools=fabric_tool.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"},\n",
    "        temperature=0.7,\n",
    "        top_p=1,\n",
    "        metadata={\n",
    "            \"use_case\": \"Microsoft Fabric Data Analysis\",\n",
    "            \"data_source\": \"Fabric\",\n",
    "            \"response_validation\": \"Must include source link\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Created Agent ID: {fabric_agent.id}\")\n",
    "    logger.info(f\"Agent Metadata: {fabric_agent.metadata}\")\n",
    "\n",
    "except HttpResponseError as e:\n",
    "    try:\n",
    "        error_json = json.loads(e.response.content)\n",
    "        logger.error(f\"Error Message: {error_json.get('Message')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"Non-JSON Error Content: {e.response.content}\")\n",
    "\n",
    "print_agent_summary(fabric_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 20:06:13,916 - micro - MainProcess - INFO     Created Thread ID: thread_2o5rdFBPTml7sG9gL0U9jksc (1545354897.py:<module>:4)\n",
      "INFO:micro:Created Thread ID: thread_2o5rdFBPTml7sG9gL0U9jksc\n",
      "2025-03-19 20:06:14,398 - micro - MainProcess - INFO     Created User Message ID: msg_pNdwFp2tdfZ5zuiAjOvNn0qk (1545354897.py:<module>:12)\n",
      "INFO:micro:Created User Message ID: msg_pNdwFp2tdfZ5zuiAjOvNn0qk\n",
      "2025-03-19 20:06:15,920 - micro - MainProcess - INFO     Run created. Polling for status... (1545354897.py:<module>:18)\n",
      "INFO:micro:Run created. Polling for status...\n",
      "2025-03-19 20:06:18,325 - micro - MainProcess - INFO     Current run ID: run_6dLjWCxALCMIxCsdWqIipf83 (1545354897.py:<module>:24)\n",
      "INFO:micro:Current run ID: run_6dLjWCxALCMIxCsdWqIipf83\n",
      "2025-03-19 20:06:18,329 - micro - MainProcess - INFO     Current run status: RunStatus.FAILED (1545354897.py:<module>:25)\n",
      "INFO:micro:Current run status: RunStatus.FAILED\n",
      "2025-03-19 20:06:18,333 - micro - MainProcess - INFO     Run finished with status: RunStatus.FAILED (1545354897.py:<module>:27)\n",
      "INFO:micro:Run finished with status: RunStatus.FAILED\n",
      "2025-03-19 20:06:18,729 - micro - MainProcess - INFO     ----- Conversation History ----- (1545354897.py:<module>:31)\n",
      "INFO:micro:----- Conversation History -----\n",
      "2025-03-19 20:06:18,734 - micro - MainProcess - INFO     USER: How does Product A compare to Product B in terms of MARD percentage across different glucose ranges? Use the tools to analyze the data and provide a summary. (1545354897.py:<module>:34)\n",
      "INFO:micro:USER: How does Product A compare to Product B in terms of MARD percentage across different glucose ranges? Use the tools to analyze the data and provide a summary.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1. Create a thread for the conversation\n",
    "    thread = project_client.agents.create_thread()\n",
    "    logger.info(f\"Created Thread ID: {thread.id}\")\n",
    "\n",
    "    # 2. Create a user message on that thread\n",
    "    user_message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"How does Product A compare to Product B in terms of MARD percentage across different glucose ranges? Use the tools to analyze the data and provide a summary.\",\n",
    "    )\n",
    "    logger.info(f\"Created User Message ID: {user_message.id}\")\n",
    "\n",
    "    # 3. Create a run to process the conversation\n",
    "    run = project_client.agents.create_run(\n",
    "        thread_id=thread.id, agent_id=fabric_agent.id\n",
    "    )\n",
    "    logger.info(\"Run created. Polling for status...\")\n",
    "\n",
    "    # 4. Poll until run completes or fails\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        time.sleep(2)\n",
    "        run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "        logger.info(f\"Current run ID: {run.id}\")\n",
    "        logger.info(f\"Current run status: {run.status}\")\n",
    "\n",
    "    logger.info(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    # 5. Retrieve and display the conversation history (oldest to newest)\n",
    "    conversation_history = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    logger.info(\"----- Conversation History -----\")\n",
    "    for msg in conversation_history.data:\n",
    "        if msg.content and isinstance(msg.content[-1], MessageTextContent):\n",
    "            logger.info(f\"{msg.role.upper()}: {msg.content[-1].text.value}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during agent processing: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating an Azure AI Agent with Bing Integration (Tool) + Azure AI Search**\n",
    "\n",
    "Integrate your Azure AI Agent with Azure AI Search and Bing Search to unlock powerful enterprise and real-time public web data capabilities. By combining the strengths of Azure AI Search for internal data with Bing Search for live web content, your agent can deliver enriched, context-aware responses.\n",
    "\n",
    "When a user sends a query (for example, \"Should I take an umbrella with me today? I'm in Seattle.\"), the Azure AI Agent determines whether to leverage Azure AI Search for enterprise data, Bing Search for public data, or both. It then retrieves the necessary data—applying secure, role-based access—and generates a comprehensive, human-readable response that includes required citations and links.\n",
    "\n",
    "**Prerequisites**\n",
    "+ Published Azure AI Search Index: Ensure you have a properly configured and published Azure AI  Search index containing your data.\n",
    "+ Grounding with Bing Search Resource: Create a Bing Search resource to enable real-time public web data retrieval.\n",
    "\n",
    "> For detailed step-by-step instructions, please visit [How to Set Up Bing Tool](how-to\\fabric.md) and [How to Set Up Azure AI Search Tool](how-to\\setup-fabric-azure-ai-agent.md).\n",
    "\n",
    "**Known Limitations**\n",
    "- Please review the [documentation](https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding?tabs=python&pivots=overview) for additional details and limitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_conn_id = project_client.connections.get(\n",
    "    connection_name=os.environ[\"TOOL_CONNECTION_NAME_BING\"],\n",
    ")\n",
    "bing_tool = BingGroundingTool(connection_id=bing_conn_id.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_conn_id = project_client.connections.get(\n",
    "    connection_name=os.environ[\"TOOL_CONNECTION_NAME_SEARCH\"],\n",
    ")\n",
    "azure_ai_search_tool = AzureAISearchTool(index_connection_id=search_conn_id.id,\n",
    "                                         index_name=\"ai-agentic-index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine All Tools into a ToolSet\n",
    "This step creates a custom ToolSet that includes all the tools configured earlier. It also adds a LoggingToolSet subclass to log the inputs and outputs of function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolset = ToolSet()\n",
    "toolset.add(bing_tool)\n",
    "toolset.add(azure_ai_search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 20:06:19,760 - micro - MainProcess - INFO     Created Agent ID: asst_7s7ZAeePGZpYDCo2xFR5Htsp (460002155.py:<module>:43)\n",
      "INFO:micro:Created Agent ID: asst_7s7ZAeePGZpYDCo2xFR5Htsp\n",
      "2025-03-19 20:06:19,764 - micro - MainProcess - INFO     Agent Metadata: {'use_case': 'Dual Knowledge Integration for Enterprise and Real-Time Data', 'data_source': 'Internal (Azure AI Search) and External (Bing Search)', 'response_validation': 'Must include citation(s) from internal and/or external sources'} (460002155.py:<module>:44)\n",
      "INFO:micro:Agent Metadata: {'use_case': 'Dual Knowledge Integration for Enterprise and Real-Time Data', 'data_source': 'Internal (Azure AI Search) and External (Bing Search)', 'response_validation': 'Must include citation(s) from internal and/or external sources'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Agent Creation Summary ===\n",
      "Agent Name    : reflective-dual-agent\n",
      "Agent ID      : asst_7s7ZAeePGZpYDCo2xFR5Htsp\n",
      "Agent Metadata:\n",
      "  - use_case: Dual Knowledge Integration for Enterprise and Real-Time Data\n",
      "  - data_source: Internal (Azure AI Search) and External (Bing Search)\n",
      "  - response_validation: Must include citation(s) from internal and/or external sources\n"
     ]
    }
   ],
   "source": [
    "# Set up the model name from environment variable\n",
    "deployment_name = os.environ.get(\"AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME\")\n",
    "if not deployment_name:\n",
    "    logger.error(\"Environment variable 'AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME' is not set.\")\n",
    "    exit(1)\n",
    "\n",
    "# Create the Reflective Agent with Dual Knowledge Access\n",
    "try:\n",
    "    reflective_agent = project_client.agents.create_agent(\n",
    "        model=deployment_name,\n",
    "        name=\"reflective-dual-agent\",\n",
    "        description=(\n",
    "            \"A reflective AI-powered assistant designed to integrate both internal enterprise data \"\n",
    "            \"via Azure AI Search and real-time public data via Bing Search. This agent ensures that \"\n",
    "            \"every response includes citations from internal and/or external sources, providing a comprehensive \"\n",
    "            \"and verified answer to each query.\"\n",
    "        ),\n",
    "        instructions=(\n",
    "            \"You are a reflective AI assistant equipped with two distinct tools: one for accessing internal enterprise data \"\n",
    "            \"(Azure AI Search) and another for retrieving real-time public information (Bing Search). Your goal is to \"\n",
    "            \"provide accurate and structured responses by combining data from both sources as needed. \\n\\n\"\n",
    "            \"**Response Guidelines:**\\n\"\n",
    "            \"1. Retrieve the most relevant information from internal enterprise data using Azure AI Search.\\n\"\n",
    "            \"2. Augment your answers with real-time public data from Bing Search when applicable.\\n\"\n",
    "            \"3. Every response **must include a citation** linking to the original source(s) from internal and/or external data.\\n\"\n",
    "            \"4. If no relevant data is found, respond with: 'No relevant data found.'\\n\"\n",
    "            \"5. Use precise, professional language and ensure that both internal and external data are appropriately referenced.\\n\\n\"\n",
    "            \"**Example Responses:**\\n\"\n",
    "            \"✅ *'The requested sales performance data is available here: [Internal Dataset Link], and the latest market trends can be found here: [Bing Search Result Link].'* \\n\"\n",
    "            \"❌ *'I think this might be useful...'* (Avoid vague or unverified responses.)\"\n",
    "        ),\n",
    "        toolset=toolset,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"},\n",
    "        temperature=0.7,\n",
    "        top_p=1,\n",
    "        metadata={\n",
    "            \"use_case\": \"Dual Knowledge Integration for Enterprise and Real-Time Data\",\n",
    "            \"data_source\": \"Internal (Azure AI Search) and External (Bing Search)\",\n",
    "            \"response_validation\": \"Must include citation(s) from internal and/or external sources\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Created Agent ID: {reflective_agent.id}\")\n",
    "    logger.info(f\"Agent Metadata: {reflective_agent.metadata}\")\n",
    "\n",
    "except HttpResponseError as e:\n",
    "    try:\n",
    "        error_json = json.loads(e.response.content)\n",
    "        logger.error(f\"Error Message: {error_json.get('Message')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"Non-JSON Error Content: {e.response.content}\")\n",
    "    exit(1)\n",
    "\n",
    "print_agent_summary(reflective_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 20:10:34,806 - micro - MainProcess - INFO     Created Thread ID: thread_tC7lcJD28C6m1w9J89nqsW3M (2377848834.py:<module>:4)\n",
      "INFO:micro:Created Thread ID: thread_tC7lcJD28C6m1w9J89nqsW3M\n",
      "2025-03-19 20:10:35,229 - micro - MainProcess - INFO     Created User Message ID: msg_IYxGLl6Mt4x7UyCeV2nT7qgX (2377848834.py:<module>:16)\n",
      "INFO:micro:Created User Message ID: msg_IYxGLl6Mt4x7UyCeV2nT7qgX\n",
      "2025-03-19 20:10:36,714 - micro - MainProcess - INFO     Run created. Polling for status... (2377848834.py:<module>:22)\n",
      "INFO:micro:Run created. Polling for status...\n",
      "2025-03-19 20:10:39,085 - micro - MainProcess - INFO     Current run ID: run_xIM4gpc3f4HfPaV7mbtqa88v (2377848834.py:<module>:28)\n",
      "INFO:micro:Current run ID: run_xIM4gpc3f4HfPaV7mbtqa88v\n",
      "2025-03-19 20:10:39,090 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (2377848834.py:<module>:29)\n",
      "INFO:micro:Current run status: RunStatus.IN_PROGRESS\n",
      "2025-03-19 20:10:41,585 - micro - MainProcess - INFO     Current run ID: run_xIM4gpc3f4HfPaV7mbtqa88v (2377848834.py:<module>:28)\n",
      "INFO:micro:Current run ID: run_xIM4gpc3f4HfPaV7mbtqa88v\n",
      "2025-03-19 20:10:41,589 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (2377848834.py:<module>:29)\n",
      "INFO:micro:Current run status: RunStatus.IN_PROGRESS\n",
      "2025-03-19 20:10:44,139 - micro - MainProcess - INFO     Current run ID: run_xIM4gpc3f4HfPaV7mbtqa88v (2377848834.py:<module>:28)\n",
      "INFO:micro:Current run ID: run_xIM4gpc3f4HfPaV7mbtqa88v\n",
      "2025-03-19 20:10:44,146 - micro - MainProcess - INFO     Current run status: RunStatus.IN_PROGRESS (2377848834.py:<module>:29)\n",
      "INFO:micro:Current run status: RunStatus.IN_PROGRESS\n",
      "2025-03-19 20:10:46,555 - micro - MainProcess - INFO     Current run ID: run_xIM4gpc3f4HfPaV7mbtqa88v (2377848834.py:<module>:28)\n",
      "INFO:micro:Current run ID: run_xIM4gpc3f4HfPaV7mbtqa88v\n",
      "2025-03-19 20:10:46,558 - micro - MainProcess - INFO     Current run status: RunStatus.COMPLETED (2377848834.py:<module>:29)\n",
      "INFO:micro:Current run status: RunStatus.COMPLETED\n",
      "2025-03-19 20:10:46,564 - micro - MainProcess - INFO     Run finished with status: RunStatus.COMPLETED (2377848834.py:<module>:31)\n",
      "INFO:micro:Run finished with status: RunStatus.COMPLETED\n",
      "2025-03-19 20:10:46,954 - micro - MainProcess - INFO     ----- Conversation History ----- (2377848834.py:<module>:35)\n",
      "INFO:micro:----- Conversation History -----\n",
      "2025-03-19 20:10:46,957 - micro - MainProcess - INFO     ASSISTANT: ### System Architecture of Product A\n",
      "\n",
      "The system architecture of Product A consists of several key components:\n",
      "\n",
      "1. **User Interface Layer**:\n",
      "   - Web and mobile applications that allow users to interact with the product.\n",
      "   - User authentication and authorization services.\n",
      "\n",
      "2. **Application Layer**:\n",
      "   - Microservices architecture for handling core functionalities.\n",
      "   - Business logic processing units.\n",
      "   - APIs for communication between different services.\n",
      "\n",
      "3. **Data Layer**:\n",
      "   - Relational and NoSQL databases for storage.\n",
      "   - Data warehousing solutions for analytics.\n",
      "\n",
      "4. **Integration Layer**:\n",
      "   - API gateway for routing requests.\n",
      "   - Third-party service integrations.\n",
      "   - Message brokers for asynchronous communication.\n",
      "\n",
      "5. **Infrastructure Layer**:\n",
      "   - Cloud-based infrastructure (e.g., Azure, AWS).\n",
      "   - Load balancers and CDN for performance optimization.\n",
      "   - Monitoring and logging services for infrastructure management.\n",
      "\n",
      "### Nearby Stores for Continuous Glucose Monitoring (iCGM) Devices\n",
      "\n",
      "Several stores near the 60601 area may sell continuous glucose monitoring (iCGM) devices:\n",
      "\n",
      "1. **Walgreens**\n",
      "   - 2 N Michigan Ave, Chicago, IL 60601\n",
      "   - Offers a range of medical supplies including iCGM devices.\n",
      "\n",
      "2. **CVS Pharmacy**\n",
      "   - 105 S Wabash Ave, Chicago, IL 60603\n",
      "   - Provides various health monitoring devices including CGMs.\n",
      "\n",
      "3. **Walmart Pharmacy**\n",
      "   - 4650 W North Ave, Chicago, IL 60639\n",
      "   - Stocks a variety of medical devices including continuous glucose monitors.\n",
      "\n",
      "For additional details, you may refer to the sources:\n",
      "- [GoodRx Article on OTC CGMs](https://www.goodrx.com/continuous-glucose-monitoring-faqs)【5†source】. (2377848834.py:<module>:38)\n",
      "INFO:micro:ASSISTANT: ### System Architecture of Product A\n",
      "\n",
      "The system architecture of Product A consists of several key components:\n",
      "\n",
      "1. **User Interface Layer**:\n",
      "   - Web and mobile applications that allow users to interact with the product.\n",
      "   - User authentication and authorization services.\n",
      "\n",
      "2. **Application Layer**:\n",
      "   - Microservices architecture for handling core functionalities.\n",
      "   - Business logic processing units.\n",
      "   - APIs for communication between different services.\n",
      "\n",
      "3. **Data Layer**:\n",
      "   - Relational and NoSQL databases for storage.\n",
      "   - Data warehousing solutions for analytics.\n",
      "\n",
      "4. **Integration Layer**:\n",
      "   - API gateway for routing requests.\n",
      "   - Third-party service integrations.\n",
      "   - Message brokers for asynchronous communication.\n",
      "\n",
      "5. **Infrastructure Layer**:\n",
      "   - Cloud-based infrastructure (e.g., Azure, AWS).\n",
      "   - Load balancers and CDN for performance optimization.\n",
      "   - Monitoring and logging services for infrastructure management.\n",
      "\n",
      "### Nearby Stores for Continuous Glucose Monitoring (iCGM) Devices\n",
      "\n",
      "Several stores near the 60601 area may sell continuous glucose monitoring (iCGM) devices:\n",
      "\n",
      "1. **Walgreens**\n",
      "   - 2 N Michigan Ave, Chicago, IL 60601\n",
      "   - Offers a range of medical supplies including iCGM devices.\n",
      "\n",
      "2. **CVS Pharmacy**\n",
      "   - 105 S Wabash Ave, Chicago, IL 60603\n",
      "   - Provides various health monitoring devices including CGMs.\n",
      "\n",
      "3. **Walmart Pharmacy**\n",
      "   - 4650 W North Ave, Chicago, IL 60639\n",
      "   - Stocks a variety of medical devices including continuous glucose monitors.\n",
      "\n",
      "For additional details, you may refer to the sources:\n",
      "- [GoodRx Article on OTC CGMs](https://www.goodrx.com/continuous-glucose-monitoring-faqs)【5†source】.\n",
      "2025-03-19 20:10:46,960 - micro - MainProcess - INFO     USER: Can you provide the system architecture of Product A? Additionally,Please use real-time data and search for similar stores close to 60601 that could sell continuous glucose monitoring (iCGM) devices. (2377848834.py:<module>:38)\n",
      "INFO:micro:USER: Can you provide the system architecture of Product A? Additionally,Please use real-time data and search for similar stores close to 60601 that could sell continuous glucose monitoring (iCGM) devices.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1. Create a thread for the conversation\n",
    "    thread = project_client.agents.create_thread()\n",
    "    logger.info(f\"Created Thread ID: {thread.id}\")\n",
    "\n",
    "    # 2. Create a user message on that thread\n",
    "    user_message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=(\n",
    "            \"Can you provide the system architecture of Product A? Additionally,\"\n",
    "            \"Please use real-time data and search for similar stores close to 60601 \"\n",
    "            \"that could sell continuous glucose monitoring (iCGM) devices.\"\n",
    "        ),\n",
    "    )\n",
    "    logger.info(f\"Created User Message ID: {user_message.id}\")\n",
    "\n",
    "    # 3. Create a run to process the conversation\n",
    "    run = project_client.agents.create_run(\n",
    "        thread_id=thread.id, agent_id=reflective_agent.id\n",
    "    )\n",
    "    logger.info(\"Run created. Polling for status...\")\n",
    "\n",
    "    # 4. Poll until run completes or fails\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        time.sleep(2)\n",
    "        run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "        logger.info(f\"Current run ID: {run.id}\")\n",
    "        logger.info(f\"Current run status: {run.status}\")\n",
    "\n",
    "    logger.info(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    # 5. Retrieve and display the conversation history (oldest to newest)\n",
    "    conversation_history = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    logger.info(\"----- Conversation History -----\")\n",
    "    for msg in conversation_history.data:\n",
    "        if msg.content and isinstance(msg.content[-1], MessageTextContent):\n",
    "            logger.info(f\"{msg.role.upper()}: {msg.content[-1].text.value}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during agent processing: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ai-agent-service-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
