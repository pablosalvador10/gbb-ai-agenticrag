{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dfd5e8e",
   "metadata": {},
   "source": [
    "## **Building (Enterprise) Reliable Single AI Agents with Azure AI Foundry Agent Service**\n",
    "\n",
    "### **So, What is an Agent?**\n",
    "\n",
    "When asked, \"What is an agent?\" you might hear, \"James Bond, of course!\" or even, \"An entire team of secret agents!\" In our realm, however, an agent isn’t a spy—it’s an **autonomous computational entity** powered by foundational models (like LLMs or SLMs). Think of it as a digital 007 that observes, plans, and acts based on its environment.\n",
    "\n",
    "<img src=\"https://github.com/pablosalvador10/gbb-ai-agenticrag/blob/cf385f13d14ac5b4c9fe05b954a05a421dfcd23f/utils/images/what%20is%20an%20agent.png\" align=\"left\" style=\"height:180px; margin:0 15px 10px 0; border-radius:15px; max-width:25%;\" />\n",
    "\n",
    "### **The AI Agent – A New Breed of Intelligence**\n",
    "\n",
    "In my view, the best way to describe an AI agent is through the lens of a *Generative Agent*. Researchers at Stanford pioneered this concept by creating AI entities that mimic human-like behavior in simulated environments. Drawing on the paper [*\"Generative Agents: Interactive Simulacra of Human Behavior\"* by Joon Sung Park, Joseph C. O'Brien, and colleagues](https://arxiv.org/abs/2304.03442) (definitely worth a read!), these agents are much more than simple bots. They wake up, make breakfast, form friendships, and even throw parties. Just as James Bond recalls past missions to shape his next move, generative agents retain \"memories\" of their experiences to make nuanced, contextually aware decisions.\n",
    "\n",
    "These agents don’t simply react—they **reflect, strategize, and plan**. Stanford’s approach involves crafting an architecture where agents remember past interactions, consolidate them into reflections, and dynamically retrieve relevant memories to guide future behavior. Picture each AI agent as a unique character in a bustling digital town, complete with quirks, ambitions, and social lives. With observation, planning, and reflection at their core, these generative agents go beyond automation to create simulations that feel truly human.\n",
    "\n",
    "### **Understanding The Anatomy of an Agent: Ordering Pizza with a Twist (007 Style)**\n",
    "\n",
    "Even James Bond, 007, needs to eat. When hunger strikes, he decides on pizza. Here’s how his process mirrors an AI agent’s workflow:\n",
    "\n",
    "<img src=\"https://github.com/pablosalvador10/gbb-ai-agenticrag/blob/cf385f13d14ac5b4c9fe05b954a05a421dfcd23f/utils/images/pizza-workflow.png\" align=\"right\" height=\"200\" style=\"display: block; margin: 20px auto; border-radius: 15px; max-width: 60%; height: auto;\" />\n",
    "\n",
    "\n",
    "- **Perception: Understanding the Problem**  \n",
    "  Bond realizes it’s late and that he needs food—quickly. Factors like traffic, time, and his current location shape his decision. Similarly, an AI agent begins by taking in external data (such as traffic conditions, user preferences, and time constraints) to clearly define the problem.\n",
    "\n",
    "- **Decomposition: Breaking Down the Problem**  \n",
    "  Next, Bond identifies the steps: finding nearby pizzerias, choosing the best option, and arranging delivery. Likewise, an AI agent breaks the problem into actionable tasks—searching for restaurants, filtering by criteria (e.g., delivery speed), and placing an order.\n",
    "\n",
    "- **Planning: Formulating a Strategy**  \n",
    "  Bond carefully weighs his options—speed versus quality—and selects the best pizzeria based on reputation. Similarly, AI agents evaluate constraints and user preferences to determine an optimal plan.\n",
    "\n",
    "- **Tool Utilization: Using Resources**  \n",
    "  Bond leverages his gadgets—perhaps a smartwatch or an app—to check menus and place his order. AI agents use tools like APIs, external databases, or recommendation engines to gather and process information.\n",
    "\n",
    "- **Action: Executing the Plan**  \n",
    "  With a plan in place, Bond places his order and waits for confirmation. The AI agent, in parallel, executes the task by sending requests, tracking progress, and updating systems.\n",
    "\n",
    "- **Feedback and Reflection: Evaluating the Outcome**  \n",
    "  Once the pizza arrives, Bond assesses whether it was on time and met his expectations. Similarly, AI agents review outcomes, measuring success against predefined criteria and learning from each experience.\n",
    "\n",
    "- **Memory: Retaining Lessons Learned**  \n",
    "  Bond stores his experience for future reference—both as a short-term update and as a long-term memory. Likewise, AI agents update their memory to improve performance over time, ensuring smarter decision-making in future tasks.\n",
    "\n",
    "\n",
    "#### **Let's define the Foundational Architecture of a Single AI Agent**\n",
    "\n",
    "<img src=\"https://github.com/pablosalvador10/gbb-ai-agenticrag/blob/cf385f13d14ac5b4c9fe05b954a05a421dfcd23f/utils/images/101agents.png\" align=\"left\" style=\"height:380px; margin:0 15px 10px 0; border-radius:15px; max-width:45%;\" />\n",
    "\n",
    "**Perception:** The agent processes external inputs (e.g., \"I am hungry, need pizza\") to understand the task and its context.\n",
    "**Reasoning:** Utilizing LLMs or SLMs, the agent interprets input, evaluates options, and formulates a strategy.\n",
    "**Memory:** The agent accesses and updates memory to leverage past interactions, ensuring adaptive decision-making.\n",
    "**Tools:** External resources (APIs, databases, applications) are used to perform specific operations—like finding a pizza place or calculating delivery times.\n",
    "**Action:** The agent executes the planned task, translating reasoning into tangible outputs, such as placing orders or delivering updates.\n",
    "\n",
    "\n",
    "### Building Reliable Single AI Agents with Azure AI Foundry Agent Service\n",
    "\n",
    "Azure AI Foundry Agent Service makes it simple to create and deploy intelligent, secure, and scalable AI agents without managing the underlying infrastructure. This fully managed platform streamlines every step—from initializing agents as microservices to automatically invoking the right tools based on user input. By handling conversation state, logger.ging every interaction, and integrating with over 1,400 connectors (such as logger.ic Apps and Azure Functions), it frees you to focus on designing smart workflows.\n",
    "\n",
    "The service also grounds agent responses with real-time data from sources like Bing and SharePoint, while offering flexibility with multiple language models (including GPTs, Meta and Llama) and support for various data types. Security is built in, with features such as BYO storage and keyless authentication ensuring enterprise-grade protection.\n",
    "\n",
    "**In short, Azure AI Foundry Agent Service empowers you to build reliable single-agent systems quickly and efficiently, serving as the foundation for more complex, multi-agent solutions—all while reducing development complexity and ensuring robust performance.**\n",
    "\n",
    "So, let's go ahead and create an agent with Azure AI Foundry Agent Service! 🤖🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ebacae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to c:\\Users\\pablosal\\Desktop\\gbb-ai-agenticrag\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = os.getcwd()  # Get the current working directory\n",
    "\n",
    "# Move one directory back\n",
    "parent_directory = os.path.dirname(target_directory)\n",
    "\n",
    "# Check if the parent directory exists\n",
    "if os.path.exists(parent_directory):\n",
    "    # Change the current working directory to the parent directory\n",
    "    os.chdir(parent_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Parent directory {parent_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9494aa",
   "metadata": {},
   "source": [
    "## **Prerequisites**\n",
    "\n",
    "### Step 1: Set Up Azure Foundry\n",
    "\n",
    "**Hierarchy Overview**:\n",
    "\n",
    "- **Azure AI Foundry**: Integrated platform for building, testing, and deploying AI models and applications.\n",
    "- **Azure AI Agent Service**: Managed service within Foundry for creating and managing AI agents.\n",
    "\n",
    "**Goal**: Create AI agents using Azure AI Agent Service within Azure AI Foundry.\n",
    "\n",
    "**Quick Start Steps**:\n",
    "\n",
    "1. **Access Azure AI Foundry**  \n",
    "   - Go to the [Azure AI Foundry portal](https://ai.azure.com/) and sign in.\n",
    "\n",
    "2. **Create a Project**  \n",
    "   - Click **\"Create a new project\"**.\n",
    "   - Fill in:\n",
    "     - **Project Name**: `agentic-lab-eastus-dev`\n",
    "     - **Subscription**: Your Azure subscription\n",
    "     - **Resource Group**: Existing or new\n",
    "     - **Region**: East US\n",
    "   - Click **\"Create\"**.\n",
    "\n",
    "3. **Get Your Project Endpoint**  \n",
    "   - Select your project (**agentic-lab-eastus-dev**) in the Azure AI Foundry portal.\n",
    "   - **Copy the endpoint URL** from the project overview page.  \n",
    "      The endpoint will look like:  \n",
    "      ```\n",
    "      https://<AIFoundryResourceName>.services.ai.azure.com/api/projects/<ProjectName>\n",
    "      ```\n",
    "   - *Tip*: You can also find this endpoint under **Libraries > Azure AI Foundry** in the portal.  \n",
    "\n",
    "4. **Configure Environment**  \n",
    "   - Paste the connection string into the `AZURE_AI_FOUNDRY_URL` parameter in your `.env` file.\n",
    "\n",
    "5. **Install Required Python Packages**  \n",
    "   Run the following in your terminal:\n",
    "   ```bash\n",
    "   pip install azure-ai-projects\n",
    "   pip install azure-identity\n",
    "   ```\n",
    "\n",
    "6. **Authenticate with Azure**  \n",
    "   Sign in to your Azure subscription:\n",
    "   ```bash\n",
    "   az logger.in\n",
    "   ```\n",
    "\n",
    "For more details, see the [official documentation](https://learn.microsoft.com/en-us/azure/ai-services/agents/quickstart?pivots=programming-language-python-azure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5588e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:39:57,948 - micro - MainProcess - INFO     Azure AI Agents Foundry project client created successfully (1277011103.py:<module>:31)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure-ai-projects version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import importlib.metadata as md\n",
    "from utils.ml_logging import get_logger\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.agents.models import (\n",
    "    FunctionTool,\n",
    "    ToolSet,\n",
    "    ToolOutput,\n",
    "    RequiredFunctionToolCall,\n",
    "    SubmitToolOutputsAction,\n",
    "    RunStatus,\n",
    "    MessageTextContent,\n",
    "    ListSortOrder,\n",
    ")\n",
    "\n",
    "# Versions - we are currently 1.0.0b9 of azure-ai-projects\n",
    "print(\"azure-ai-projects version:\", md.version(\"azure-ai-agents\"))\n",
    "# if you want to Upgrade the SDKs, uncomment the line below but code might break\n",
    "# %pip install -U azure-ai-agents azure-identity\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "# Connect to the AI Foundry project\n",
    "project_connection_string = os.getenv(\"AZURE_AI_FOUNDRY_URL\")\n",
    "agents_client = AgentsClient(\n",
    "    endpoint=project_connection_string,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "logger.info(\"Azure AI Agents Foundry project client created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb87e34",
   "metadata": {},
   "source": [
    "## **Helpers Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a5a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents_client() -> AgentsClient:\n",
    "    \"\"\"Return an authenticated AgentsClient based on env vars.\"\"\"\n",
    "    endpoint = os.getenv(\"AZURE_AI_FOUNDRY_URL\")\n",
    "    if not endpoint:\n",
    "        logger.error(\"AZURE_AI_FOUNDRY_URL must be set\")\n",
    "        sys.exit(1)\n",
    "    cred = DefaultAzureCredential()\n",
    "    return AgentsClient(endpoint=endpoint, credential=cred)\n",
    "\n",
    "\n",
    "def get_model_deployment() -> str:\n",
    "    \"\"\"Return the model deployment name from env vars.\"\"\"\n",
    "    dep = os.getenv(\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID\")\n",
    "    if not dep:\n",
    "        logger.error(\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID must be set\")\n",
    "        sys.exit(1)\n",
    "    return dep\n",
    "\n",
    "\n",
    "def create_agent(\n",
    "    client: AgentsClient, deployment: str, toolset: ToolSet | None = None\n",
    ") -> str:\n",
    "    \"\"\"Create an agent (optionally with tools) and return its ID.\"\"\"\n",
    "    try:\n",
    "        agent = client.create_agent(\n",
    "            model=deployment,\n",
    "            name=\"demo-agent\",\n",
    "            instructions=\"You are a concise assistant.\",\n",
    "            toolset=toolset,\n",
    "        )\n",
    "        logger.info(\"Agent created: %s\", agent.id)\n",
    "        return agent.id\n",
    "    except HttpResponseError as e:  # pragma: no cover\n",
    "        logger.error(\"Agent creation failed: %s\", e)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def create_thread(client: AgentsClient) -> str:\n",
    "    \"\"\"Start a new conversation thread.\"\"\"\n",
    "    t = client.threads.create()\n",
    "    logger.info(\"Thread created: %s\", t.id)\n",
    "    return t.id\n",
    "\n",
    "\n",
    "def post_message(client: AgentsClient, thread_id: str, role: str, text: str) -> None:\n",
    "    \"\"\"Post a message to a thread.\"\"\"\n",
    "    m = client.messages.create(thread_id=thread_id, role=role, content=text)\n",
    "    logger.debug(\"Message posted: %s\", m.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d26fb",
   "metadata": {},
   "source": [
    "## **Basic Conversation – No Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0058e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:40:05,006 - micro - MainProcess - INFO     Agent created: asst_dUztJKZ3PBMK6c5ARb8ZX6JH (705178453.py:create_agent:27)\n",
      "2025-05-28 15:40:05,507 - micro - MainProcess - INFO     Thread created: thread_zahiu1wawuIYFQVNqduRekGd (705178453.py:create_thread:36)\n",
      "2025-05-28 15:40:10,541 - micro - MainProcess - INFO     Run finished with status → RunStatus.COMPLETED (2978901451.py:<module>:13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Conversation —\n",
      "YOU: Why should I visit Madrid in 100 words?\n",
      "AZURE AI FOUNDRY AGENT: Madrid is a vibrant hub of culture, history, and gastronomy. Explore world-class museums like the Prado, Reina Sofia, and Thyssen-Bornemisza, home to masterpieces by artists such as Picasso and Velázquez. Stroll through grand plazas like Plaza Mayor and Puerta del Sol, or relax in the lush Retiro Park. Indulge in its renowned culinary scene, from traditional tapas to Michelin-starred dining. Madrid comes alive at night, with flamenco shows, bustling nightlife, and warm local hospitality. Its mix of historical landmarks, such as the Royal Palace, and modern energy creates an unforgettable experience. Madrid is the heart of Spain, bursting with charm!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:40:11,983 - micro - MainProcess - INFO     Agent asst_dUztJKZ3PBMK6c5ARb8ZX6JH deleted (2978901451.py:<module>:23)\n"
     ]
    }
   ],
   "source": [
    "client = get_agents_client()\n",
    "deploy = get_model_deployment()\n",
    "\n",
    "with client:\n",
    "    agent_id = create_agent(client, deploy)\n",
    "    thread_id = create_thread(client)\n",
    "    post_message(client, thread_id, \"user\", \"Why should I visit Madrid in 100 words?\")\n",
    "\n",
    "    run = client.runs.create_and_process(thread_id=thread_id, agent_id=agent_id)\n",
    "    logger.info(\"Run finished with status → %s\", run.status)\n",
    "\n",
    "    print(\"\\n— Conversation —\")\n",
    "    for msg in client.messages.list(thread_id, order=ListSortOrder.ASCENDING):\n",
    "        last = msg.text_messages[-1] if msg.text_messages else None\n",
    "        if isinstance(last, MessageTextContent):\n",
    "            role = \"YOU\" if msg.role == \"user\" else \"AZURE AI FOUNDRY AGENT\"\n",
    "            print(f\"{role}: {last.text.value}\")\n",
    "\n",
    "    client.delete_agent(agent_id)\n",
    "    logger.info(\"Agent %s deleted\", agent_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043d32c",
   "metadata": {},
   "source": [
    "You can track the agent (`agent_id`) and conversation threads directly in Azure AI Foundry.\n",
    "\n",
    "<img alt=\"UI Agents\" src=\"https://github.com/pablosalvador10/gbb-ai-agenticrag/blob/main/utils/images/agentsfoundry.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080eaeb",
   "metadata": {},
   "source": [
    "## **Adding Tools and Custom User Functions**\n",
    "\n",
    "> Scenario: We want the agent to call Python functions to perform tasks like getting the current local time, summing numbers, or retrieving mock weather data. We wrap these Python functions in a FunctionTool, then attach them to the agent as part of a ToolSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cf2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Any, Set, List\n",
    "\n",
    "\n",
    "def get_stock_price(symbol: str) -> float:\n",
    "    \"\"\"Return a stubbed stock price.\"\"\"\n",
    "    return 123.45\n",
    "\n",
    "\n",
    "def analyze_sentiment(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Return a stubbed sentiment result.\"\"\"\n",
    "    return {\"sentiment\": \"positive\", \"score\": 0.85}\n",
    "\n",
    "\n",
    "def summarize_text(text: str) -> str:\n",
    "    \"\"\"Return the first 100 chars and an ellipsis.\"\"\"\n",
    "    return f\"{text[:100]}…\"\n",
    "\n",
    "\n",
    "CUSTOM_FUNCS: Set[Callable[..., Any]] = {\n",
    "    get_stock_price,\n",
    "    analyze_sentiment,\n",
    "    summarize_text,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c7d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:40:16,087 - micro - MainProcess - INFO     Agent created: asst_U17Vml2DrjAUODgy01pMAv0G (705178453.py:create_agent:27)\n",
      "2025-05-28 15:40:16,580 - micro - MainProcess - INFO     Thread created: thread_rftswBSwXkrgnZDEuzrH3i7o (705178453.py:create_thread:36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Run created, id = run_ji4hctX21tDVlmjuVyytMva8, status = RunStatus.QUEUED\n",
      "🔄 Run status: RunStatus.REQUIRES_ACTION\n",
      "🛠  Agent requests 2 tool call(s)\n",
      "   ↪ Executing summarize_text({\"text\": \"Azure AI provides a comprehensive suite of tools for building intelligent apps.\"})\n",
      "   ✔ Result ready\n",
      "   ↪ Executing analyze_sentiment({\"text\": \"Azure AI provides a comprehensive suite of tools for building intelligent apps.\"})\n",
      "   ✔ Result ready\n",
      "🚚 Tool outputs submitted\n",
      "🔄 Run status: RunStatus.COMPLETED\n",
      "✅ Run finished: RunStatus.COMPLETED\n",
      "USER: Summarise this text and analyse its sentiment: 'Azure AI provides a comprehensive suite of tools for building intelligent apps.'\n",
      "ASSISTANT: The summary is: \"Azure AI provides a comprehensive suite of tools for building intelligent apps…\".  \n",
      "The sentiment is positive with a score of 0.85.\n",
      "🧹 Agent deleted\n"
     ]
    }
   ],
   "source": [
    "import json, time\n",
    "from typing import List, Set\n",
    "from azure.ai.agents.models import (\n",
    "    RunStatus,\n",
    "    SubmitToolOutputsAction,\n",
    "    RequiredFunctionToolCall,\n",
    "    ToolOutput,\n",
    "    MessageTextContent,\n",
    "    ListSortOrder,\n",
    ")\n",
    "\n",
    "func_tool = FunctionTool(CUSTOM_FUNCS)\n",
    "toolset = ToolSet()\n",
    "toolset.add(func_tool)\n",
    "client = get_agents_client()\n",
    "\n",
    "with client:  # keep HTTP session alive\n",
    "    deploy = get_model_deployment()\n",
    "    agent_id = create_agent(client, deploy, toolset)\n",
    "    thread_id = create_thread(client)\n",
    "\n",
    "    post_message(\n",
    "        client,\n",
    "        thread_id,\n",
    "        \"user\",\n",
    "        \"Summarise this text and analyse its sentiment: \"\n",
    "        \"'Azure AI provides a comprehensive suite of tools for building intelligent apps.'\",\n",
    "    )\n",
    "\n",
    "    run = client.runs.create(thread_id=thread_id, agent_id=agent_id)\n",
    "    print(f\"⏳ Run created, id = {run.id}, status = {run.status}\")\n",
    "\n",
    "    terminal: Set[RunStatus] = {\n",
    "        RunStatus.COMPLETED,\n",
    "        RunStatus.FAILED,\n",
    "        RunStatus.CANCELLED,\n",
    "        RunStatus.EXPIRED,\n",
    "    }\n",
    "\n",
    "    while run.status not in terminal:\n",
    "        if run.status == RunStatus.REQUIRES_ACTION and isinstance(\n",
    "            run.required_action, SubmitToolOutputsAction\n",
    "        ):\n",
    "            tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "            print(f\"🛠  Agent requests {len(tool_calls)} tool call(s)\")\n",
    "\n",
    "            outs: List[ToolOutput] = []\n",
    "            for call in tool_calls:\n",
    "                if not isinstance(call, RequiredFunctionToolCall):\n",
    "                    continue\n",
    "\n",
    "                args = call.function.arguments\n",
    "                print(f\"   ↪ Executing {call.function.name}({args})\")\n",
    "                raw = func_tool.execute(call)\n",
    "                outs.append(\n",
    "                    ToolOutput(\n",
    "                        tool_call_id=call.id,\n",
    "                        output=raw if isinstance(raw, str) else json.dumps(raw),\n",
    "                    )\n",
    "                )\n",
    "                print(f\"   ✔ Result ready\")\n",
    "\n",
    "            client.runs.submit_tool_outputs(\n",
    "                thread_id=thread_id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=outs,\n",
    "            )\n",
    "            print(\"🚚 Tool outputs submitted\")\n",
    "\n",
    "        time.sleep(1)\n",
    "        run = client.runs.get(thread_id, run.id)\n",
    "        print(f\"🔄 Run status: {run.status}\")\n",
    "\n",
    "    if run.status == RunStatus.FAILED:\n",
    "        print(\"❌ Run failed:\", run.last_error)\n",
    "    else:\n",
    "        print(\"✅ Run finished:\", run.status)\n",
    "\n",
    "    for m in client.messages.list(thread_id, order=ListSortOrder.ASCENDING):\n",
    "        last = m.text_messages[-1] if m.text_messages else None\n",
    "        if isinstance(last, MessageTextContent):\n",
    "            role = m.role.upper()\n",
    "            print(f\"{role}: {last.text.value}\")\n",
    "\n",
    "    client.delete_agent(agent_id)\n",
    "    print(\"🧹 Agent deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c43d",
   "metadata": {},
   "source": [
    "## **Let's Stream the Output**\n",
    "\n",
    "| Benefit                | Why it Matters                                                                                   |\n",
    "|------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| **Real-time answers**  | See tokens as soon as the model generates them—no more waiting for the full response to finish.  |\n",
    "| **Tool progress hooks**| Each tool call emits a `RunStepDeltaChunk`, so you can display live updates like “calling `get_stock_price('TSLA')` … done”. |\n",
    "| **Early error surfacing** | If something goes wrong, `AgentStreamEvent.ERROR` fires immediately—so users aren’t left waiting for a failed run. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2690c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, functools\n",
    "\n",
    "\n",
    "def safe(func):\n",
    "    \"\"\"Ensure every tool returns a JSON object string.\"\"\"\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        raw = func(*args, **kwargs)\n",
    "        # If it's already a dict, keep it; else wrap\n",
    "        payload = raw if isinstance(raw, dict) else {\"value\": raw}\n",
    "        return json.dumps(payload)  # always an object → sdk is happy\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "SAFE_FUNCS = {safe(f) for f in CUSTOM_FUNCS}\n",
    "func_tool = FunctionTool(SAFE_FUNCS)\n",
    "toolset = ToolSet()\n",
    "toolset.add(func_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da91e098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:40:28,038 - micro - MainProcess - INFO     Agent created: asst_RISxn1L0dTXUdR4Cvf0vOozw (705178453.py:create_agent:27)\n",
      "2025-05-28 15:40:28,469 - micro - MainProcess - INFO     Thread created: thread_ZNYiJmZlf9k1EpeMIznpgP3t (705178453.py:create_thread:36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ streaming …\n",
      "\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "🛠 tool step …\n",
      "\n",
      "✅ finished\n",
      "The current TSLA price is $123.45. Market sentiment: Positive outlook regarding Tesla's EV advancements and trading potential.\n",
      "✅ finished\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import (\n",
    "    AgentStreamEvent,\n",
    "    MessageDeltaChunk,\n",
    "    RunStepDeltaChunk,\n",
    "    RunStatus,\n",
    "    MessageTextContent,\n",
    "    ListSortOrder,\n",
    "    ThreadMessage,\n",
    "    ThreadRun,\n",
    ")\n",
    "\n",
    "client = get_agents_client()\n",
    "\n",
    "with client:\n",
    "    client.enable_auto_function_calls(toolset)\n",
    "\n",
    "    agent_id = create_agent(client, get_model_deployment(), toolset)\n",
    "    thread_id = create_thread(client)\n",
    "\n",
    "    post_message(\n",
    "        client,\n",
    "        thread_id,\n",
    "        \"user\",\n",
    "        \"Give me the current TSLA price and a 10-word market sentiment.\",\n",
    "    )\n",
    "\n",
    "    print(\"⏳ streaming …\\n\")\n",
    "\n",
    "    with client.runs.stream(thread_id=thread_id, agent_id=agent_id) as stream:\n",
    "        for et, data, _ in stream:\n",
    "            if isinstance(data, MessageDeltaChunk):\n",
    "                print(data.text, end=\"\", flush=True)\n",
    "\n",
    "            elif isinstance(data, RunStepDeltaChunk):\n",
    "                fn_name = data.delta.get(\"function_call\", {}).get(\"name\", \"tool\")\n",
    "                print(f\"\\n🛠 {fn_name} step …\", flush=True)\n",
    "\n",
    "            elif et == AgentStreamEvent.ERROR:\n",
    "                print(\"\\n🚨 error:\", data)\n",
    "\n",
    "            elif et == AgentStreamEvent.DONE:\n",
    "                print(\"\\n✅ finished\")\n",
    "    client.delete_agent(agent_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a35dc5",
   "metadata": {},
   "source": [
    "### **Let's Think About Prod - It Needs for Streaming, Async Calls, and Event-Driven Orchestration**\n",
    "\n",
    "When Agentic Systems, it's crucial to consider:\n",
    "\n",
    "- **Streaming Outputs:**  \n",
    "    Real-time token streaming provides immediate feedback, improving user experience and enabling faster iteration.\n",
    "\n",
    "- **Asynchronous Execution:**  \n",
    "    Async calls allow agents to handle multiple tasks concurrently, reducing latency and supporting complex workflows.\n",
    "\n",
    "- **Event-Driven Orchestration:**  \n",
    "    Leveraging event handlers enables agents to react to intermediate steps, tool calls, and errors as they happen, making the system more robust and interactive.\n",
    "\n",
    "By combining these patterns, we unlock more responsive, scalable, and maintainable agent architectures—delivering both better performance and a superior user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5dd7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Set, List\n",
    "from azure.ai.agents.models import (\n",
    "    AsyncAgentEventHandler,\n",
    "    MessageDeltaChunk,\n",
    "    RunStepDeltaChunk,\n",
    "    ThreadMessage,\n",
    "    ThreadRun,\n",
    "    RunStep,\n",
    ")\n",
    "\n",
    "\n",
    "class CaptureEvents(AsyncAgentEventHandler):\n",
    "    \"\"\"Console stream + collects tokens in self.tokens.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()  # keep base internals intact\n",
    "        self.tokens: List[str] = []\n",
    "        self.seen: Set[str] = set()\n",
    "\n",
    "    async def on_message_delta(self, delta: MessageDeltaChunk) -> None:\n",
    "        self.tokens.append(delta.text)\n",
    "        print(delta.text, end=\"\", flush=True)\n",
    "\n",
    "    async def on_run_step(self, step: RunStep) -> None:\n",
    "        calls = getattr(step, \"tool_calls\", None)\n",
    "        if calls:\n",
    "            for call in calls:\n",
    "                fn = getattr(call.function, \"name\", None)\n",
    "                if fn and call.id not in self.seen:\n",
    "                    self.seen.add(call.id)\n",
    "                    print(f\"\\n🛠  {fn} …\", flush=True)\n",
    "        print(f\"\\n🔄 run step status → {step.status}\", flush=True)\n",
    "\n",
    "    async def on_run_step_delta(self, chunk: RunStepDeltaChunk) -> None:\n",
    "        fn = chunk.delta.get(\"function_call\", {}).get(\"name\") or chunk.delta.get(\n",
    "            \"tool_call\", {}\n",
    "        ).get(\"function\", {}).get(\"name\")\n",
    "        if fn and chunk.id not in self.seen:\n",
    "            self.seen.add(chunk.id)\n",
    "            print(f\"\\n🛠  {fn} …\", flush=True)\n",
    "\n",
    "    async def on_thread_run(self, run: ThreadRun) -> None:\n",
    "        print(f\"\\n🔄 run status → {run.status}\", flush=True)\n",
    "\n",
    "    async def on_thread_message(self, message: ThreadMessage) -> None:\n",
    "        if message.status:\n",
    "            print(f\"\\n💬 msg status → {message.status}\", flush=True)\n",
    "\n",
    "    async def on_error(self, data: str) -> None:\n",
    "        print(\"\\n🚨 stream error:\", data, flush=True)\n",
    "\n",
    "    async def on_done(self) -> None:\n",
    "        print(\"\\n✅ stream finished\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ba84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from azure.ai.agents.aio import AgentsClient\n",
    "from azure.ai.agents.models import AsyncAgentEventHandler\n",
    "\n",
    "\n",
    "async def create_agent(\n",
    "    client: AgentsClient, *, model: str, name: str, instructions: str, toolset: ToolSet\n",
    ") -> str:\n",
    "    agent = await client.create_agent(\n",
    "        model=model, name=name, instructions=instructions, toolset=toolset\n",
    "    )\n",
    "    logger.info(\"Agent created → %s\", agent.id)\n",
    "    return agent.id\n",
    "\n",
    "\n",
    "async def run_agent_with_events(\n",
    "    client: AgentsClient,\n",
    "    agent_id: str,\n",
    "    prompt: str,\n",
    "    events: Optional[AsyncAgentEventHandler] = None,\n",
    ") -> str:\n",
    "    \"\"\"Create thread, post prompt, stream; return the full assistant reply.\"\"\"\n",
    "    token_buffer: List[str] = []\n",
    "    handler = events or CaptureEvents()\n",
    "\n",
    "    thread = await client.threads.create()\n",
    "    await client.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n",
    "\n",
    "    async with await client.runs.stream(\n",
    "        thread_id=thread.id, agent_id=agent_id, event_handler=handler\n",
    "    ) as s:\n",
    "        await s.until_done()\n",
    "\n",
    "    return \"\".join(handler.tokens) if handler.tokens else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a93eff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:40:40,527 - micro - MainProcess - INFO     Agent created → asst_BipXGyYaasFHCWEI5f4FHT35 (545006648.py:create_agent:9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 run status → RunStatus.QUEUED\n",
      "\n",
      "🔄 run status → RunStatus.QUEUED\n",
      "\n",
      "🔄 run status → RunStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run step status → RunStepStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run step status → RunStepStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run status → RunStatus.REQUIRES_ACTION\n",
      "\n",
      "✅ stream finished\n",
      "\n",
      "🔄 run step status → RunStepStatus.COMPLETED\n",
      "\n",
      "🔄 run status → RunStatus.QUEUED\n",
      "\n",
      "🔄 run status → RunStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run step status → RunStepStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run step status → RunStepStatus.IN_PROGRESS\n",
      "\n",
      "💬 msg status → MessageStatus.IN_PROGRESS\n",
      "\n",
      "💬 msg status → MessageStatus.IN_PROGRESS\n",
      "The current TSLA price is $123.45.  \n",
      "Sentiment: Tesla shows upward momentum driven by strong demand.\n",
      "💬 msg status → MessageStatus.COMPLETED\n",
      "\n",
      "🔄 run step status → RunStepStatus.COMPLETED\n",
      "\n",
      "🔄 run status → RunStatus.COMPLETED\n",
      "\n",
      "✅ stream finished\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def safe(fn):\n",
    "    \"\"\"Return the same name & docstring, but JSON-serialise the result.\"\"\"\n",
    "\n",
    "    @functools.wraps(fn)\n",
    "    def wrapper(*a, **kw):\n",
    "        raw = fn(*a, **kw)\n",
    "        payload: Dict[str, Any] = raw if isinstance(raw, dict) else {\"value\": raw}\n",
    "        return json.dumps(payload)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    cred = DefaultAzureCredential()\n",
    "    client = AgentsClient(os.environ[\"AZURE_AI_FOUNDRY_URL\"], cred)\n",
    "\n",
    "    try:\n",
    "        # tools + agent creation identical to earlier cells -------------\n",
    "        SAFE_FUNCS = {safe(get_stock_price), safe(summarize_text)}\n",
    "        function_tool = FunctionTool(SAFE_FUNCS)\n",
    "        toolset = ToolSet()\n",
    "        toolset.add(function_tool)\n",
    "        client.enable_auto_function_calls(SAFE_FUNCS)\n",
    "\n",
    "        agent_id = await create_agent(\n",
    "            client,\n",
    "            model=get_model_deployment(),\n",
    "            name=\"event-agent\",\n",
    "            instructions=\"You are an async agent with event handler.\",\n",
    "            toolset=toolset,\n",
    "        )\n",
    "\n",
    "        response = await run_agent_with_events(\n",
    "            client,\n",
    "            agent_id,\n",
    "            prompt=\"Give me the current TSLA price and a 10-word sentiment.\",\n",
    "        )\n",
    "\n",
    "        await client.delete_agent(agent_id)\n",
    "        return response\n",
    "    finally:\n",
    "        await client.close()\n",
    "\n",
    "\n",
    "response = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0dc92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current TSLA price is $123.45.  \\nSentiment: Tesla shows upward momentum driven by strong demand.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49719872",
   "metadata": {},
   "source": [
    "## **Let's add Traceability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8cd2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED - Optional. Set to `true` to trace the\n",
    "# content of chat messages, which may contain personal data. False by default.\n",
    "!set AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b2e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry import trace\n",
    "\n",
    "configure_azure_monitor(\n",
    "    connection_string=os.environ[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"]\n",
    ")\n",
    "tracer = trace.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8be182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_span(name: str):\n",
    "    return tracer.start_as_current_span(name)\n",
    "\n",
    "\n",
    "class CaptureEventsTracing(AsyncAgentEventHandler):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tokens: List[str] = []\n",
    "        self.seen: Set[str] = set()\n",
    "\n",
    "    async def on_message_delta(self, delta: MessageDeltaChunk):\n",
    "        self.tokens.append(delta.text)\n",
    "        print(delta.text, end=\"\", flush=True)\n",
    "        with start_span(\"delta\"):\n",
    "            trace.get_current_span().set_attribute(\"token\", delta.text)\n",
    "\n",
    "    async def _announce_tool(self, step_id: str, fn: str):\n",
    "        if step_id not in self.seen:\n",
    "            self.seen.add(step_id)\n",
    "            print(f\"\\n🛠  {fn} …\", flush=True)\n",
    "            with start_span(f\"tool:{fn}\"):\n",
    "                trace.get_current_span().set_attribute(\"step_id\", step_id)\n",
    "\n",
    "    async def on_run_step(self, step: RunStep):\n",
    "        for call in getattr(step, \"tool_calls\", []):\n",
    "            fn = getattr(call.function, \"name\", None)\n",
    "            if fn:\n",
    "                await self._announce_tool(call.id, fn)\n",
    "        with start_span(\"run_step\"):\n",
    "            trace.get_current_span().set_attribute(\"status\", str(step.status))\n",
    "        print(f\"\\n🔄 run step status → {step.status}\", flush=True)\n",
    "\n",
    "    async def on_run_step_delta(self, chunk: RunStepDeltaChunk):\n",
    "        fn = chunk.delta.get(\"function_call\", {}).get(\"name\") or chunk.delta.get(\n",
    "            \"tool_call\", {}\n",
    "        ).get(\"function\", {}).get(\"name\")\n",
    "        if fn:\n",
    "            await self._announce_tool(chunk.id, fn)\n",
    "\n",
    "    async def on_thread_run(self, run: ThreadRun):\n",
    "        print(f\"\\n🔄 run status → {run.status}\", flush=True)\n",
    "        with start_span(\"thread_run\"):\n",
    "            trace.get_current_span().set_attribute(\"status\", str(run.status))\n",
    "\n",
    "    async def on_thread_message(self, msg: ThreadMessage):\n",
    "        if msg.status:\n",
    "            print(f\"\\n💬 msg status → {msg.status}\", flush=True)\n",
    "            with start_span(\"thread_message\"):\n",
    "                trace.get_current_span().set_attribute(\"status\", str(msg.status))\n",
    "\n",
    "    async def on_error(self, data: str):\n",
    "        print(\"\\n🚨 stream error:\", data, flush=True)\n",
    "        with start_span(\"error\"):\n",
    "            trace.get_current_span().set_attribute(\"detail\", data)\n",
    "\n",
    "    async def on_done(self):\n",
    "        print(\"\\n✅ stream finished\", flush=True)\n",
    "        with start_span(\"done\"):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef69ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:40:59,637 - micro - MainProcess - INFO     Agent created → asst_BXcHXUZeqzjJDutJJbFKBHpX (545006648.py:create_agent:9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 run status → RunStatus.QUEUED\n",
      "\n",
      "🔄 run status → RunStatus.QUEUED\n",
      "\n",
      "🔄 run status → RunStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run step status → RunStepStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run step status → RunStepStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run status → RunStatus.REQUIRES_ACTION\n",
      "\n",
      "✅ stream finished\n",
      "\n",
      "🔄 run step status → RunStepStatus.COMPLETED\n",
      "\n",
      "🔄 run status → RunStatus.QUEUED\n",
      "\n",
      "🔄 run status → RunStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run step status → RunStepStatus.IN_PROGRESS\n",
      "\n",
      "🔄 run step status → RunStepStatus.IN_PROGRESS\n",
      "\n",
      "💬 msg status → MessageStatus.IN_PROGRESS\n",
      "\n",
      "💬 msg status → MessageStatus.IN_PROGRESS\n",
      "The current TSLA price is $123.45, and the sentiment is positive with a score of 0.85.\n",
      "💬 msg status → MessageStatus.COMPLETED\n",
      "\n",
      "🔄 run step status → RunStepStatus.COMPLETED\n",
      "\n",
      "🔄 run status → RunStatus.COMPLETED\n",
      "\n",
      "✅ stream finished\n",
      "\n",
      "\n",
      "ASSISTANT (full): The current TSLA price is $123.45, and the sentiment is positive with a score of 0.85.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:41:06,019 - micro - MainProcess - INFO     Agent asst_BXcHXUZeqzjJDutJJbFKBHpX deleted (1444509381.py:main:32)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    endpoint = os.environ[\"AZURE_AI_FOUNDRY_URL\"]\n",
    "    model = os.environ[\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID\"]\n",
    "\n",
    "    cred = DefaultAzureCredential()\n",
    "    client = AgentsClient(endpoint, cred)\n",
    "\n",
    "    run_id = f\"async-agent-run-{int(time.time())}\"\n",
    "    with tracer.start_as_current_span(run_id):\n",
    "        try:\n",
    "            client.enable_auto_function_calls(SAFE_FUNCS)\n",
    "\n",
    "            agent_id = await create_agent(\n",
    "                client,\n",
    "                model=model,\n",
    "                name=\"traceable-agent\",\n",
    "                instructions=\"You are a helpful async agent.\",\n",
    "                toolset=toolset,\n",
    "            )\n",
    "\n",
    "            answer = await run_agent_with_events(\n",
    "                client,\n",
    "                agent_id,\n",
    "                prompt=\"Give me the current TSLA price and a 10-word sentiment.\",\n",
    "                events=CaptureEventsTracing(),\n",
    "            )\n",
    "\n",
    "            print(\"\\n\\nASSISTANT (full):\", answer)\n",
    "\n",
    "            await client.delete_agent(agent_id)\n",
    "            logger.info(\"Agent %s deleted\", agent_id)\n",
    "\n",
    "        finally:\n",
    "            await client.close()\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77369cc7",
   "metadata": {},
   "source": [
    "You should see the traces of each event in the Tracing feature with Azure AI Foundry.\n",
    "\n",
    "<img alt=\"Traceability Example\" src=\"https://github.com/pablosalvador10/gbb-ai-agenticrag/blob/main/utils/images/tracebility.png\">\n",
    "\n",
    "The Tracing feature in Azure AI Foundry provides detailed visibility into every step of your agent’s execution—including tool calls, message deltas, and status updates—helping you debug, monitor, and optimize your workflows with ease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ai-agent-service-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
