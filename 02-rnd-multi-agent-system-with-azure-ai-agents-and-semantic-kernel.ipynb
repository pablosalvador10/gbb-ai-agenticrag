{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Use Case Overview**\n",
    "\n",
    "Imagine you’re part of an R&D team that needs to merge structured data (e.g., experimental results, market trends) from Microsoft Fabric with unstructured documents (e.g., research reports, engineering notes) in SharePoint, then validate these findings against external references (e.g., Bing) and a high-quality “ground truth” internal knowledge stores (e.g., Azure AI Search).\n",
    "\n",
    "This was a classic Retrieval-Augmented Generation (RAG) scenario—multiple data sources must be queried in real time and cross-checked for consistency. However, by leveraging Azure AI agent services (an agetic enterprise-ready microservices approach) alongside frameworks like Semantic Kernel, we can evolve beyond basic RAG into a mostly autonomous, agentic system. In this design, Agentic RAG and the Reflection Pattern enable each agent to iteratively refine its output until it’s confident in delivering a high-quality, validated answer—paving the way for intelligent automation that continually learns and improves.\n",
    "\n",
    "To summarize, you’re not only bringing data to the AI but also bringing AI to the data, thus maximizing the value of your knowledge stores. By leveraging state-of-the-art retrieval solutions like Azure AI Search, while also tapping sources such as SharePoint (unstructured data) and Fabric (structured data), you can harness your most valuable asset—data—to achieve new levels of insight and automation. \n",
    "\n",
    "**In this demo, we have two Azure AI Agents (extending beyond a single-agent architecture):**\n",
    "\n",
    "+ DataRetrievalAgent: Has access to Microsoft Fabric (for structured data) and SharePoint (for unstructured documents). Its job is to gather relevant internal data: for example, “failure rates of Material X in high-temperature tests,” or “engineering notes on prior tests.”\n",
    "\n",
    "- ValidationInsightsAgent Has access to Bing / Azure Cognitive Search for external references and can run a “reflection” or “validation” step. Its job is to cross-check what was returned by the first agent and highlight missing or conflicting information. ValidationInsightsAgent has access to highly curated knowledge sources (e.g., Azure AI Search) for validating the accuracy or truthfulness of the information it receives from DataRetrievalAgent.\n",
    "\n",
    "\n",
    "**Moving from a single-agent setup to a multi-agent system is now simpler than ever with Semantic Kernel. The general flow looks like this:**\n",
    "\n",
    "1. The user asks a question (e.g., “Retrieve historical failure rates for Material X in extreme temperatures and cross-check if new standards or conflicting data exist.”).\n",
    "2. The DataRetrievalAgent fetches structured data from Fabric (e.g., lab test results, analytics) and unstructured docs from SharePoint (e.g., research memos, engineering notes).\n",
    "3. The ValidationInsightsAgent then queries Bing/Azure Search to verify or supplement the results. Employ a reflection pattern, where it iterates over the combined results, looking for gaps or inconsistencies. If needed, it loops back to the DataRetrievalAgent for clarifications or additional data.\n",
    "\n",
    "Finally, the user receives a validated, summarized answer that merges internal data with external cross-checks. Thanks to the agents’ back-and-forth reflection.\n",
    "\n",
    "### **Why This Matters**\n",
    "\n",
    "+ **Reduced Manual Research**: Instead of manually sifting through multiple data silos and external search engines, the AI Agents automate data gathering and vetting.\n",
    "+ **Higher Confidence**: Validation ensures data accuracy and highlights missing pieces, improving R&D decision-making.\n",
    "+ **Enterprise-Grade Security**: Each agent can enforce On-Behalf-Of (OBO) authentication to protect sensitive data (e.g., only pulling data the user is authorized to see).\n",
    "In the Jupyter Notebook\n",
    "\n",
    "When you run the code in this Jupyter notebook:\n",
    "\n",
    "(TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime as pydatetime\n",
    "from typing import Any, List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "# Azure AI Projects\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "# semantic kernel\n",
    "from semantic_kernel.contents import AuthorRole\n",
    "from semantic_kernel.agents.azure_ai import AzureAIAgent, AzureAIAgentSettings\n",
    "from semantic_kernel.agents.open_ai.run_polling_options import RunPollingOptions\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# configure logging\n",
    "from utils.ml_logging import get_logger\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "# set the directory to the location of the script\n",
    "try:\n",
    "    target_directory = os.getenv(\"TARGET_DIRECTORY\", os.getcwd())  # Use environment variable if available\n",
    "    if os.path.exists(target_directory):\n",
    "        os.chdir(target_directory)\n",
    "        logging.info(f\"Successfully changed directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        logging.error(f\"Directory does not exist: {target_directory}\")\n",
    "except Exception as e:\n",
    "    logging.exception(f\"An error occurred while changing directory: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Client and Load Azure AI Foundry**\n",
    "\n",
    "Here, we initialize the Azure AI client using DefaultAzureCredential. This allows us to authenticate and connect to the Azure AI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AzureAIAgent.create_client(credential=DefaultAzureCredential())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Creating Azure AI Agents: DataRetrievalAgent**\n",
    "\n",
    "The DataRetrievalAgent is responsible for internal data retrieval, combining structured data from Microsoft Fabric with unstructured documents from SharePoint. This agent ensures that research teams can efficiently access critical R&D insights, such as historical failure rates, experimental results, and engineering notes—all while maintaining secure and authorized access controls.\n",
    "\n",
    "Agent Capabilities\n",
    "+ ✅ Structured Data Retrieval → Queries Microsoft Fabric for experiment logs, test results, and structured analytics.\n",
    "+ ✅ Unstructured Document Search → Fetches relevant reports, blueprints, and research notes from SharePoint.\n",
    "+ ✅ OBO Authentication → Uses On-Behalf-Of (OBO) authentication to ensure users can only access data they are permitted to view.\n",
    "\n",
    "For a detailed breakdown of how to create a single Azure AI Agent and configure its data (tools) connections, please refer to:\n",
    "📌 [01-single-agents-with-azure-ai-agents.ipynb](01-single-agents-with-azure-ai-agents.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import ServiceRequestError\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "\n",
    "async def get_connection_id(client: AIProjectClient, env_var: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Retrieves the connection object using a connection name stored in an environment variable.\n",
    "\n",
    "    Args:\n",
    "        client: The Azure AI Project client.\n",
    "        env_var (str): The environment variable holding the connection name.\n",
    "\n",
    "    Returns:\n",
    "        Connection object if found, otherwise raises an error.\n",
    "    \"\"\"\n",
    "    connection_name = os.getenv(env_var)\n",
    "    if not connection_name:\n",
    "        logger.error(f\"Missing environment variable: '{env_var}'\")\n",
    "        raise ValueError(f\"Environment variable '{env_var}' is required.\")\n",
    "\n",
    "    try:\n",
    "        connection = await client.connections.get(connection_name=connection_name)\n",
    "        logger.info(f\"Retrieved Connection ID for {env_var}: {connection.id}\")\n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to retrieve connection for {env_var}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:38:25,007 - micro - MainProcess - INFO     Retrieved Connection ID for TOOL_CONNECTION_NAME_SHAREPOINT: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-mukeshag-5297_ai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-5026/connections/ContosoAgentDemoSharepoint (2375541312.py:get_connection_id:22)\n",
      "INFO:micro:Retrieved Connection ID for TOOL_CONNECTION_NAME_SHAREPOINT: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-mukeshag-5297_ai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-5026/connections/ContosoAgentDemoSharepoint\n",
      "2025-03-20 15:38:25,010 - micro - MainProcess - INFO     Successfully created ToolSet with SharePoint and Fabric tools. (2239274105.py:<module>:21)\n",
      "INFO:micro:Successfully created ToolSet with SharePoint and Fabric tools.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import (\n",
    "    SharepointTool,\n",
    "    FabricTool,\n",
    "    ToolSet,\n",
    ")\n",
    "\n",
    "# Initialize Azure AI Agent settings\n",
    "dataretrievalagent_settings = AzureAIAgentSettings.create()\n",
    "\n",
    "toolset = ToolSet()\n",
    "\n",
    "try:\n",
    "    # Retrieve and add SharePoint Tool\n",
    "    sharepoint_connection = await get_connection_id(project_client, \"TOOL_CONNECTION_NAME_SHAREPOINT\")\n",
    "    toolset.add(SharepointTool(connection_id=sharepoint_connection.id))\n",
    "\n",
    "    # # Retrieve and add Fabric Tool\n",
    "    # fabric_connection = await get_connection_id(project_client, \"TOOL_CONNECTION_NAME_FABRIC\")\n",
    "    # toolset.add(FabricTool(connection_id=fabric_connection.id))\n",
    "\n",
    "    logger.info(\"Successfully created ToolSet with SharePoint and Fabric tools.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create ToolSet: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataRetrievalAgent Run ID: asst_BN7AvpIntZuA4s7nI2wQB4ri\n"
     ]
    }
   ],
   "source": [
    "dataretrievalagent_settings_definition = await project_client.agents.create_agent(\n",
    "    model=dataretrievalagent_settings.model_deployment_name,\n",
    "    name=\"DataRetrievalAgent\",\n",
    "    description=(\n",
    "        \"An AI agent specialized in retrieving and integrating data from two key internal sources: \"\n",
    "        \"Microsoft Fabric for structured metrics (e.g., performance data, experiment results, and analytics for Product A and Product B) \"\n",
    "        \"and SharePoint for unstructured documents (e.g., research papers, design reports, and qualitative insights).\"\n",
    "    ),\n",
    "    instructions=(\n",
    "        \"### Role & Objective\\n\"\n",
    "        \"You are a research-focused AI assistant responsible for retrieving and integrating data from internal enterprise sources. \"\n",
    "        \"Your responses must be precise, well-referenced, and relevant to the request.\\n\\n\"\n",
    "        \n",
    "        \"### Data Retrieval & Prioritization\\n\"\n",
    "        \"1. **Structured Data (Microsoft Fabric) and any questions related to clinical glucose monitoring studies:** \\n\"\n",
    "        \"   - Retrieve from Microsoft Fabric when the query involves numerical metrics, performance statistics, or structured analytics.\\n\"\n",
    "        \"   - Data is available to support comparisons of the accuracy and reliability of two glucose monitoring products (Product A and Product B). \"\n",
    "        \"This structured data evaluates performance across different glucose ranges and includes MARD percentages, accuracy within ±20 mg/dL/±20%, and the number of readings for each product.\\n\"\n",
    "        \"   - Example: clinical glucose monitoring studies between Product A or Product B.\\n\\n\"\n",
    "        \n",
    "        \"2. **Qualitative Data (SharePoint):** \\n\"\n",
    "        \"   - Retrieve from SharePoint when the request pertains to qualitative insights, research papers, design documents, or textual analysis.\\n\"\n",
    "        \"   - Example: Research reports, design blueprints, or qualitative R&D insights.\\n\\n\"\n",
    "        \n",
    "        \"3. **Integrated Queries:** \\n\"\n",
    "        \"   - If the query requires both structured and qualitative data, retrieve from both sources and integrate the results for a comprehensive response.\\n\"\n",
    "        \"   - Ensure clarity in presenting combined insights.\\n\\n\"\n",
    "        \n",
    "        \"### Response Quality\\n\"\n",
    "        \"1. **Accuracy & Relevance:** Always prioritize retrieving the most current and applicable data.\\n\"\n",
    "        \"2. **Clarity & Transparency:** Clearly indicate the data source(s) used and any limitations in the available information.\\n\"\n",
    "        \"3. **Professionalism:** Present findings in a structured and concise manner to facilitate decision-making.\\n\"\n",
    "    ),\n",
    "    toolset=toolset,\n",
    "    headers={\"x-ms-enable-preview\": \"true\"},\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    metadata={\n",
    "        \"use_case\": \"Internal Data Retrieval for R&D\",\n",
    "        \"data_source\": \"Microsoft Fabric (structured metrics) and SharePoint (research documents)\",\n",
    "        \"response_validation\": \"Ensure data accuracy and relevance by retrieving the most recent and applicable data.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# Print the agent's run ID (agent ID)\n",
    "print(f\"DataRetrievalAgent Run ID: {dataretrievalagent_settings_definition.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 **User:** How does Product A compare to Product B in terms of MARD percentage across different glucose ranges?What are the latest trends in R&D?\n",
      "\n",
      "🤖 **Agent:** ### MARD Percentage Comparison\n",
      "\n",
      "For Product A, the Mean Absolute Relative Difference (MARD) was reported as 8.7% (±0.4%) in trials under various glucose ranges【3:2†source】. Unfortunately, specific MARD data for Product B across different glucose ranges wasn't provided in the available documents. Further detailed studies would be needed to provide a direct comparison for Product B.\n",
      "\n",
      "### Latest Trends in R&D\n",
      "\n",
      "1. **Non-Invasive or Minimally Invasive Sensors**: R&D is exploring optical spectroscopy and radiofrequency monitoring for glucose measurement, aiming to reduce skin insertions and adhesive issues【5:1†source】.\n",
      "\n",
      "2. **Extended Sensor Lifespan**: Future CGM devices may last for several months, reducing the need for frequent replacements while maintaining accuracy【5:1†source】.\n",
      "\n",
      "3. **Enhanced Interoperability**: There is a push for devices (CGMs, insulin pens/pumps, and software) to work seamlessly together【5:1†source】.\n",
      "\n",
      "4. **AI-Driven Insights**: Combining CGM data with AI to provide personalized insulin management suggestions is an emerging area【5:4†source】.\n",
      "\n",
      "These trends indicate a move towards more user-friendly, integrated, and long-lasting glucose monitoring solutions.\n",
      "\n",
      "👤 **User:** What are the key features from Dexcom G7 CGM System?\n",
      "\n",
      "🤖 **Agent:** The Dexcom G7 CGM System features:\n",
      "\n",
      "1. **Integrated Design**: Combines the transmitter and sensor into one unit, applied with a simplified one-click applicator.\n",
      "\n",
      "2. **Reduced Size**: Significantly smaller than the previous Dexcom G6 sensor.\n",
      "\n",
      "3. **Age Compatibility**: Approved for use in individuals 2 years and older. For ages 7 and up, it's used on the back of the upper arm; for ages 2 to 6, it can be used on the upper buttocks as well.\n",
      "\n",
      "4. **Faster Warm-Up**: The G7 has a 30-minute warm-up time, compared to 2 hours with the G6【9:1†source】.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataretrievalagent = AzureAIAgent(\n",
    "    client=project_client,\n",
    "    definition=dataretrievalagent_settings_definition,\n",
    "    polling_options=RunPollingOptions(run_polling_interval=timedelta(seconds=1)),\n",
    ")\n",
    "\n",
    "thread = await project_client.agents.create_thread()\n",
    "\n",
    "USER_INPUTS = [\n",
    "    \"How does Product A compare to Product B in terms of MARD percentage across different glucose ranges?\"\n",
    "    \"What are the latest trends in R&D?\",\n",
    "    \"What are the key features from Dexcom G7 CGM System?\",\n",
    "   ]\n",
    "try:\n",
    "    for user_input in USER_INPUTS:\n",
    "        # Add the user input as a chat message\n",
    "        await dataretrievalagent.add_chat_message(thread_id=thread.id, message=user_input)\n",
    "        print(f\"👤 **User:** {user_input}\\n\")\n",
    "        \n",
    "        # Invoke the agent for the specified thread and stream the response\n",
    "        async for content in dataretrievalagent.invoke(thread_id=thread.id):\n",
    "            # Only print non-tool messages\n",
    "            if content.role != AuthorRole.TOOL:\n",
    "                print(f\"🤖 **Agent:** {content.content}\\n\")\n",
    "                \n",
    "except HttpResponseError as e:\n",
    "    try:\n",
    "        error_json = json.loads(e.response.content)\n",
    "        logging.error(f\"❌ **Error Message:** {error_json.get('Message')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(f\"❌ **Non-JSON Error Content:** {e.response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Creating Azure AI Agents: ValidationInsightsAgent**\n",
    "\n",
    "The ValidationInsightsAgent is designed to validate and cross-check the data retrieved by the DataRetrievalAgent. It accesses external references such as Bing and Azure Cognitive Search to verify and supplement the internal data. Additionally, it leverages highly curated knowledge sources (e.g., Azure AI Search) to ensure the accuracy and truthfulness of the information, using a reflection or validation step to highlight missing or conflicting details.\n",
    "\n",
    "Agent Capabilities:\n",
    "\n",
    "+ ✅ External Reference Verification → Queries Bing and Azure Cognitive Search for real-time validation.\n",
    "+ ✅ Reflection & Validation Step → Iteratively reviews and refines the information received from the DataRetrievalAgent.\n",
    "+ ✅ Curated Knowledge Validation → Uses Azure AI Search to confirm the accuracy and reliability of internal data.\n",
    "\n",
    "For a detailed breakdown of how to create a ValidationInsightsAgent and configure its external tools and connections, please refer to:\n",
    "📌 [01-single-agents-with-azure-ai-agents.ipynb](01-single-agents-with-azure-ai-agents.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:40:22,801 - micro - MainProcess - INFO     Retrieved Connection ID for TOOL_CONNECTION_NAME_BING: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-mukeshag-5297_ai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-5026/connections/agentsbinggrounding (2375541312.py:get_connection_id:22)\n",
      "INFO:micro:Retrieved Connection ID for TOOL_CONNECTION_NAME_BING: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-mukeshag-5297_ai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-5026/connections/agentsbinggrounding\n",
      "2025-03-20 15:40:22,808 - micro - MainProcess - INFO     Bing Grounding Tool added successfully. (1615353572.py:<module>:19)\n",
      "INFO:micro:Bing Grounding Tool added successfully.\n",
      "2025-03-20 15:40:22,813 - micro - MainProcess - INFO     Using PDF file path: c:\\Users\\pablosal\\Desktop\\azure-ai-agent-services-demo\\data\\product_data\\ProductATechncialArchitecture.pdf (1615353572.py:<module>:32)\n",
      "INFO:micro:Using PDF file path: c:\\Users\\pablosal\\Desktop\\azure-ai-agent-services-demo\\data\\product_data\\ProductATechncialArchitecture.pdf\n",
      "2025-03-20 15:40:35,954 - micro - MainProcess - INFO     Azure AI Search Tool added successfully. (1615353572.py:<module>:43)\n",
      "INFO:micro:Azure AI Search Tool added successfully.\n",
      "2025-03-20 15:40:35,959 - micro - MainProcess - INFO     Successfully created ToolSet with Bing and File Search tools. (1615353572.py:<module>:46)\n",
      "INFO:micro:Successfully created ToolSet with Bing and File Search tools.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import (\n",
    "    BingGroundingTool,\n",
    "    AzureAISearchTool,\n",
    "    FileSearchTool,\n",
    "    VectorStore,\n",
    "    OpenAIFile\n",
    ")\n",
    "\n",
    "# Initialize Azure AI Agent settings\n",
    "validationinsightagent_settings = AzureAIAgentSettings.create()\n",
    "\n",
    "# Create a ToolSet to manage tools\n",
    "toolset = ToolSet()\n",
    "\n",
    "try:\n",
    "    # Retrieve and add the Bing Grounding Tool\n",
    "    bing_connection = await get_connection_id(project_client, \"TOOL_CONNECTION_NAME_BING\")\n",
    "    toolset.add(BingGroundingTool(connection_id=bing_connection.id))\n",
    "    logger.info(\"Bing Grounding Tool added successfully.\")\n",
    "\n",
    "    # Retrieve and add the Azure AI Search Tool\n",
    "    # search_connection = await get_connection_id(project_client, \"TOOL_CONNECTION_NAME_SEARCH\")\n",
    "    # azure_ai_search_connection = AzureAISearchTool(\n",
    "    #     index_connection_id=search_connection.id,\n",
    "    #     index_name=\"ai-agentic-index\"\n",
    "    # )\n",
    "    # toolset.add(azure_ai_search_connection)\n",
    "    # logger.info(\"Azure AI Search Tool added successfully.\")\n",
    "\n",
    "    # Dynamically construct the PDF file path using os.path.join\n",
    "    pdf_file_path = os.path.join(target_directory, \"data\", \"product_data\", \"ProductATechncialArchitecture.pdf\")\n",
    "    logger.info(f\"Using PDF file path: {pdf_file_path}\")\n",
    "\n",
    "    file: OpenAIFile = await project_client.agents.upload_file_and_poll(file_path=pdf_file_path, purpose=\"assistants\")\n",
    "    vector_store: VectorStore = await project_client.agents.create_vector_store_and_poll(\n",
    "        file_ids=[file.id], name=\"my_vectorstore\"\n",
    "    )\n",
    "\n",
    "    # 2. Create file search tool with uploaded resources\n",
    "    file_search = FileSearchTool(vector_store_ids=[vector_store.id])\n",
    "\n",
    "    toolset.add(file_search)\n",
    "    logger.info(\"Azure AI Search Tool added successfully.\")\n",
    " \n",
    "\n",
    "    logger.info(\"Successfully created ToolSet with Bing and File Search tools.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create ToolSet: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValidationInsightsAgent Run ID: asst_cflIDuNZR0fOpTJp59zhhDdn\n"
     ]
    }
   ],
   "source": [
    "# Create or update a new Validation Insights Agent\n",
    "validationinsightsagent_definition = await project_client.agents.create_agent(\n",
    "    model=dataretrievalagent_settings.model_deployment_name,\n",
    "    name=\"ValidationInsightsAgent\",\n",
    "    description=(\n",
    "        \"An AI agent designed to validate and refine R&D insights by cross-checking \"\n",
    "        \"both internal enterprise data sources (e.g., file search vector store, SharePoint, Fabric) \"\n",
    "        \"and external public data (Bing, Azure AI Search). It uses a reflection pattern \"\n",
    "        \"to ensure response accuracy, consistency, and proper citations.\"\n",
    "    ),\n",
    "    instructions=(\n",
    "        \"### Role & Objective\\n\"\n",
    "        \"You are the 'Validation Insights' AI assistant, responsible for validating insights by \"\n",
    "        \"retrieving and cross-checking data from internal enterprise sources and external web searches. \"\n",
    "        \"Your responses must be accurate, well-referenced, and actionable.\"\n",
    "        \"\\n\\n\"\n",
    "        \"### Data Retrieval & Prioritization\\n\"\n",
    "        \"1. **Primary Data Source**: Always consult internal enterprise sources first (File Search Vector Store). \"\n",
    "        \"2. **External Validation**: If internal data is insufficient or requires verification, utilize Bing and Azure AI Search.\"\n",
    "        \"\\n\\n\"\n",
    "        \"### Reflection & Validation\\n\"\n",
    "        \"1. **Evaluate Consistency**: After retrieving data, compare sources to identify inconsistencies.\\n\"\n",
    "        \"2. **Perform Refinement**: If contradictions or gaps exist, conduct a second retrieval pass to ensure accuracy.\"\n",
    "        \"\\n\\n\"\n",
    "        \"### Response Quality\\n\"\n",
    "        \"1. **Accuracy & Transparency**: Always prioritize factual correctness and completeness in responses.\\n\"\n",
    "        \"2. **Citations & References**: Clearly cite the sources (internal or external) used in your response.\\n\"\n",
    "        \"3. **Clarity & Professionalism**: Deliver insights concisely and in a structured format. Be transparent if data validation is pending.\"\n",
    "    ),\n",
    "    toolset=toolset,\n",
    "    # Prefer the internal file search vector store by default\n",
    "    tool_resources=file_search.resources,\n",
    "    headers={\"x-ms-enable-preview\": \"true\"},\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    metadata={\n",
    "        \"use_case\": \"Cross-Validation and Insight Generation for R&D\",\n",
    "        \"data_source\": \"Internal (Fabric, SharePoint) and External (Bing, Azure AI Search)\",\n",
    "        \"response_validation\": (\n",
    "            \"Employ a reflection step to cross-check data accuracy \"\n",
    "            \"and provide clear citations in final responses.\"\n",
    "        )\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"ValidationInsightsAgent Run ID: {validationinsightsagent_definition.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 **User:** What are the characteristics and architecture of Product A?\n",
      "\n",
      "🤖 **Agent:** ### Characteristics and Architecture of Product A\n",
      "\n",
      "**Characteristics:**\n",
      "\n",
      "1. **Functionality**: Product A is an integrated continuous glucose monitoring (iCGM) system designed to replace traditional blood glucose monitoring by providing real-time interstitial glucose readings【4:0†source】.\n",
      "\n",
      "2. **Accuracy**: Demonstrates a high level of accuracy with a Mean Absolute Relative Difference (MARD) of approximately 8.5% to 9.2% during varying glucose conditions【4:1†source】.\n",
      "\n",
      "3. **Usability**: User-friendly with a mobile application that provides real-time data, customizable alerts, and compatibility with other diabetes management devices【4:4†source】.\n",
      "\n",
      "4. **Durability**: Engineered for long-term sensor wear (up to 10 days) with a hypoallergenic adhesive patch【4:4†source】.\n",
      "\n",
      "5. **Adaptability**: Includes a future-ready adaptive machine learning algorithm for personalized insulin dosing and lifestyle adjustments【4:2†source】.\n",
      "\n",
      "**Architecture:**\n",
      "\n",
      "1. **Sensor Module**:\n",
      "   - **Core Design**: Factory-calibrated electrochemical sensor with an enzyme-coated electrode for high sensitivity【4:0†source】.\n",
      "   - **Protective Features**: Micro-porous membrane to minimize interference and biofouling【4:0†source】.\n",
      "\n",
      "2. **Transmitter and Communication Layer**:\n",
      "   - **Data Transmission**: Low-power transmitter with Bluetooth connectivity using AES-256 encryption【4:4†source】.\n",
      "   - **Data Buffering**: Capable of storing 24 hours of data to ensure continuity during connection loss【4:4†source】.\n",
      "\n",
      "3. **Software and Analytics**:\n",
      "   - **Mobile Interface**: Provides glucose readings, trend analysis, and data sharing via a secure cloud platform【4:4†source】.\n",
      "   - **Cloud Management**: Real-time data upload with advanced analytics for comprehensive glucose management【4:4†source】.\n",
      "\n",
      "Product A combines advanced sensor technology with robust data handling and user-friendly interfaces, supporting integration with third-party systems to enhance diabetes management【4:0†source】【4:4†source】.\n",
      "\n",
      "👤 **User:** What are the key features from Dexcom G7 CGM System?\n",
      "\n",
      "🤖 **Agent:** ### Key Features of the Dexcom G7 CGM System\n",
      "\n",
      "1. **Size and Design**: The G7 is 60% smaller than previous models, offering a discreet, all-in-one wearable design suitable for upper arm placement【10:0†source】.\n",
      "\n",
      "2. **Warm-up Time**: It features a 30-minute sensor warm-up, the fastest among CGM systems【10:0†source】.\n",
      "\n",
      "3. **Accuracy**: The system provides industry-leading accuracy with a Mean Absolute Relative Difference (MARD) of 8.2%【10:0†source】.\n",
      "\n",
      "4. **Ease of Use**: Designed for simplicity, it does not require fingersticks or calibration【10:0†source】.\n",
      "\n",
      "5. **Alerts and Notifications**: Includes customizable alerts, such as an \"Urgent Low Soon\" predictive alert【10:0†source】.\n",
      "\n",
      "6. **Integration and Connectivity**: Capable of integration with various devices and platforms, including Apple Watch and Garmin【10:0†source】.\n",
      "\n",
      "7. **Water Resistance**: The sensor is waterproof, supporting active lifestyles【10:0†source】.\n",
      "\n",
      "8. **Data Sharing**: Allows remote monitoring and data sharing with up to 10 people【10:0†source】.\n",
      "\n",
      "These features make the Dexcom G7 a powerful tool for managing diabetes with real-time glucose monitoring.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation_agent = AzureAIAgent(\n",
    "    client=project_client,\n",
    "    definition=validationinsightsagent_definition,\n",
    "    polling_options=RunPollingOptions(run_polling_interval=timedelta(seconds=1)),\n",
    ")\n",
    "\n",
    "# Create a conversation thread for the agent\n",
    "thread = await project_client.agents.create_thread()\n",
    "\n",
    "# Define a list of user inputs designed to trigger both internal search (e.g., product architecture) \n",
    "# and external market trend validation.\n",
    "USER_INPUTS = [\n",
    "    \"What are the characteristics and architecture of Product A?\",\n",
    "    \"What are the key features from Dexcom G7 CGM System?\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    for user_input in USER_INPUTS:\n",
    "        # Add the user input as a chat message\n",
    "        await validation_agent.add_chat_message(thread_id=thread.id, message=user_input)\n",
    "        print(f\"👤 **User:** {user_input}\\n\")\n",
    "        \n",
    "        # Invoke the agent for the specified thread and stream the response\n",
    "        async for content in validation_agent.invoke(thread_id=thread.id):\n",
    "            # Only print non-tool messages\n",
    "            if content.role != AuthorRole.TOOL:\n",
    "                print(f\"🤖 **Agent:** {content.content}\\n\")\n",
    "                \n",
    "except HttpResponseError as e:\n",
    "    try:\n",
    "        error_json = json.loads(e.response.content)\n",
    "        logger.error(f\"❌ **Error Message:** {error_json.get('Message')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"❌ **Non-JSON Error Content:** {e.response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Creating Multi Agent System**\n",
    "\n",
    "The following sample demonstrates how to create an OpenAI assistant using either Azure OpenAI or OpenAI, a chat completion agent and have them participate in a group chat to work towards the user's requirement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import AgentGroupChat\n",
    "from semantic_kernel.agents.azure_ai import AzureAIAgent\n",
    "from semantic_kernel.agents.strategies import TerminationStrategy, KernelFunctionSelectionStrategy\n",
    "from semantic_kernel.functions import KernelFunctionFromPrompt\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 2) A Custom Termination Strategy\n",
    "###############################################################################\n",
    "class ApprovalTerminationStrategy(TerminationStrategy):\n",
    "    \"\"\"\n",
    "    Ends the conversation if the Evaluator agent's last output includes the word 'approved'.\n",
    "    \"\"\"\n",
    "    def __init__(self, agents, maximum_iterations=10):\n",
    "        super().__init__(maximum_iterations=maximum_iterations)\n",
    "        self.agents = agents\n",
    "\n",
    "    async def should_agent_terminate(self, agent, history) -> bool:\n",
    "        # We assume the Evaluator is among self.agents\n",
    "        # If the final content from the Evaluator includes 'approved', we end\n",
    "        last_msg = history[-1]\n",
    "        return (last_msg.name in [a.name for a in self.agents]) and (\"approved\" in last_msg.content.lower())\n",
    "\n",
    "###############################################################################\n",
    "# 3) Creating a Kernel for the Selection Function\n",
    "###############################################################################\n",
    "def _create_kernel_with_chat_completion(service_id: str) -> Kernel:\n",
    "    \"\"\"\n",
    "    Creates a Semantic Kernel instance with an Azure OpenAI chat completion service.\n",
    "    Make sure you have environment variables for your Azure OpenAI keys/endpoint.\n",
    "    \"\"\"\n",
    "    from semantic_kernel import Kernel\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    kernel = Kernel()\n",
    "    # Retrieve environment vars (adjust to your naming)\n",
    "    AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "    AZURE_OPENAI_API_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "    AZURE_AOAI_CHAT_MODEL_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_ID\")  \n",
    "\n",
    "    # Register an Azure Chat Completion service in the kernel\n",
    "    kernel.add_service(\n",
    "        service=AzureChatCompletion(\n",
    "            deployment_name=AZURE_AOAI_CHAT_MODEL_DEPLOYMENT,\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            endpoint=AZURE_OPENAI_API_ENDPOINT,\n",
    "            api_version=AZURE_OPENAI_API_VERSION,\n",
    "        )\n",
    "    )\n",
    "    return kernel\n",
    "\n",
    "###############################################################################\n",
    "# 4) Example LLM Prompt for Multi-Agent Turn Selection\n",
    "###############################################################################\n",
    "RETRIEVER_NAME = \"ValidationInsightsAgent\"\n",
    "EVALUATOR_NAME = \"DataRetrievalAgent\"\n",
    "\n",
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\",\n",
    "    prompt=f\"\"\"\n",
    "Determine which participant takes the next turn in a conversation based on the most recent participant.\n",
    "State only the name of the participant to take the next turn.\n",
    "No participant should take more than one turn in a row.\n",
    "\n",
    "Choose only from these participants:\n",
    "- {RETRIEVER_NAME}\n",
    "- {EVALUATOR_NAME}\n",
    "\n",
    "Always follow these rules when selecting the next participant:\n",
    "- {RETRIEVER_NAME} retrieving the document or relevant data the query.\n",
    "- After {RETRIEVER_NAME}, it is {EVALUATOR_NAME}'s turn to evaluate the content.\n",
    "- After {EVALUATOR_NAME}, the workflow may terminate if 'approved'.\n",
    "\n",
    "History:\n",
    "{{{{$history}}}}\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 5) Utility Logging For Agent Interaction\n",
    "###############################################################################\n",
    "def log_agent_invocation(agent_name: str, role: str, input_data: str, output_data: str):\n",
    "    trace_data = {\n",
    "        \"agent_name\": agent_name,\n",
    "        \"role\": role,\n",
    "        \"input\": input_data,\n",
    "        \"output\": output_data,\n",
    "    }\n",
    "    logger.info(\"AGENT INVOCATION:\\n\" + json.dumps(trace_data, indent=4))\n",
    "\n",
    "###############################################################################\n",
    "# 6) Main Async Function\n",
    "###############################################################################\n",
    "async def main():\n",
    "    # 2. Initialize the credential & AzureAIAgent client\n",
    "    async with (\n",
    "        DefaultAzureCredential() as creds,\n",
    "        AzureAIAgent.create_client(credential=creds) as client,\n",
    "    ):\n",
    "        # Pre-existing Azure AI Agents (IDs from your environment)\n",
    "        ValidationInsightsAgentID = \"asst_cflIDuNZR0fOpTJp59zhhDdn\"\n",
    "        DataRetrievalAgentID = \"asst_BN7AvpIntZuA4s7nI2wQB4ri\"\n",
    "\n",
    "        # 3. Retrieve each agent definition from your Azure AI Agent Service\n",
    "        #    Assume the Formulator & Evaluator are the same agent or different? \n",
    "        #    Below, just demonstrating you might have 2 definitions for 3 roles.\n",
    "        dataretrieval_def = await client.agents.get_agent(agent_id=DataRetrievalAgentID)\n",
    "        validation_def = await client.agents.get_agent(agent_id=ValidationInsightsAgentID)\n",
    "\n",
    "        # 4. Build SK Agents from these definitions\n",
    "        agent_retriever = AzureAIAgent(client=client, definition=dataretrieval_def)\n",
    "        agent_evaluator = AzureAIAgent(client=client, definition=validation_def)\n",
    "\n",
    "        # 5. Setup the multi-agent chat\n",
    "        chat = AgentGroupChat(\n",
    "            agents=[agent_retriever, agent_evaluator],\n",
    "            termination_strategy=ApprovalTerminationStrategy(\n",
    "                maximum_iterations=10,\n",
    "                agents=[agent_evaluator],  # The Evaluator decides final approval\n",
    "            ),\n",
    "            selection_strategy=KernelFunctionSelectionStrategy(\n",
    "                function=selection_function,\n",
    "                kernel=_create_kernel_with_chat_completion(\"selection\"),\n",
    "                # We parse the output of the LLM prompt to choose next agent\n",
    "                result_parser=lambda result: str(result.value[0]) if result.value else EVALUATOR_NAME,\n",
    "                agent_variable_name=\"agents\",   # the variable in the prompt\n",
    "                history_variable_name=\"history\", # the variable in the prompt\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Example user system or user message\n",
    "        system_message = \"\"\"\n",
    "        You are orchestrating a multi-step R&D conversation between two roles: \n",
    "        1) Retriever – gathers internal data from Fabric/SharePoint and external references from Bing/Azure Search.\n",
    "        2) Evaluator – cross-validates the retrieved data, identifies missing insights, and decides if it is 'approved' or if more data is needed.\n",
    "\n",
    "        **Demo Flow: AI-Powered R&D and Product Design**\n",
    "        1. A researcher initiates a query for internal experiment data and external market trends to refine a new product design.\n",
    "        2. Retriever queries Fabric AI Skill for structured results (e.g., experiment data), and SharePoint for related research papers, engineering reports, and design notes.\n",
    "        3. Evaluator checks the alignment between internal test results and external market or regulatory feedback. Identifies any conflicting standards or data gaps. If needed, it reruns queries for additional sources.\n",
    "        4. The system compiles an AI-generated report summarizing key findings, highlighting risk factors, data gaps, and actionable recommendations.\n",
    "        5. The researcher can ask follow-up questions about materials, regulatory risks, or design improvements. \n",
    "\n",
    "        The user can keep asking questions until the Evaluator decides it is 'approved' (final answer) or more data is required.\n",
    "        \"\"\"\n",
    "        await chat.add_chat_message(message=system_message)\n",
    "        logger.info(f\"System Setup: {system_message}\")\n",
    "\n",
    "        # Updated user message introducing the high-level request\n",
    "        user_message = \"\"\"\n",
    "        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\n",
    "        \"\"\"\n",
    "        await chat.add_chat_message(message=user_message)\n",
    "        logger.info(f\"User Input: {user_message}\")\n",
    "\n",
    "        # 6. Real-time streaming of conversation\n",
    "        try:\n",
    "            last_input = user_message\n",
    "            async for content in chat.invoke():\n",
    "                agent_name = content.name or \"Unknown\"\n",
    "                agent_role = content.role.name\n",
    "                agent_output = content.content\n",
    "\n",
    "                # Log invocation\n",
    "                log_agent_invocation(agent_name, agent_role, last_input, agent_output)\n",
    "\n",
    "                # Print\n",
    "                print(f\"{agent_role} - {agent_name}: {agent_output}\")\n",
    "\n",
    "                last_input = agent_output\n",
    "\n",
    "            logger.info(f\"Workflow Complete? {chat.is_complete}\")\n",
    "\n",
    "        except HttpResponseError as err:\n",
    "            logger.error(f\"Error while streaming conversation: {err}\")\n",
    "\n",
    "        finally:\n",
    "            # 7. Optionally reset or cleanup if ephemeral\n",
    "            await chat.reset()\n",
    "            # If you'd like to delete ephemeral agent definitions, do so here\n",
    "            # e.g., await client.agents.delete_agent(DataRetrievalAgentID)\n",
    "            #       await client.agents.delete_agent(ValidationInsightsAgentID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:43:35,634 - micro - MainProcess - INFO     System Setup: \n",
      "        You are orchestrating a multi-step R&D conversation between two roles: \n",
      "        1) Retriever – gathers internal data from Fabric/SharePoint and external references from Bing/Azure Search.\n",
      "        2) Evaluator – cross-validates the retrieved data, identifies missing insights, and decides if it is 'approved' or if more data is needed.\n",
      "\n",
      "        **Demo Flow: AI-Powered R&D and Product Design**\n",
      "        1. A researcher initiates a query for internal experiment data and external market trends to refine a new product design.\n",
      "        2. Retriever queries Fabric AI Skill for structured results (e.g., experiment data), and SharePoint for related research papers, engineering reports, and design notes.\n",
      "        3. Evaluator checks the alignment between internal test results and external market or regulatory feedback. Identifies any conflicting standards or data gaps. If needed, it reruns queries for additional sources.\n",
      "        4. The system compiles an AI-generated report summarizing key findings, highlighting risk factors, data gaps, and actionable recommendations.\n",
      "        5. The researcher can ask follow-up questions about materials, regulatory risks, or design improvements. \n",
      "\n",
      "        The user can keep asking questions until the Evaluator decides it is 'approved' (final answer) or more data is required.\n",
      "         (1936533635.py:main:156)\n",
      "INFO:micro:System Setup: \n",
      "        You are orchestrating a multi-step R&D conversation between two roles: \n",
      "        1) Retriever – gathers internal data from Fabric/SharePoint and external references from Bing/Azure Search.\n",
      "        2) Evaluator – cross-validates the retrieved data, identifies missing insights, and decides if it is 'approved' or if more data is needed.\n",
      "\n",
      "        **Demo Flow: AI-Powered R&D and Product Design**\n",
      "        1. A researcher initiates a query for internal experiment data and external market trends to refine a new product design.\n",
      "        2. Retriever queries Fabric AI Skill for structured results (e.g., experiment data), and SharePoint for related research papers, engineering reports, and design notes.\n",
      "        3. Evaluator checks the alignment between internal test results and external market or regulatory feedback. Identifies any conflicting standards or data gaps. If needed, it reruns queries for additional sources.\n",
      "        4. The system compiles an AI-generated report summarizing key findings, highlighting risk factors, data gaps, and actionable recommendations.\n",
      "        5. The researcher can ask follow-up questions about materials, regulatory risks, or design improvements. \n",
      "\n",
      "        The user can keep asking questions until the Evaluator decides it is 'approved' (final answer) or more data is required.\n",
      "        \n",
      "2025-03-20 15:43:35,638 - micro - MainProcess - INFO     User Input: \n",
      "        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\n",
      "         (1936533635.py:main:163)\n",
      "INFO:micro:User Input: \n",
      "        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\n",
      "        \n",
      "2025-03-20 15:44:40,165 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"\\n        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\\n        \",\n",
      "    \"output\": \"### Characteristics and Architecture of Product A\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system. Here are its key characteristics and architecture:\\n\\n1. **Sensor Module:**\\n   - **Sensor Core:** Factory-calibrated electrochemical sensor with high sensitivity, measuring interstitial glucose every 5 minutes.\\n   - **Protective Membrane:** Biocompatible membrane minimizes interference, ensuring signal stability.\\n   - **Adhesive and Patch:** Hypoallergenic, durable for up to 10 days, with overpatch for durability during activities\\u30105:0\\u2020source\\u3011.\\n\\n2. **Transmitter and Communication Layer:**\\n   - **Transmitter:** Low-power, battery-powered, converting signals every 5 minutes, with robust battery life.\\n   - **Connectivity:** Secure Bluetooth, AES-256 encryption, with data buffering for up to 24 hours\\u30105:4\\u2020source\\u3011.\\n\\n3. **Software and Analytics:**\\n   - **Mobile Application:** Real-time data display, trend analysis, and customizable alerts.\\n   - **Cloud-Based Management:** Data uploaded to a cloud portal for advanced analytics and personalized insights\\u30105:4\\u2020source\\u3011.\\n\\n### Market Research and Competitor Analysis\\n\\nFor external market trends, I will need to conduct a web search. As for internal competitor analysis, I will check if there is more data available on other products.\\n\\nLet me search for external market trends and verify any additional internal competitor analysis data. Please hold on.\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"\\n        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\\n        \",\n",
      "    \"output\": \"### Characteristics and Architecture of Product A\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system. Here are its key characteristics and architecture:\\n\\n1. **Sensor Module:**\\n   - **Sensor Core:** Factory-calibrated electrochemical sensor with high sensitivity, measuring interstitial glucose every 5 minutes.\\n   - **Protective Membrane:** Biocompatible membrane minimizes interference, ensuring signal stability.\\n   - **Adhesive and Patch:** Hypoallergenic, durable for up to 10 days, with overpatch for durability during activities\\u30105:0\\u2020source\\u3011.\\n\\n2. **Transmitter and Communication Layer:**\\n   - **Transmitter:** Low-power, battery-powered, converting signals every 5 minutes, with robust battery life.\\n   - **Connectivity:** Secure Bluetooth, AES-256 encryption, with data buffering for up to 24 hours\\u30105:4\\u2020source\\u3011.\\n\\n3. **Software and Analytics:**\\n   - **Mobile Application:** Real-time data display, trend analysis, and customizable alerts.\\n   - **Cloud-Based Management:** Data uploaded to a cloud portal for advanced analytics and personalized insights\\u30105:4\\u2020source\\u3011.\\n\\n### Market Research and Competitor Analysis\\n\\nFor external market trends, I will need to conduct a web search. As for internal competitor analysis, I will check if there is more data available on other products.\\n\\nLet me search for external market trends and verify any additional internal competitor analysis data. Please hold on.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - ValidationInsightsAgent: ### Characteristics and Architecture of Product A\n",
      "\n",
      "**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system. Here are its key characteristics and architecture:\n",
      "\n",
      "1. **Sensor Module:**\n",
      "   - **Sensor Core:** Factory-calibrated electrochemical sensor with high sensitivity, measuring interstitial glucose every 5 minutes.\n",
      "   - **Protective Membrane:** Biocompatible membrane minimizes interference, ensuring signal stability.\n",
      "   - **Adhesive and Patch:** Hypoallergenic, durable for up to 10 days, with overpatch for durability during activities【5:0†source】.\n",
      "\n",
      "2. **Transmitter and Communication Layer:**\n",
      "   - **Transmitter:** Low-power, battery-powered, converting signals every 5 minutes, with robust battery life.\n",
      "   - **Connectivity:** Secure Bluetooth, AES-256 encryption, with data buffering for up to 24 hours【5:4†source】.\n",
      "\n",
      "3. **Software and Analytics:**\n",
      "   - **Mobile Application:** Real-time data display, trend analysis, and customizable alerts.\n",
      "   - **Cloud-Based Management:** Data uploaded to a cloud portal for advanced analytics and personalized insights【5:4†source】.\n",
      "\n",
      "### Market Research and Competitor Analysis\n",
      "\n",
      "For external market trends, I will need to conduct a web search. As for internal competitor analysis, I will check if there is more data available on other products.\n",
      "\n",
      "Let me search for external market trends and verify any additional internal competitor analysis data. Please hold on.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:44:40,554 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"### Characteristics and Architecture of Product A\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system. Here are its key characteristics and architecture:\\n\\n1. **Sensor Module:**\\n   - **Sensor Core:** Factory-calibrated electrochemical sensor with high sensitivity, measuring interstitial glucose every 5 minutes.\\n   - **Protective Membrane:** Biocompatible membrane minimizes interference, ensuring signal stability.\\n   - **Adhesive and Patch:** Hypoallergenic, durable for up to 10 days, with overpatch for durability during activities\\u30105:0\\u2020source\\u3011.\\n\\n2. **Transmitter and Communication Layer:**\\n   - **Transmitter:** Low-power, battery-powered, converting signals every 5 minutes, with robust battery life.\\n   - **Connectivity:** Secure Bluetooth, AES-256 encryption, with data buffering for up to 24 hours\\u30105:4\\u2020source\\u3011.\\n\\n3. **Software and Analytics:**\\n   - **Mobile Application:** Real-time data display, trend analysis, and customizable alerts.\\n   - **Cloud-Based Management:** Data uploaded to a cloud portal for advanced analytics and personalized insights\\u30105:4\\u2020source\\u3011.\\n\\n### Market Research and Competitor Analysis\\n\\nFor external market trends, I will need to conduct a web search. As for internal competitor analysis, I will check if there is more data available on other products.\\n\\nLet me search for external market trends and verify any additional internal competitor analysis data. Please hold on.\",\n",
      "    \"output\": \"### Characteristics and Architecture of Product A\\n\\n**Product A** is a sophisticated integrated continuous glucose monitoring (iCGM) system with the following features:\\n\\n1. **Sensor Module:**\\n   - **Sensor Core:** Factory-calibrated electrochemical sensor for real-time glucose measurement.\\n   - **Protective Membrane:** Biocompatible to reduce interference.\\n   - **Adhesive and Patch:** Hypoallergenic and durable for up to 10 days\\u30105:0\\u2020source\\u3011.\\n\\n2. **Transmitter and Communication Layer:**\\n   - **Transmitter:** Low-power, battery-powered for signal conversion.\\n   - **Connectivity:** Secure Bluetooth with AES-256 encryption\\u30105:4\\u2020source\\u3011.\\n\\n3. **Software and Analytics:**\\n   - **Mobile Application:** Real-time data and alerts.\\n   - **Cloud-Based Management:** Advanced analytics and personalized insights\\u30105:4\\u2020source\\u3011.\\n\\n### Internal Competitor Analysis\\n\\nThe company has conducted competitor analysis on several products, though specific names are not detailed in the provided files. The focus has been on ensuring Product A meets high standards of accuracy and user satisfaction through rigorous clinical trials\\u30108:3\\u2020source\\u3011.\\n\\n### External Market Research\\n\\nTo gather insights on similar products in the market, I would need to conduct a web search. If you would like me to proceed with this, please confirm.\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"### Characteristics and Architecture of Product A\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system. Here are its key characteristics and architecture:\\n\\n1. **Sensor Module:**\\n   - **Sensor Core:** Factory-calibrated electrochemical sensor with high sensitivity, measuring interstitial glucose every 5 minutes.\\n   - **Protective Membrane:** Biocompatible membrane minimizes interference, ensuring signal stability.\\n   - **Adhesive and Patch:** Hypoallergenic, durable for up to 10 days, with overpatch for durability during activities\\u30105:0\\u2020source\\u3011.\\n\\n2. **Transmitter and Communication Layer:**\\n   - **Transmitter:** Low-power, battery-powered, converting signals every 5 minutes, with robust battery life.\\n   - **Connectivity:** Secure Bluetooth, AES-256 encryption, with data buffering for up to 24 hours\\u30105:4\\u2020source\\u3011.\\n\\n3. **Software and Analytics:**\\n   - **Mobile Application:** Real-time data display, trend analysis, and customizable alerts.\\n   - **Cloud-Based Management:** Data uploaded to a cloud portal for advanced analytics and personalized insights\\u30105:4\\u2020source\\u3011.\\n\\n### Market Research and Competitor Analysis\\n\\nFor external market trends, I will need to conduct a web search. As for internal competitor analysis, I will check if there is more data available on other products.\\n\\nLet me search for external market trends and verify any additional internal competitor analysis data. Please hold on.\",\n",
      "    \"output\": \"### Characteristics and Architecture of Product A\\n\\n**Product A** is a sophisticated integrated continuous glucose monitoring (iCGM) system with the following features:\\n\\n1. **Sensor Module:**\\n   - **Sensor Core:** Factory-calibrated electrochemical sensor for real-time glucose measurement.\\n   - **Protective Membrane:** Biocompatible to reduce interference.\\n   - **Adhesive and Patch:** Hypoallergenic and durable for up to 10 days\\u30105:0\\u2020source\\u3011.\\n\\n2. **Transmitter and Communication Layer:**\\n   - **Transmitter:** Low-power, battery-powered for signal conversion.\\n   - **Connectivity:** Secure Bluetooth with AES-256 encryption\\u30105:4\\u2020source\\u3011.\\n\\n3. **Software and Analytics:**\\n   - **Mobile Application:** Real-time data and alerts.\\n   - **Cloud-Based Management:** Advanced analytics and personalized insights\\u30105:4\\u2020source\\u3011.\\n\\n### Internal Competitor Analysis\\n\\nThe company has conducted competitor analysis on several products, though specific names are not detailed in the provided files. The focus has been on ensuring Product A meets high standards of accuracy and user satisfaction through rigorous clinical trials\\u30108:3\\u2020source\\u3011.\\n\\n### External Market Research\\n\\nTo gather insights on similar products in the market, I would need to conduct a web search. If you would like me to proceed with this, please confirm.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - ValidationInsightsAgent: ### Characteristics and Architecture of Product A\n",
      "\n",
      "**Product A** is a sophisticated integrated continuous glucose monitoring (iCGM) system with the following features:\n",
      "\n",
      "1. **Sensor Module:**\n",
      "   - **Sensor Core:** Factory-calibrated electrochemical sensor for real-time glucose measurement.\n",
      "   - **Protective Membrane:** Biocompatible to reduce interference.\n",
      "   - **Adhesive and Patch:** Hypoallergenic and durable for up to 10 days【5:0†source】.\n",
      "\n",
      "2. **Transmitter and Communication Layer:**\n",
      "   - **Transmitter:** Low-power, battery-powered for signal conversion.\n",
      "   - **Connectivity:** Secure Bluetooth with AES-256 encryption【5:4†source】.\n",
      "\n",
      "3. **Software and Analytics:**\n",
      "   - **Mobile Application:** Real-time data and alerts.\n",
      "   - **Cloud-Based Management:** Advanced analytics and personalized insights【5:4†source】.\n",
      "\n",
      "### Internal Competitor Analysis\n",
      "\n",
      "The company has conducted competitor analysis on several products, though specific names are not detailed in the provided files. The focus has been on ensuring Product A meets high standards of accuracy and user satisfaction through rigorous clinical trials【8:3†source】.\n",
      "\n",
      "### External Market Research\n",
      "\n",
      "To gather insights on similar products in the market, I would need to conduct a web search. If you would like me to proceed with this, please confirm.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:44:48,734 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"DataRetrievalAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"### Characteristics and Architecture of Product A\\n\\n**Product A** is a sophisticated integrated continuous glucose monitoring (iCGM) system with the following features:\\n\\n1. **Sensor Module:**\\n   - **Sensor Core:** Factory-calibrated electrochemical sensor for real-time glucose measurement.\\n   - **Protective Membrane:** Biocompatible to reduce interference.\\n   - **Adhesive and Patch:** Hypoallergenic and durable for up to 10 days\\u30105:0\\u2020source\\u3011.\\n\\n2. **Transmitter and Communication Layer:**\\n   - **Transmitter:** Low-power, battery-powered for signal conversion.\\n   - **Connectivity:** Secure Bluetooth with AES-256 encryption\\u30105:4\\u2020source\\u3011.\\n\\n3. **Software and Analytics:**\\n   - **Mobile Application:** Real-time data and alerts.\\n   - **Cloud-Based Management:** Advanced analytics and personalized insights\\u30105:4\\u2020source\\u3011.\\n\\n### Internal Competitor Analysis\\n\\nThe company has conducted competitor analysis on several products, though specific names are not detailed in the provided files. The focus has been on ensuring Product A meets high standards of accuracy and user satisfaction through rigorous clinical trials\\u30108:3\\u2020source\\u3011.\\n\\n### External Market Research\\n\\nTo gather insights on similar products in the market, I would need to conduct a web search. If you would like me to proceed with this, please confirm.\",\n",
      "    \"output\": \"Would you like me to perform an external market search for similar products?\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"DataRetrievalAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"### Characteristics and Architecture of Product A\\n\\n**Product A** is a sophisticated integrated continuous glucose monitoring (iCGM) system with the following features:\\n\\n1. **Sensor Module:**\\n   - **Sensor Core:** Factory-calibrated electrochemical sensor for real-time glucose measurement.\\n   - **Protective Membrane:** Biocompatible to reduce interference.\\n   - **Adhesive and Patch:** Hypoallergenic and durable for up to 10 days\\u30105:0\\u2020source\\u3011.\\n\\n2. **Transmitter and Communication Layer:**\\n   - **Transmitter:** Low-power, battery-powered for signal conversion.\\n   - **Connectivity:** Secure Bluetooth with AES-256 encryption\\u30105:4\\u2020source\\u3011.\\n\\n3. **Software and Analytics:**\\n   - **Mobile Application:** Real-time data and alerts.\\n   - **Cloud-Based Management:** Advanced analytics and personalized insights\\u30105:4\\u2020source\\u3011.\\n\\n### Internal Competitor Analysis\\n\\nThe company has conducted competitor analysis on several products, though specific names are not detailed in the provided files. The focus has been on ensuring Product A meets high standards of accuracy and user satisfaction through rigorous clinical trials\\u30108:3\\u2020source\\u3011.\\n\\n### External Market Research\\n\\nTo gather insights on similar products in the market, I would need to conduct a web search. If you would like me to proceed with this, please confirm.\",\n",
      "    \"output\": \"Would you like me to perform an external market search for similar products?\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - DataRetrievalAgent: Would you like me to perform an external market search for similar products?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:45:01,745 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"Would you like me to perform an external market search for similar products?\",\n",
      "    \"output\": \"### External Market Trends for Continuous Glucose Monitoring Systems\\n\\n1. **Market Growth**: The global continuous glucose monitoring (CGM) systems market is projected to reach USD 17 billion by 2029, with a CAGR of 15.1%\\u301012:2\\u2020source\\u3011.\\n\\n2. **Key Drivers**: Growth is driven by the increasing prevalence of diabetes, demand for minimally invasive devices, and technological advancements, including AI integration and non-invasive monitoring solutions\\u301012:0\\u2020source\\u3011\\u301012:2\\u2020source\\u3011.\\n\\n3. **Product Innovations**: Recent trends highlight the integration with smart devices, wearable technology, and the rise of telemedicine and remote healthcare solutions\\u301012:2\\u2020source\\u3011.\\n\\n4. **Competitive Landscape**: Companies like Abbott, Medtronic, and Dexcom are leading in this sector, focusing on advanced features and improved user experience\\u301012:1\\u2020source\\u3011.\\n\\nThis analysis provides a comprehensive view of the CGM market, highlighting growth opportunities and technological innovations. If further details are needed, feel free to ask.\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"Would you like me to perform an external market search for similar products?\",\n",
      "    \"output\": \"### External Market Trends for Continuous Glucose Monitoring Systems\\n\\n1. **Market Growth**: The global continuous glucose monitoring (CGM) systems market is projected to reach USD 17 billion by 2029, with a CAGR of 15.1%\\u301012:2\\u2020source\\u3011.\\n\\n2. **Key Drivers**: Growth is driven by the increasing prevalence of diabetes, demand for minimally invasive devices, and technological advancements, including AI integration and non-invasive monitoring solutions\\u301012:0\\u2020source\\u3011\\u301012:2\\u2020source\\u3011.\\n\\n3. **Product Innovations**: Recent trends highlight the integration with smart devices, wearable technology, and the rise of telemedicine and remote healthcare solutions\\u301012:2\\u2020source\\u3011.\\n\\n4. **Competitive Landscape**: Companies like Abbott, Medtronic, and Dexcom are leading in this sector, focusing on advanced features and improved user experience\\u301012:1\\u2020source\\u3011.\\n\\nThis analysis provides a comprehensive view of the CGM market, highlighting growth opportunities and technological innovations. If further details are needed, feel free to ask.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - ValidationInsightsAgent: ### External Market Trends for Continuous Glucose Monitoring Systems\n",
      "\n",
      "1. **Market Growth**: The global continuous glucose monitoring (CGM) systems market is projected to reach USD 17 billion by 2029, with a CAGR of 15.1%【12:2†source】.\n",
      "\n",
      "2. **Key Drivers**: Growth is driven by the increasing prevalence of diabetes, demand for minimally invasive devices, and technological advancements, including AI integration and non-invasive monitoring solutions【12:0†source】【12:2†source】.\n",
      "\n",
      "3. **Product Innovations**: Recent trends highlight the integration with smart devices, wearable technology, and the rise of telemedicine and remote healthcare solutions【12:2†source】.\n",
      "\n",
      "4. **Competitive Landscape**: Companies like Abbott, Medtronic, and Dexcom are leading in this sector, focusing on advanced features and improved user experience【12:1†source】.\n",
      "\n",
      "This analysis provides a comprehensive view of the CGM market, highlighting growth opportunities and technological innovations. If further details are needed, feel free to ask.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:45:10,604 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"### External Market Trends for Continuous Glucose Monitoring Systems\\n\\n1. **Market Growth**: The global continuous glucose monitoring (CGM) systems market is projected to reach USD 17 billion by 2029, with a CAGR of 15.1%\\u301012:2\\u2020source\\u3011.\\n\\n2. **Key Drivers**: Growth is driven by the increasing prevalence of diabetes, demand for minimally invasive devices, and technological advancements, including AI integration and non-invasive monitoring solutions\\u301012:0\\u2020source\\u3011\\u301012:2\\u2020source\\u3011.\\n\\n3. **Product Innovations**: Recent trends highlight the integration with smart devices, wearable technology, and the rise of telemedicine and remote healthcare solutions\\u301012:2\\u2020source\\u3011.\\n\\n4. **Competitive Landscape**: Companies like Abbott, Medtronic, and Dexcom are leading in this sector, focusing on advanced features and improved user experience\\u301012:1\\u2020source\\u3011.\\n\\nThis analysis provides a comprehensive view of the CGM market, highlighting growth opportunities and technological innovations. If further details are needed, feel free to ask.\",\n",
      "    \"output\": \"Would you like any additional information or insights on Product A or its market context?\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"### External Market Trends for Continuous Glucose Monitoring Systems\\n\\n1. **Market Growth**: The global continuous glucose monitoring (CGM) systems market is projected to reach USD 17 billion by 2029, with a CAGR of 15.1%\\u301012:2\\u2020source\\u3011.\\n\\n2. **Key Drivers**: Growth is driven by the increasing prevalence of diabetes, demand for minimally invasive devices, and technological advancements, including AI integration and non-invasive monitoring solutions\\u301012:0\\u2020source\\u3011\\u301012:2\\u2020source\\u3011.\\n\\n3. **Product Innovations**: Recent trends highlight the integration with smart devices, wearable technology, and the rise of telemedicine and remote healthcare solutions\\u301012:2\\u2020source\\u3011.\\n\\n4. **Competitive Landscape**: Companies like Abbott, Medtronic, and Dexcom are leading in this sector, focusing on advanced features and improved user experience\\u301012:1\\u2020source\\u3011.\\n\\nThis analysis provides a comprehensive view of the CGM market, highlighting growth opportunities and technological innovations. If further details are needed, feel free to ask.\",\n",
      "    \"output\": \"Would you like any additional information or insights on Product A or its market context?\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - ValidationInsightsAgent: Would you like any additional information or insights on Product A or its market context?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:45:20,012 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"DataRetrievalAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"Would you like any additional information or insights on Product A or its market context?\",\n",
      "    \"output\": \"If you need further details or have specific questions about Product A or market insights, feel free to ask!\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"DataRetrievalAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"Would you like any additional information or insights on Product A or its market context?\",\n",
      "    \"output\": \"If you need further details or have specific questions about Product A or market insights, feel free to ask!\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - DataRetrievalAgent: If you need further details or have specific questions about Product A or market insights, feel free to ask!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:45:29,611 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"If you need further details or have specific questions about Product A or market insights, feel free to ask!\",\n",
      "    \"output\": \"Let me know if there's anything else you need regarding Product A or market trends!\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"If you need further details or have specific questions about Product A or market insights, feel free to ask!\",\n",
      "    \"output\": \"Let me know if there's anything else you need regarding Product A or market trends!\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - ValidationInsightsAgent: Let me know if there's anything else you need regarding Product A or market trends!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:45:38,025 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"DataRetrievalAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"Let me know if there's anything else you need regarding Product A or market trends!\",\n",
      "    \"output\": \"If you have more questions or need additional insights about Product A or market trends, feel free to ask!\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"DataRetrievalAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"Let me know if there's anything else you need regarding Product A or market trends!\",\n",
      "    \"output\": \"If you have more questions or need additional insights about Product A or market trends, feel free to ask!\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - DataRetrievalAgent: If you have more questions or need additional insights about Product A or market trends, feel free to ask!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:45:46,759 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"If you have more questions or need additional insights about Product A or market trends, feel free to ask!\",\n",
      "    \"output\": \"Is there anything else you'd like to explore about Product A or market trends?\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"If you have more questions or need additional insights about Product A or market trends, feel free to ask!\",\n",
      "    \"output\": \"Is there anything else you'd like to explore about Product A or market trends?\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - ValidationInsightsAgent: Is there anything else you'd like to explore about Product A or market trends?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 15:45:56,581 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"DataRetrievalAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"Is there anything else you'd like to explore about Product A or market trends?\",\n",
      "    \"output\": \"Would you like more information on Product A or further market analysis? Let me know how I can assist!\"\n",
      "} (1936533635.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"DataRetrievalAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"Is there anything else you'd like to explore about Product A or market trends?\",\n",
      "    \"output\": \"Would you like more information on Product A or further market analysis? Let me know how I can assist!\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - DataRetrievalAgent: Would you like more information on Product A or further market analysis? Let me know how I can assist!\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main() \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 168\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    167\u001b[39m     last_input = user_message\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m chat.invoke():\n\u001b[32m    169\u001b[39m         agent_name = content.name \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         agent_role = content.role.name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\agents\\group_chat\\agent_group_chat.py:151\u001b[39m, in \u001b[36mAgentGroupChat.invoke\u001b[39m\u001b[34m(self, agent, is_joining)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.termination_strategy.maximum_iterations):\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m         selected_agent = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.selection_strategy.next(\u001b[38;5;28mself\u001b[39m.agents, \u001b[38;5;28mself\u001b[39m.history.messages)\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    153\u001b[39m         logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\agents\\strategies\\selection\\selection_strategy.py:43\u001b[39m, in \u001b[36mSelectionStrategy.next\u001b[39m\u001b[34m(self, agents, history)\u001b[39m\n\u001b[32m     41\u001b[39m     agent = \u001b[38;5;28mself\u001b[39m.initial_agent\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     agent = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.select_agent(agents, history)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.has_selected = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m agent\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\agents\\strategies\\selection\\kernel_function_selection_strategy.py:95\u001b[39m, in \u001b[36mKernelFunctionSelectionStrategy.select_agent\u001b[39m\u001b[34m(self, agents, history)\u001b[39m\n\u001b[32m     89\u001b[39m logger.info(\n\u001b[32m     90\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKernel Function Selection Strategy next method called, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvoking function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.function.plugin_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.function.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     92\u001b[39m )\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function.invoke(kernel=\u001b[38;5;28mself\u001b[39m.kernel, arguments=arguments)\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m     97\u001b[39m     logger.error(\u001b[33m\"\u001b[39m\u001b[33mKernel Function Selection Strategy next method failed\u001b[39m\u001b[33m\"\u001b[39m, exc_info=ex)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function.py:248\u001b[39m, in \u001b[36mKernelFunction.invoke\u001b[39m\u001b[34m(self, kernel, arguments, metadata, **kwargs)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    244\u001b[39m     stack = kernel.construct_call_stack(\n\u001b[32m    245\u001b[39m         filter_type=FilterTypes.FUNCTION_INVOCATION,\n\u001b[32m    246\u001b[39m         inner_function=\u001b[38;5;28mself\u001b[39m._invoke_internal,\n\u001b[32m    247\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m stack(function_context)\n\u001b[32m    250\u001b[39m     KernelFunctionLogMessages.log_function_invoked_success(logger, \u001b[38;5;28mself\u001b[39m.fully_qualified_name)\n\u001b[32m    251\u001b[39m     KernelFunctionLogMessages.log_function_result_value(logger, function_context.result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function_from_prompt.py:174\u001b[39m, in \u001b[36mKernelFunctionFromPrompt._invoke_internal\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m    172\u001b[39m chat_history = ChatHistory.from_rendered_prompt(prompt_render_result.rendered_prompt)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     chat_message_contents = \u001b[38;5;28;01mawait\u001b[39;00m prompt_render_result.ai_service.get_chat_message_contents(\n\u001b[32m    175\u001b[39m         chat_history=chat_history,\n\u001b[32m    176\u001b[39m         settings=prompt_render_result.execution_settings,\n\u001b[32m    177\u001b[39m         **{\u001b[33m\"\u001b[39m\u001b[33mkernel\u001b[39m\u001b[33m\"\u001b[39m: context.kernel, \u001b[33m\"\u001b[39m\u001b[33marguments\u001b[39m\u001b[33m\"\u001b[39m: context.arguments},\n\u001b[32m    178\u001b[39m     )\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m FunctionExecutionException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError occurred while invoking function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\chat_completion_client_base.py:134\u001b[39m, in \u001b[36mChatCompletionClientBase.get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m     settings.function_choice_behavior.configure(\n\u001b[32m    125\u001b[39m         kernel=kernel,\n\u001b[32m    126\u001b[39m         update_settings_callback=\u001b[38;5;28mself\u001b[39m._update_function_choice_settings_callback(),\n\u001b[32m    127\u001b[39m         settings=settings,\n\u001b[32m    128\u001b[39m     )\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    131\u001b[39m     settings.function_choice_behavior \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m settings.function_choice_behavior.auto_invoke_kernel_functions\n\u001b[32m    133\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_chat_message_contents(chat_history, settings)\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Auto invoke loop\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m use_span(\u001b[38;5;28mself\u001b[39m._start_auto_function_invocation_activity(kernel, settings), end_on_exit=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\utils\\telemetry\\model_diagnostics\\decorators.py:112\u001b[39m, in \u001b[36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(completion_func)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(*args: Any, **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[ChatMessageContent]:\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    111\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(*args, **kwargs)\n\u001b[32m    114\u001b[39m     completion_service: \u001b[33m\"\u001b[39m\u001b[33mChatCompletionClientBase\u001b[39m\u001b[33m\"\u001b[39m = args[\u001b[32m0\u001b[39m]\n\u001b[32m    115\u001b[39m     chat_history: ChatHistory = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_chat_completion_base.py:88\u001b[39m, in \u001b[36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings)\u001b[39m\n\u001b[32m     85\u001b[39m settings.messages = \u001b[38;5;28mself\u001b[39m._prepare_chat_history_for_request(chat_history)\n\u001b[32m     86\u001b[39m settings.ai_model_id = settings.ai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_id\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_request(settings)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m     90\u001b[39m response_metadata = \u001b[38;5;28mself\u001b[39m._get_metadata_from_chat_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:59\u001b[39m, in \u001b[36mOpenAIHandler._send_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.TEXT \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.CHAT:\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_completion_request(settings)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.EMBEDDING:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIEmbeddingPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:87\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m settings.tools \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     86\u001b[39m         settings_dict.pop(\u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(**settings_dict)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     89\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.completions.create(**settings_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2000\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1957\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1958\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1959\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1997\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1998\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   1999\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2000\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2001\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2002\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2003\u001b[39m             {\n\u001b[32m   2004\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2005\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2006\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2007\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2008\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2009\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2010\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2011\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2012\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2013\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2014\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2015\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2016\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2017\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2018\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2019\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2020\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2021\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2022\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2023\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2024\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2025\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2026\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2027\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2028\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2029\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2030\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2031\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2032\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2033\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2034\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2035\u001b[39m             },\n\u001b[32m   2036\u001b[39m             completion_create_params.CompletionCreateParams,\n\u001b[32m   2037\u001b[39m         ),\n\u001b[32m   2038\u001b[39m         options=make_request_options(\n\u001b[32m   2039\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2040\u001b[39m         ),\n\u001b[32m   2041\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2042\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2043\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2044\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\openai\\_base_client.py:1767\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1753\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1754\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1755\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1762\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1763\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1764\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1765\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1766\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\openai\\_base_client.py:1461\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1458\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1459\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1462\u001b[39m     cast_to=cast_to,\n\u001b[32m   1463\u001b[39m     options=options,\n\u001b[32m   1464\u001b[39m     stream=stream,\n\u001b[32m   1465\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1466\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1467\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\openai\\_base_client.py:1500\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1497\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauth\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.custom_auth\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m   1501\u001b[39m         request,\n\u001b[32m   1502\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m   1503\u001b[39m         **kwargs,\n\u001b[32m   1504\u001b[39m     )\n\u001b[32m   1505\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1506\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpx\\_client.py:1674\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1670\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1672\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1674\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1675\u001b[39m     request,\n\u001b[32m   1676\u001b[39m     auth=auth,\n\u001b[32m   1677\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1678\u001b[39m     history=[],\n\u001b[32m   1679\u001b[39m )\n\u001b[32m   1680\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpx\\_client.py:1702\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1699\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1702\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1703\u001b[39m         request,\n\u001b[32m   1704\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1705\u001b[39m         history=history,\n\u001b[32m   1706\u001b[39m     )\n\u001b[32m   1707\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1708\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpx\\_client.py:1739\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1736\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1741\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpx\\_client.py:1776\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1772\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1773\u001b[39m     )\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1779\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpx\\_transports\\default.py:377\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    364\u001b[39m req = httpcore.Request(\n\u001b[32m    365\u001b[39m     method=request.method,\n\u001b[32m    366\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    374\u001b[39m     extensions=request.extensions,\n\u001b[32m    375\u001b[39m )\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    382\u001b[39m     status_code=resp.status,\n\u001b[32m    383\u001b[39m     headers=resp.headers,\n\u001b[32m    384\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    385\u001b[39m     extensions=resp.extensions,\n\u001b[32m    386\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpcore\\_async\\connection.py:101\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpcore\\_async\\connection.py:78\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request_lock:\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connect(request)\n\u001b[32m     80\u001b[39m         ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m         http2_negotiated = (\n\u001b[32m     82\u001b[39m             ssl_object \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     83\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m ssl_object.selected_alpn_protocol() == \u001b[33m\"\u001b[39m\u001b[33mh2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpcore\\_async\\connection.py:156\u001b[39m, in \u001b[36mAsyncHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    149\u001b[39m     kwargs = {\n\u001b[32m    150\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mssl_context\u001b[39m\u001b[33m\"\u001b[39m: ssl_context,\n\u001b[32m    151\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mserver_hostname\u001b[39m\u001b[33m\"\u001b[39m: sni_hostname\n\u001b[32m    152\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._origin.host.decode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    153\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    154\u001b[39m     }\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mstart_tls\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m         stream = \u001b[38;5;28;01mawait\u001b[39;00m stream.start_tls(**kwargs)\n\u001b[32m    157\u001b[39m         trace.return_value = stream\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\httpcore\\_backends\\anyio.py:70\u001b[39m, in \u001b[36mAnyIOStream.start_tls\u001b[39m\u001b[34m(self, ssl_context, server_hostname, timeout)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         ssl_stream = \u001b[38;5;28;01mawait\u001b[39;00m anyio.streams.tls.TLSStream.wrap(\n\u001b[32m     71\u001b[39m             \u001b[38;5;28mself\u001b[39m._stream,\n\u001b[32m     72\u001b[39m             ssl_context=ssl_context,\n\u001b[32m     73\u001b[39m             hostname=server_hostname,\n\u001b[32m     74\u001b[39m             standard_compatible=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     75\u001b[39m             server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     76\u001b[39m         )\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aclose()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\anyio\\streams\\tls.py:132\u001b[39m, in \u001b[36mTLSStream.wrap\u001b[39m\u001b[34m(cls, transport_stream, server_side, hostname, ssl_context, standard_compatible)\u001b[39m\n\u001b[32m    122\u001b[39m ssl_object = ssl_context.wrap_bio(\n\u001b[32m    123\u001b[39m     bio_in, bio_out, server_side=server_side, server_hostname=hostname\n\u001b[32m    124\u001b[39m )\n\u001b[32m    125\u001b[39m wrapper = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    126\u001b[39m     transport_stream=transport_stream,\n\u001b[32m    127\u001b[39m     standard_compatible=standard_compatible,\n\u001b[32m   (...)\u001b[39m\u001b[32m    130\u001b[39m     _write_bio=bio_out,\n\u001b[32m    131\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m wrapper._call_sslobject_method(ssl_object.do_handshake)\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\anyio\\streams\\tls.py:147\u001b[39m, in \u001b[36mTLSStream._call_sslobject_method\u001b[39m\u001b[34m(self, func, *args)\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._write_bio.pending:\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.send(\u001b[38;5;28mself\u001b[39m._write_bio.read())\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.receive()\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EndOfStream:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28mself\u001b[39m._read_bio.write_eof()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:1246\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1241\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.is_set()\n\u001b[32m   1242\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing()\n\u001b[32m   1243\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.is_at_eof\n\u001b[32m   1244\u001b[39m ):\n\u001b[32m   1245\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\asyncio\\locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "await main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creting Streamlit App "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import Necessary Modules\n",
    "# Import the required modules in your Python script:\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import streamlit as st\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import AgentGroupChat\n",
    "from semantic_kernel.agents.azure_ai import AzureAIAgent\n",
    "from semantic_kernel.agents.strategies import TerminationStrategy, KernelFunctionSelectionStrategy\n",
    "from semantic_kernel.functions import KernelFunctionFromPrompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the Approval Termination Strategy\n",
    "# Create a custom termination strategy to end the conversation based on specific criteria:\n",
    "\n",
    "class ApprovalTerminationStrategy(TerminationStrategy):\n",
    "    def __init__(self, agents, maximum_iterations=10):\n",
    "        super().__init__(maximum_iterations=maximum_iterations)\n",
    "        self.agents = agents\n",
    "\n",
    "    async def should_agent_terminate(self, agent, history) -> bool:\n",
    "        last_msg = history[-1]\n",
    "        return (last_msg.name in [a.name for a in self.agents]) and (\"approved\" in last_msg.content.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize the Kernel with Chat Completion\n",
    "# Set up the Semantic Kernel with an Azure OpenAI chat completion service:\n",
    "\n",
    "def _create_kernel_with_chat_completion() -> Kernel:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    kernel = Kernel()\n",
    "    AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "    AZURE_OPENAI_API_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "    AZURE_AOAI_CHAT_MODEL_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_MODEL_DEPLOYMENT\", \"gpt-4\")\n",
    "\n",
    "    kernel.add_service(\n",
    "        service=AzureChatCompletion(\n",
    "            deployment_name=AZURE_AOAI_CHAT_MODEL_DEPLOYMENT,\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            endpoint=AZURE_OPENAI_API_ENDPOINT,\n",
    "            api_version=AZURE_OPENAI_API_VERSION,\n",
    "        )\n",
    "    )\n",
    "    return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define the Selection Function Prompt\n",
    "# Create a prompt to determine the next participant in the conversation:\n",
    "\n",
    "RETRIEVER_NAME = \"ValidationInsightsAgent\"\n",
    "EVALUATOR_NAME = \"DataRetrievalAgent\"\n",
    "\n",
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\",\n",
    "    prompt=f\"\"\"\n",
    "Determine which participant takes the next turn in a conversation based on the most recent participant.\n",
    "State only the name of the participant to take the next turn.\n",
    "No participant should take more than one turn in a row.\n",
    "\n",
    "Choose only from these participants:\n",
    "- {RETRIEVER_NAME}\n",
    "- {EVALUATOR_NAME}\n",
    "\n",
    "Always follow these rules when selecting the next participant:\n",
    "- {RETRIEVER_NAME} retrieves the document or relevant data for the query.\n",
    "- After {RETRIEVER_NAME}, it is {EVALUATOR_NAME}'s turn to evaluate the content.\n",
    "- After {EVALUATOR_NAME}, the workflow may terminate if 'approved'.\n",
    "\n",
    "History:\n",
    "{{{{$history}}}}\n",
    "\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Initialize Agents and Chat\n",
    "# Set up the agents and the chat interface:\n",
    "\n",
    "async def initialize_agents():\n",
    "    creds = DefaultAzureCredential()\n",
    "    client = await AzureAIAgent.create_client(credential=creds)\n",
    "\n",
    "    ValidationInsightsAgentID = \"asst_kdFT72VdYH0YpoG3tJ5lmoFy\"\n",
    "    DataRetrievalAgentID = \"asst_Wo0GJ9MpmvkfRPNwllC7bYFS\"\n",
    "\n",
    "    dataretrieval_def = await client.agents.get_agent(agent_id=DataRetrievalAgentID)\n",
    "    validation_def = await client.agents.get_agent(agent_id=ValidationInsightsAgentID)\n",
    "\n",
    "    agent_retriever = AzureAIAgent(client=client, definition=dataretrieval_def)\n",
    "    agent_evaluator = AzureAIAgent(client=client, definition=validation_def)\n",
    "\n",
    "    chat = AgentGroupChat(\n",
    "        agents=[agent_retriever, agent_evaluator],\n",
    "        termination_strategy=ApprovalTerminationStrategy(\n",
    "            maximum_iterations=10,\n",
    "            agents=[agent_evaluator],\n",
    "        ),\n",
    "        selection_strategy=KernelFunctionSelectionStrategy(\n",
    "            function=selection_function,\n",
    "            kernel=_create_kernel_with_chat_completion(),\n",
    "            result_parser=lambda result: str(result.value[0]) if result.value else EVALUATOR_NAME,\n",
    "            agent_variable_name=\"agents\",\n",
    "            history_variable_name=\"history\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Build the Streamlit Interface\n",
    "# Create the Streamlit interface to interact with the agents:\n",
    "\n",
    "async def main():\n",
    "    st.title(\"Multi-Agent Chat Interface\")\n",
    "\n",
    "    if \"chat\" not in st.session_state:\n",
    "        st.session_state.chat = await initialize_agents()\n",
    "        st.session_state.history = []\n",
    "\n",
    "    user_input = st.chat_input(\"Enter your message:\")\n",
    "    if user_input:\n",
    "        st.session_state.history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        await st.session_state.chat.add_chat_message(message=user_input)\n",
    "\n",
    "        async for content in st.session_state.chat.invoke():\n",
    "            agent_name = content.name or \"Unknown\"\n",
    "            agent_role = content.role.name\n",
    "            agent_output = content.content\n",
    "\n",
    "            st.session_state.history.append({\"role\": agent_role, \"name\": agent_name, \"content\": agent_output})\n",
    "\n",
    "            st.chat_message(agent_role).write(f\"**{agent_name}:** {agent_output}\")\n",
    "\n",
    "        if st.session_state.chat.is_complete:\n",
    "            st.write(\"Conversation has been approved and terminated.\")\n",
    "            st.session_state.chat.reset()\n",
    "            st.session_state.history = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Run the Streamlit Application\n",
    "\n",
    "Save your script (e.g., app.py) and run it using Streamlit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run src/chatapp/app.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ai-agent-service-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
