{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Use Case Overview**\n",
    "\n",
    "Imagine you‚Äôre part of an R&D team that needs to merge structured data (e.g., experimental results, market trends) from Microsoft Fabric with unstructured documents (e.g., research reports, engineering notes) in SharePoint, then validate these findings against external references (e.g., Bing) and a high-quality ‚Äúground truth‚Äù internal knowledge stores (e.g., Azure AI Search).\n",
    "\n",
    "This was a classic Retrieval-Augmented Generation (RAG) scenario‚Äîmultiple data sources must be queried in real time and cross-checked for consistency. However, by leveraging Azure AI agent services (an agetic enterprise-ready microservices approach) alongside frameworks like Semantic Kernel, we can evolve beyond basic RAG into a mostly autonomous, agentic system. In this design, Agentic RAG and the Reflection Pattern enable each agent to iteratively refine its output until it‚Äôs confident in delivering a high-quality, validated answer‚Äîpaving the way for intelligent automation that continually learns and improves.\n",
    "\n",
    "To summarize, you‚Äôre not only bringing data to the AI but also bringing AI to the data, thus maximizing the value of your knowledge stores. By leveraging state-of-the-art retrieval solutions like Azure AI Search, while also tapping sources such as SharePoint (unstructured data) and Fabric (structured data), you can harness your most valuable asset‚Äîdata‚Äîto achieve new levels of insight and automation. \n",
    "\n",
    "**In this demo, we have two Azure AI Agents (extending beyond a single-agent architecture):**\n",
    "\n",
    "+ DataRetrievalAgent: Has access to Microsoft Fabric (for structured data) and SharePoint (for unstructured documents). Its job is to gather relevant internal data: for example, ‚Äúfailure rates of Material X in high-temperature tests,‚Äù or ‚Äúengineering notes on prior tests.‚Äù\n",
    "\n",
    "- ValidationInsightsAgent Has access to Bing / Azure Cognitive Search for external references and can run a ‚Äúreflection‚Äù or ‚Äúvalidation‚Äù step. Its job is to cross-check what was returned by the first agent and highlight missing or conflicting information. ValidationInsightsAgent has access to highly curated knowledge sources (e.g., Azure AI Search) for validating the accuracy or truthfulness of the information it receives from DataRetrievalAgent.\n",
    "\n",
    "\n",
    "**Moving from a single-agent setup to a multi-agent system is now simpler than ever with Semantic Kernel. The general flow looks like this:**\n",
    "\n",
    "1. The user asks a question (e.g., ‚ÄúRetrieve historical failure rates for Material X in extreme temperatures and cross-check if new standards or conflicting data exist.‚Äù).\n",
    "2. The DataRetrievalAgent fetches structured data from Fabric (e.g., lab test results, analytics) and unstructured docs from SharePoint (e.g., research memos, engineering notes).\n",
    "3. The ValidationInsightsAgent then queries Bing/Azure Search to verify or supplement the results. Employ a reflection pattern, where it iterates over the combined results, looking for gaps or inconsistencies. If needed, it loops back to the DataRetrievalAgent for clarifications or additional data.\n",
    "\n",
    "Finally, the user receives a validated, summarized answer that merges internal data with external cross-checks. Thanks to the agents‚Äô back-and-forth reflection.\n",
    "\n",
    "### **Why This Matters**\n",
    "\n",
    "+ **Reduced Manual Research**: Instead of manually sifting through multiple data silos and external search engines, the AI Agents automate data gathering and vetting.\n",
    "+ **Higher Confidence**: Validation ensures data accuracy and highlights missing pieces, improving R&D decision-making.\n",
    "+ **Enterprise-Grade Security**: Each agent can enforce On-Behalf-Of (OBO) authentication to protect sensitive data (e.g., only pulling data the user is authorized to see).\n",
    "In the Jupyter Notebook\n",
    "\n",
    "When you run the code in this Jupyter notebook:\n",
    "\n",
    "(TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime as pydatetime\n",
    "from typing import Any, List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "# Azure AI Projects\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "# semantic kernel\n",
    "from semantic_kernel.contents import AuthorRole\n",
    "from semantic_kernel.agents.azure_ai import AzureAIAgent, AzureAIAgentSettings\n",
    "from semantic_kernel.agents.open_ai.run_polling_options import RunPollingOptions\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# configure logging\n",
    "from utils.ml_logging import get_logger\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "# set the directory to the location of the script\n",
    "try:\n",
    "    target_directory = os.getenv(\"TARGET_DIRECTORY\", os.getcwd())  # Use environment variable if available\n",
    "    if os.path.exists(target_directory):\n",
    "        os.chdir(target_directory)\n",
    "        logging.info(f\"Successfully changed directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        logging.error(f\"Directory does not exist: {target_directory}\")\n",
    "except Exception as e:\n",
    "    logging.exception(f\"An error occurred while changing directory: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Client and Load Azure AI Foundry**\n",
    "\n",
    "Here, we initialize the Azure AI client using DefaultAzureCredential. This allows us to authenticate and connect to the Azure AI service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AzureAIAgent.create_client(credential=DefaultAzureCredential())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Creating Azure AI Agents: DataRetrievalAgent**\n",
    "\n",
    "The DataRetrievalAgent is responsible for internal data retrieval, combining structured data from Microsoft Fabric with unstructured documents from SharePoint. This agent ensures that research teams can efficiently access critical R&D insights, such as historical failure rates, experimental results, and engineering notes‚Äîall while maintaining secure and authorized access controls.\n",
    "\n",
    "Agent Capabilities\n",
    "+ ‚úÖ Structured Data Retrieval ‚Üí Queries Microsoft Fabric for experiment logs, test results, and structured analytics.\n",
    "+ ‚úÖ Unstructured Document Search ‚Üí Fetches relevant reports, blueprints, and research notes from SharePoint.\n",
    "+ ‚úÖ OBO Authentication ‚Üí Uses On-Behalf-Of (OBO) authentication to ensure users can only access data they are permitted to view.\n",
    "\n",
    "For a detailed breakdown of how to create a single Azure AI Agent and configure its data (tools) connections, please refer to:\n",
    "üìå [01-single-agents-with-azure-ai-agents.ipynb](01-single-agents-with-azure-ai-agents.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import ServiceRequestError\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "\n",
    "async def get_connection_id(client: AIProjectClient, env_var: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Retrieves the connection object using a connection name stored in an environment variable.\n",
    "\n",
    "    Args:\n",
    "        client: The Azure AI Project client.\n",
    "        env_var (str): The environment variable holding the connection name.\n",
    "\n",
    "    Returns:\n",
    "        Connection object if found, otherwise raises an error.\n",
    "    \"\"\"\n",
    "    connection_name = os.getenv(env_var)\n",
    "    if not connection_name:\n",
    "        logger.error(f\"Missing environment variable: '{env_var}'\")\n",
    "        raise ValueError(f\"Environment variable '{env_var}' is required.\")\n",
    "\n",
    "    try:\n",
    "        connection = await client.connections.get(connection_name=connection_name)\n",
    "        logger.info(f\"Retrieved Connection ID for {env_var}: {connection.id}\")\n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to retrieve connection for {env_var}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 09:39:27,626 - micro - MainProcess - INFO     Retrieved Connection ID for TOOL_CONNECTION_NAME_SHAREPOINT: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-zhuoqunliai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-1959/connections/ContosoAgentDemoSharepoint (2375541312.py:get_connection_id:22)\n",
      "INFO:micro:Retrieved Connection ID for TOOL_CONNECTION_NAME_SHAREPOINT: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-zhuoqunliai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-1959/connections/ContosoAgentDemoSharepoint\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import (\n",
    "    SharepointTool,\n",
    "    FabricTool,\n",
    "    ToolSet,\n",
    ")\n",
    "\n",
    "# Initialize Azure AI Agent settings\n",
    "dataretrievalagent_settings = AzureAIAgentSettings.create()\n",
    "\n",
    "toolset = ToolSet()\n",
    "\n",
    "try:\n",
    "    # Retrieve and add SharePoint Tool\n",
    "    sharepoint_connection = await get_connection_id(project_client, \"TOOL_CONNECTION_NAME_SHAREPOINT\")\n",
    "    toolset.add(SharepointTool(connection_id=sharepoint_connection.id))\n",
    "\n",
    "    # # Retrieve and add Fabric Tool\n",
    "    # fabric_connection = await get_connection_id(project_client, \"TOOL_CONNECTION_NAME_FABRIC\")\n",
    "    # toolset.add(FabricTool(connection_id=fabric_connection.id))\n",
    "\n",
    "    # logger.info(\"Successfully created ToolSet with SharePoint and Fabric tools.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create ToolSet: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataRetrievalAgent Run ID: asst_hxkuQFK54htjhyCOO1hmbYPB\n"
     ]
    }
   ],
   "source": [
    "dataretrievalagent_settings_definition = await project_client.agents.create_agent(\n",
    "    model=dataretrievalagent_settings.model_deployment_name,\n",
    "    name=\"DataRetrievalAgent\",\n",
    "    description=(\n",
    "        \"An AI agent designed to retrieve and integrate structured data from Microsoft Fabric \"\n",
    "        \"and unstructured documents from SharePoint to provide comprehensive R&D insights.\"\n",
    "    ),\n",
    "    instructions=(\n",
    "        \"You are an AI assistant specialized in retrieving data from internal enterprise sources. \"\n",
    "        \"Utilize the provided tools to access and integrate information from Microsoft Fabric and SharePoint. \"\n",
    "        \"Ensure that all responses are based on the most relevant and recent data available.\"\n",
    "    ),\n",
    "    toolset=toolset,\n",
    "    headers={\"x-ms-enable-preview\": \"true\"},\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    metadata={\n",
    "        \"use_case\": \"Internal Data Retrieval for R&D\",\n",
    "        \"data_source\": \"Microsoft Fabric and SharePoint\",\n",
    "        \"response_validation\": \"Ensure data accuracy and relevance\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# Print the agent's run ID (agent ID)\n",
    "print(f\"DataRetrievalAgent Run ID: {dataretrievalagent_settings_definition.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ **User:** What are the latest trends in R&D?\n",
      "\n",
      "ü§ñ **Agent:** The latest trends in research and development (R&D) for 2023 encompass several areas, with significant advancements noted in various fields:\n",
      "\n",
      "1. **Diabetes Technology**:\n",
      "   - **Automated Insulin Delivery Systems**: The approval and implementation of systems like the Omnipod 5, which integrates a tubeless pod insulin pump with a continuous glucose monitoring sensor, allowing for automated insulin delivery based on real-time glucose levels.\n",
      "   - **Advanced Hybrid Closed-Loop Systems**: Devices such as the MiniMed 780G, which offer more precise glycemic control using advanced algorithms.\n",
      "   - **Bionic Pancreas**: Innovations like the bionic pancreas, which have shown promising results in managing type 1 diabetes through randomized trials.\n",
      "\n",
      "These advancements highlight a trend towards integrating technology and healthcare, particularly through devices that offer automated and real-time health management solutions„Äê7:1‚Ä†source„Äë„Äê5:1‚Ä†source„Äë.\n",
      "\n",
      "üë§ **User:** What are the key features from Dexcom G7 CGM System?\n",
      "\n",
      "ü§ñ **Agent:** The Dexcom G7 Continuous Glucose Monitoring (CGM) System, which received FDA clearance in December 2022, includes several key features:\n",
      "\n",
      "1. **All-in-One Transmitter and Sensor**: The G7 integrates the transmitter and sensor into a single unit, simplifying the application process.\n",
      "2. **Simplified One-Click Applicator**: The application of the G7 sensor is streamlined with a one-click applicator, making it easier to use.\n",
      "3. **Smaller Size**: The Dexcom G7 sensor is significantly smaller than its predecessor, the G6, enhancing user comfort.\n",
      "4. **Faster Warm-Up Time**: The warm-up time for the G7 is reduced to 30 minutes, compared to 2 hours for the G6.\n",
      "5. **Flexible Wear Locations**: Users aged 7 years and older can wear the device on the back of their upper arm, while children aged 2 to 6 years can wear it on the upper buttocks as well.\n",
      "6. **Real-Time Data**: The G7 provides continuous glucose monitoring data in real-time without the need for scanning.\n",
      "\n",
      "These features collectively enhance the usability and convenience of the CGM system for a wide range of users, from young children to adults„Äê11:1‚Ä†source„Äë„Äê11:2‚Ä†source„Äë.\n",
      "\n",
      "üë§ **User:** What documents are available in SharePoint related to R&D?\n",
      "\n",
      "ü§ñ **Agent:** I was unable to locate a specific list of documents related to R&D in SharePoint. You may need to access your SharePoint directory directly or provide further details to narrow down the search. If you have specific document names or topics, that could assist in retrieving the relevant information.\n",
      "\n",
      "üë§ **User:** How does Product A compare to Product B in terms of MARD percentage across different glucose ranges?\n",
      "\n",
      "ü§ñ **Agent:** The comparison between Product A and Product B in terms of Mean Absolute Relative Difference (MARD) percentage across different glucose ranges can be summarized as follows:\n",
      "\n",
      "### Product A:\n",
      "- **Accuracy**: The beta trial of Product A reported a MARD of 8.7% (¬±0.4%) relative to reference methods. This performance meets the internal targets for nonadjunctive use.\n",
      "- **Testing Conditions**: Product A sensors underwent rigorous bench testing under simulated physiological conditions, including continuous operation over a 14-day period with dynamic glucose changes (40‚Äì400 mg/dL) to assess drift and sensor stability„Äê21:3‚Ä†source„Äë„Äê21:4‚Ä†source„Äë.\n",
      "\n",
      "### Product B:\n",
      "- **Accuracy**: Product B's MARD percentage and performance data are not explicitly mentioned in the provided documents. However, it is indicated that calibration-free devices, such as Product B, still show measurable divergence from capillary blood glucose values. More extensive investigations with larger sample sizes and standardized accuracy metrics are recommended to confirm these findings and refine the technology„Äê21:1‚Ä†source„Äë.\n",
      "\n",
      "In conclusion, Product A appears to have a well-documented MARD percentage of 8.7%, while the detailed performance metrics for Product B are less specific. Further comparative studies would be necessary to provide a more comprehensive understanding of their performance across various glucose ranges.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataretrievalagent = AzureAIAgent(\n",
    "    client=project_client,\n",
    "    definition=dataretrievalagent_settings_definition,\n",
    "    polling_options=RunPollingOptions(run_polling_interval=timedelta(seconds=1)),\n",
    ")\n",
    "\n",
    "thread = await project_client.agents.create_thread()\n",
    "\n",
    "USER_INPUTS = [\n",
    "    \"What are the latest trends in R&D?\",\n",
    "    \"What are the key features from Dexcom G7 CGM System?\",\n",
    "    \"What documents are available in SharePoint related to R&D?\",\n",
    "    \"How does Product A compare to Product B in terms of MARD percentage across different glucose ranges?\"]\n",
    "try:\n",
    "    for user_input in USER_INPUTS:\n",
    "        # Add the user input as a chat message\n",
    "        await dataretrievalagent.add_chat_message(thread_id=thread.id, message=user_input)\n",
    "        print(f\"üë§ **User:** {user_input}\\n\")\n",
    "        \n",
    "        # Invoke the agent for the specified thread and stream the response\n",
    "        async for content in dataretrievalagent.invoke(thread_id=thread.id):\n",
    "            # Only print non-tool messages\n",
    "            if content.role != AuthorRole.TOOL:\n",
    "                print(f\"ü§ñ **Agent:** {content.content}\\n\")\n",
    "                \n",
    "except HttpResponseError as e:\n",
    "    try:\n",
    "        error_json = json.loads(e.response.content)\n",
    "        logging.error(f\"‚ùå **Error Message:** {error_json.get('Message')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(f\"‚ùå **Non-JSON Error Content:** {e.response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Creating Azure AI Agents: ValidationInsightsAgent**\n",
    "\n",
    "The ValidationInsightsAgent is designed to validate and cross-check the data retrieved by the DataRetrievalAgent. It accesses external references such as Bing and Azure Cognitive Search to verify and supplement the internal data. Additionally, it leverages highly curated knowledge sources (e.g., Azure AI Search) to ensure the accuracy and truthfulness of the information, using a reflection or validation step to highlight missing or conflicting details.\n",
    "\n",
    "Agent Capabilities:\n",
    "\n",
    "+ ‚úÖ External Reference Verification ‚Üí Queries Bing and Azure Cognitive Search for real-time validation.\n",
    "+ ‚úÖ Reflection & Validation Step ‚Üí Iteratively reviews and refines the information received from the DataRetrievalAgent.\n",
    "+ ‚úÖ Curated Knowledge Validation ‚Üí Uses Azure AI Search to confirm the accuracy and reliability of internal data.\n",
    "\n",
    "For a detailed breakdown of how to create a ValidationInsightsAgent and configure its external tools and connections, please refer to:\n",
    "üìå [01-single-agents-with-azure-ai-agents.ipynb](01-single-agents-with-azure-ai-agents.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 08:21:38,847 - micro - MainProcess - INFO     Retrieved Connection ID for TOOL_CONNECTION_NAME_BING: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-zhuoqunliai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-1959/connections/agentsbinggrounding (2375541312.py:get_connection_id:22)\n",
      "INFO:micro:Retrieved Connection ID for TOOL_CONNECTION_NAME_BING: /subscriptions/47f1c914-e299-4953-a99d-3e34644cfe1c/resourceGroups/rg-zhuoqunliai/providers/Microsoft.MachineLearningServices/workspaces/zhuoqunli-1959/connections/agentsbinggrounding\n",
      "2025-03-20 08:21:38,851 - micro - MainProcess - INFO     Bing Grounding Tool added successfully. (3079022251.py:<module>:19)\n",
      "INFO:micro:Bing Grounding Tool added successfully.\n",
      "2025-03-20 08:21:38,856 - micro - MainProcess - INFO     Using PDF file path: C:\\Users\\pablosal\\Desktop\\azure-ai-agent-services-demo\\data\\product_data\\ProductATechncialArchitecture.pdf (3079022251.py:<module>:31)\n",
      "INFO:micro:Using PDF file path: C:\\Users\\pablosal\\Desktop\\azure-ai-agent-services-demo\\data\\product_data\\ProductATechncialArchitecture.pdf\n",
      "2025-03-20 08:21:49,081 - micro - MainProcess - INFO     Azure AI Search Tool added successfully. (3079022251.py:<module>:42)\n",
      "INFO:micro:Azure AI Search Tool added successfully.\n",
      "2025-03-20 08:21:49,083 - micro - MainProcess - INFO     Successfully created ToolSet with Bing and File Search tools. (3079022251.py:<module>:45)\n",
      "INFO:micro:Successfully created ToolSet with Bing and File Search tools.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import (\n",
    "    BingGroundingTool,\n",
    "    AzureAISearchTool,\n",
    "    FileSearchTool,\n",
    "    VectorStore,\n",
    "    OpenAIFile\n",
    ")\n",
    "\n",
    "# Initialize Azure AI Agent settings\n",
    "validationinsightagent_settings = AzureAIAgentSettings.create()\n",
    "\n",
    "# Create a ToolSet to manage tools\n",
    "toolset = ToolSet()\n",
    "\n",
    "try:\n",
    "    # Retrieve and add the Bing Grounding Tool\n",
    "    bing_connection = await get_connection_id(project_client, \"TOOL_CONNECTION_NAME_BING\")\n",
    "    toolset.add(BingGroundingTool(connection_id=bing_connection.id))\n",
    "    logger.info(\"Bing Grounding Tool added successfully.\")\n",
    "\n",
    "    # Retrieve and add the Azure AI Search Tool\n",
    "    # search_connection = await get_connection_id(project_client, \"TOOL_CONNECTION_NAME_SEARCH\")\n",
    "    # azure_ai_search_connection = AzureAISearchTool(\n",
    "    #     index_connection_id=search_connection.id,\n",
    "    #     index_name=\"ai-agentic-index\"\n",
    "    # )\n",
    "    # toolset.add(azure_ai_search_connection)\n",
    "    # logger.info(\"Azure AI Search Tool added successfully.\")\n",
    "\n",
    "    pdf_file_path = r\"C:\\Users\\pablosal\\Desktop\\azure-ai-agent-services-demo\\data\\product_data\\ProductATechncialArchitecture.pdf\"\n",
    "    logger.info(f\"Using PDF file path: {pdf_file_path}\")\n",
    "\n",
    "    file: OpenAIFile = await project_client.agents.upload_file_and_poll(file_path=pdf_file_path, purpose=\"assistants\")\n",
    "    vector_store: VectorStore = await project_client.agents.create_vector_store_and_poll(\n",
    "        file_ids=[file.id], name=\"my_vectorstore\"\n",
    "    )\n",
    "\n",
    "    # 2. Create file search tool with uploaded resources\n",
    "    file_search = FileSearchTool(vector_store_ids=[vector_store.id])\n",
    "\n",
    "    toolset.add(file_search)\n",
    "    logger.info(\"Azure AI Search Tool added successfully.\")\n",
    " \n",
    "\n",
    "    logger.info(\"Successfully created ToolSet with Bing and File Search tools.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create ToolSet: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValidationInsightsAgent Run ID: asst_kdFT72VdYH0YpoG3tJ5lmoFy\n"
     ]
    }
   ],
   "source": [
    "# Create or update a new Validation Insights Agent\n",
    "validationinsightsagent_definition = await project_client.agents.create_agent(\n",
    "    model=dataretrievalagent_settings.model_deployment_name,\n",
    "    name=\"ValidationInsightsAgent\",\n",
    "    description=(\n",
    "        \"An AI agent designed to validate and refine R&D insights by cross-checking \"\n",
    "        \"both internal enterprise data sources (e.g., file search vector store, SharePoint, Fabric) \"\n",
    "        \"and external public data (Bing, Azure AI Search). It uses a reflection pattern \"\n",
    "        \"to ensure response accuracy, consistency, and proper citations.\"\n",
    "    ),\n",
    "    instructions=(\n",
    "        \"You are a 'Validation Insights' AI assistant, specialized in combining internal enterprise data \"\n",
    "        \"(from file search vector stores) and with external search capabilities \"\n",
    "        \"(Bing and Azure AI Search). \"\n",
    "        \"\\n\\n\"\n",
    "        \"1. **Data Retrieval & Cross-Validation**: Always consult the internal file search index first. \"\n",
    "        \"If internal data is insufficient or needs verification, leverage Bing and File Store to find \"\n",
    "        \"additional context and resolve discrepancies. \"\n",
    "        \"\\n\\n\"\n",
    "        \"2. **Reflection Step**: After retrieving data, pause and reflect on the consistency and relevance \"\n",
    "        \"of the combined information. If you find contradictions or gaps, perform a second pass to refine \"\n",
    "        \"and unify the insights. \"\n",
    "        \"\\n\\n\"\n",
    "        \"3. **Accuracy & Citations**: In your final response, prioritize clarity, correctness, and completeness. \"\n",
    "        \"Include citations (links or references) to the sources (internal or external) you used, ensuring \"\n",
    "        \"the user understands where information came from. \"\n",
    "        \"\\n\\n\"\n",
    "        \"4. **User-Focused Delivery**: Present your findings in a concise, professional manner. If certain \"\n",
    "        \"details are not confirmed or require further validation, be transparent. \"\n",
    "        \"\\n\\n\"\n",
    "        \"Aim to deliver responses that combine the best aspects of internal knowledge with the breadth \"\n",
    "        \"of external web data, ensuring your insights are well-supported and actionable.\"\n",
    "    ),\n",
    "    toolset=toolset,\n",
    "    # Prefer the internal file search vector store by default\n",
    "    tool_resources=file_search.resources,\n",
    "    headers={\"x-ms-enable-preview\": \"true\"},\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    metadata={\n",
    "        \"use_case\": \"Cross-Validation and Insight Generation for R&D\",\n",
    "        \"data_source\": \"Internal (Fabric, SharePoint) and External (Bing, Azure AI Search)\",\n",
    "        \"response_validation\": (\n",
    "            \"Employ a reflection step to cross-check data accuracy \"\n",
    "            \"and provide clear citations in final responses.\"\n",
    "        )\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"ValidationInsightsAgent Run ID: {validationinsightsagent_definition.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ **User:** What are the characteristics and architecture of Product A?\n",
      "\n",
      "ü§ñ **Agent:** ### Characteristics and Architecture of Product A\n",
      "\n",
      "#### Characteristics\n",
      "Product A is an advanced integrated continuous glucose monitoring (iCGM) system designed by Contoso Enterprise. It features several state-of-the-art components and functionalities that ensure high accuracy, user comfort, and robust data management. Key characteristics include:\n",
      "\n",
      "1. **Sensor Module**:\n",
      "   - **Sensor Core**: Factory-calibrated electrochemical sensor measuring interstitial glucose every 5 minutes, with an enzyme-coated electrode for high sensitivity across a glucose range of 40‚Äì400 mg/dL.\n",
      "   - **Protective Membrane**: Micro-porous, biocompatible membrane that minimizes biofouling and enhances signal stability.\n",
      "   - **Adhesive and Patch**: Integrated within a hypoallergenic adhesive patch suitable for long-term wear (up to 10 days), with an overpatch for additional durability during physical activities„Äê4:0‚Ä†source„Äë.\n",
      "\n",
      "2. **Transmitter and Communication Layer**:\n",
      "   - **Low-Power Transmitter**: Battery-powered transmitter that converts analog signals to digital data every 5 minutes, with a battery life supporting a full sensor session plus a 12-hour grace period.\n",
      "   - **Wireless Transmission**: Secure Bluetooth connectivity (AES-256 encryption) for data transmission to paired mobile devices or dedicated receivers.\n",
      "   - **Data Buffering**: Stores up to 24 hours of data in case of connection loss, ensuring continuous data availability once connectivity is restored.\n",
      "   - **Interoperability**: Supports open API standards for integration with third-party devices„Äê4:0‚Ä†source„Äë„Äê4:4‚Ä†source„Äë.\n",
      "\n",
      "3. **Software and Analytics**:\n",
      "   - **Mobile Application and Receiver Interface**: Real-time display of sensor readings, trend arrows, and historical glucose graphs, with customizable alerts for hypo- and hyperglycemia.\n",
      "   - **Cloud-Based Data Management**: Real-time data upload to a secure cloud portal, generating comprehensive reports and utilizing adaptive machine learning for personalized insights„Äê4:4‚Ä†source„Äë.\n",
      "\n",
      "#### Architecture\n",
      "The architecture of Product A is designed to ensure seamless integration of its components, providing accurate and reliable glucose monitoring. The architecture includes:\n",
      "\n",
      "1. **Sensor Module**:\n",
      "   - **Design and Construction**: Focused on ensuring high sensitivity and rapid response through an enzyme-coated electrode and a protective biocompatible membrane.\n",
      "   - **Integration**: Hypoallergenic adhesive patch for long-term wear, with an additional overpatch for enhanced durability„Äê4:0‚Ä†source„Äë.\n",
      "\n",
      "2. **Transmitter and Communication**:\n",
      "   - **Low-Power Transmitter**: Converts analog sensor signals to digital data, transmitting every 5 minutes.\n",
      "   - **Data Connectivity**: Secure Bluetooth connection with data buffering capabilities to ensure no data loss during temporary disconnections„Äê4:4‚Ä†source„Äë.\n",
      "\n",
      "3. **Software and Analytics**:\n",
      "   - **User Interfaces**: Mobile app and dedicated receiver for user-friendly interaction and real-time data visualization.\n",
      "   - **Cloud Integration**: Secure cloud platform for comprehensive data management and advanced analytics, including adaptive machine learning algorithms for future updates„Äê4:4‚Ä†source„Äë.\n",
      "\n",
      "Overall, Product A's architecture and characteristics have been rigorously tested through pre-clinical evaluations, beta testing, and pivotal clinical trials, demonstrating high accuracy, stability, and user satisfaction„Äê4:2‚Ä†source„Äë„Äê4:3‚Ä†source„Äë.\n",
      "\n",
      "üë§ **User:** What are the key features from Dexcom G7 CGM System?\n",
      "\n",
      "ü§ñ **Agent:** ### Key Features of the Dexcom G7 CGM System\n",
      "\n",
      "The Dexcom G7 Continuous Glucose Monitoring (CGM) system is a state-of-the-art device designed to assist individuals with diabetes in managing their glucose levels more effectively. Below are the key features of the Dexcom G7 system:\n",
      "\n",
      "1. **Sensor and Transmitter Integration**:\n",
      "   - **All-in-One Sensor**: The Dexcom G7 combines the sensor and transmitter into a single unit, making it easier to apply and reducing the form factor.\n",
      "   - **Wear Duration**: The sensor is designed for a 10-day wear period, providing continuous glucose monitoring with high accuracy.\n",
      "   - **Quick Warm-Up**: The system features a rapid warm-up time of approximately 30 minutes, ensuring users can start monitoring glucose levels quickly after sensor application„Äê4‚Ä†source„Äë  .\n",
      "\n",
      "2. **Accuracy and Performance**:\n",
      "   - **MARD (Mean Absolute Relative Difference)**: The Dexcom G7 system has demonstrated a low MARD, indicating high accuracy in glucose readings. This is critical for making informed treatment decisions.\n",
      "   - **Performance During Dynamic Conditions**: The system maintains reliable performance during periods of rapid glucose changes, important for capturing accurate readings during meals, exercise, and other activities    .\n",
      "\n",
      "3. **User Interface and Alerts**:\n",
      "   - **Mobile App Integration**: The Dexcom G7 pairs with a mobile application that provides real-time glucose readings, trends, and alerts for hypo- and hyperglycemia.\n",
      "   - **Customizable Alerts**: Users can set personalized thresholds for glucose levels, receiving alerts to help them manage their condition proactively.\n",
      "   - **Discreet Wearability**: The smaller profile and integrated design of the sensor make it less obtrusive and more comfortable for users to wear discreetly    .\n",
      "\n",
      "4. **Data Sharing and Connectivity**:\n",
      "   - **Bluetooth Connectivity**: Secure Bluetooth technology is used to transmit data from the sensor to the user‚Äôs mobile device, ensuring real-time data access.\n",
      "   - **Data Sharing**: Users can share their glucose data with healthcare providers and caregivers through the Dexcom Clarity platform, facilitating better management and remote monitoring.\n",
      "   - **Integration with Other Devices**: The Dexcom G7 system supports integration with other diabetes management tools, such as insulin pumps and smart pens, through interoperable technology    .\n",
      "\n",
      "5. **Regulatory and Clinical Validation**:\n",
      "   - **Regulatory Approvals**: The Dexcom G7 CGM system has received regulatory approvals and meets the necessary standards for safety and efficacy.\n",
      "   - **Clinical Trials**: The system has undergone extensive clinical testing to validate its performance, accuracy, and user satisfaction across diverse populations and use cases    .\n",
      "\n",
      "These features collectively make the Dexcom G7 a highly effective tool for continuous glucose monitoring, aiding individuals with diabetes in maintaining better control over their glucose levels and improving their overall quality of life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation_agent = AzureAIAgent(\n",
    "    client=project_client,\n",
    "    definition=validationinsightsagent_definition,\n",
    "    polling_options=RunPollingOptions(run_polling_interval=timedelta(seconds=1)),\n",
    ")\n",
    "\n",
    "# Create a conversation thread for the agent\n",
    "thread = await project_client.agents.create_thread()\n",
    "\n",
    "# Define a list of user inputs designed to trigger both internal search (e.g., product architecture) \n",
    "# and external market trend validation.\n",
    "USER_INPUTS = [\n",
    "    \"What are the characteristics and architecture of Product A?\",\n",
    "    \"What are the key features from Dexcom G7 CGM System?\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    for user_input in USER_INPUTS:\n",
    "        # Add the user input as a chat message\n",
    "        await validation_agent.add_chat_message(thread_id=thread.id, message=user_input)\n",
    "        print(f\"üë§ **User:** {user_input}\\n\")\n",
    "        \n",
    "        # Invoke the agent for the specified thread and stream the response\n",
    "        async for content in validation_agent.invoke(thread_id=thread.id):\n",
    "            # Only print non-tool messages\n",
    "            if content.role != AuthorRole.TOOL:\n",
    "                print(f\"ü§ñ **Agent:** {content.content}\\n\")\n",
    "                \n",
    "except HttpResponseError as e:\n",
    "    try:\n",
    "        error_json = json.loads(e.response.content)\n",
    "        logger.error(f\"‚ùå **Error Message:** {error_json.get('Message')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"‚ùå **Non-JSON Error Content:** {e.response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Creating Multi Agent System**\n",
    "\n",
    "The following sample demonstrates how to create an OpenAI assistant using either Azure OpenAI or OpenAI, a chat completion agent and have them participate in a group chat to work towards the user's requirement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import AgentGroupChat\n",
    "from semantic_kernel.agents.azure_ai import AzureAIAgent\n",
    "from semantic_kernel.agents.strategies import TerminationStrategy, KernelFunctionSelectionStrategy\n",
    "from semantic_kernel.functions import KernelFunctionFromPrompt\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 2) A Custom Termination Strategy\n",
    "###############################################################################\n",
    "class ApprovalTerminationStrategy(TerminationStrategy):\n",
    "    \"\"\"\n",
    "    Ends the conversation if the Evaluator agent's last output includes the word 'approved'.\n",
    "    \"\"\"\n",
    "    def __init__(self, agents, maximum_iterations=10):\n",
    "        super().__init__(maximum_iterations=maximum_iterations)\n",
    "        self.agents = agents\n",
    "\n",
    "    async def should_agent_terminate(self, agent, history) -> bool:\n",
    "        # We assume the Evaluator is among self.agents\n",
    "        # If the final content from the Evaluator includes 'approved', we end\n",
    "        last_msg = history[-1]\n",
    "        return (last_msg.name in [a.name for a in self.agents]) and (\"approved\" in last_msg.content.lower())\n",
    "\n",
    "###############################################################################\n",
    "# 3) Creating a Kernel for the Selection Function\n",
    "###############################################################################\n",
    "def _create_kernel_with_chat_completion(service_id: str) -> Kernel:\n",
    "    \"\"\"\n",
    "    Creates a Semantic Kernel instance with an Azure OpenAI chat completion service.\n",
    "    Make sure you have environment variables for your Azure OpenAI keys/endpoint.\n",
    "    \"\"\"\n",
    "    from semantic_kernel import Kernel\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    kernel = Kernel()\n",
    "    # Retrieve environment vars (adjust to your naming)\n",
    "    AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "    AZURE_OPENAI_API_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "    AZURE_AOAI_CHAT_MODEL_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_ID\")  \n",
    "\n",
    "    # Register an Azure Chat Completion service in the kernel\n",
    "    kernel.add_service(\n",
    "        service=AzureChatCompletion(\n",
    "            deployment_name=AZURE_AOAI_CHAT_MODEL_DEPLOYMENT,\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            endpoint=AZURE_OPENAI_API_ENDPOINT,\n",
    "            api_version=AZURE_OPENAI_API_VERSION,\n",
    "        )\n",
    "    )\n",
    "    return kernel\n",
    "\n",
    "###############################################################################\n",
    "# 4) Example LLM Prompt for Multi-Agent Turn Selection\n",
    "###############################################################################\n",
    "RETRIEVER_NAME = \"ValidationInsightsAgent\"\n",
    "EVALUATOR_NAME = \"DataRetrievalAgent\"\n",
    "\n",
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\",\n",
    "    prompt=f\"\"\"\n",
    "Determine which participant takes the next turn in a conversation based on the most recent participant.\n",
    "State only the name of the participant to take the next turn.\n",
    "No participant should take more than one turn in a row.\n",
    "\n",
    "Choose only from these participants:\n",
    "- {RETRIEVER_NAME}\n",
    "- {EVALUATOR_NAME}\n",
    "\n",
    "Always follow these rules when selecting the next participant:\n",
    "- {RETRIEVER_NAME} retrieving the document or relevant data the query.\n",
    "- After {RETRIEVER_NAME}, it is {EVALUATOR_NAME}'s turn to evaluate the content.\n",
    "- After {EVALUATOR_NAME}, the workflow may terminate if 'approved'.\n",
    "\n",
    "History:\n",
    "{{{{$history}}}}\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 5) Utility Logging For Agent Interaction\n",
    "###############################################################################\n",
    "def log_agent_invocation(agent_name: str, role: str, input_data: str, output_data: str):\n",
    "    trace_data = {\n",
    "        \"agent_name\": agent_name,\n",
    "        \"role\": role,\n",
    "        \"input\": input_data,\n",
    "        \"output\": output_data,\n",
    "    }\n",
    "    logger.info(\"AGENT INVOCATION:\\n\" + json.dumps(trace_data, indent=4))\n",
    "\n",
    "###############################################################################\n",
    "# 6) Main Async Function\n",
    "###############################################################################\n",
    "async def main():\n",
    "    # 2. Initialize the credential & AzureAIAgent client\n",
    "    async with (\n",
    "        DefaultAzureCredential() as creds,\n",
    "        AzureAIAgent.create_client(credential=creds) as client,\n",
    "    ):\n",
    "        # Pre-existing Azure AI Agents (IDs from your environment)\n",
    "        ValidationInsightsAgentID = \"asst_kdFT72VdYH0YpoG3tJ5lmoFy\"\n",
    "        DataRetrievalAgentID = \"asst_Wo0GJ9MpmvkfRPNwllC7bYFS\"\n",
    "\n",
    "        # 3. Retrieve each agent definition from your Azure AI Agent Service\n",
    "        #    Assume the Formulator & Evaluator are the same agent or different? \n",
    "        #    Below, just demonstrating you might have 2 definitions for 3 roles.\n",
    "        dataretrieval_def = await client.agents.get_agent(agent_id=DataRetrievalAgentID)\n",
    "        validation_def = await client.agents.get_agent(agent_id=ValidationInsightsAgentID)\n",
    "\n",
    "        # 4. Build SK Agents from these definitions\n",
    "        agent_retriever = AzureAIAgent(client=client, definition=dataretrieval_def)\n",
    "        agent_evaluator = AzureAIAgent(client=client, definition=validation_def)\n",
    "\n",
    "        # 5. Setup the multi-agent chat\n",
    "        chat = AgentGroupChat(\n",
    "            agents=[agent_retriever, agent_evaluator],\n",
    "            termination_strategy=ApprovalTerminationStrategy(\n",
    "                maximum_iterations=10,\n",
    "                agents=[agent_evaluator],  # The Evaluator decides final approval\n",
    "            ),\n",
    "            selection_strategy=KernelFunctionSelectionStrategy(\n",
    "                function=selection_function,\n",
    "                kernel=_create_kernel_with_chat_completion(\"selection\"),\n",
    "                # We parse the output of the LLM prompt to choose next agent\n",
    "                result_parser=lambda result: str(result.value[0]) if result.value else EVALUATOR_NAME,\n",
    "                agent_variable_name=\"agents\",   # the variable in the prompt\n",
    "                history_variable_name=\"history\", # the variable in the prompt\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Example user system or user message\n",
    "        system_message = \"\"\"\n",
    "        You are orchestrating a multi-step R&D conversation between two roles: \n",
    "        1) Retriever ‚Äì gathers internal data from Fabric/SharePoint and external references from Bing/Azure Search.\n",
    "        2) Evaluator ‚Äì cross-validates the retrieved data, identifies missing insights, and decides if it is 'approved' or if more data is needed.\n",
    "\n",
    "        **Demo Flow: AI-Powered R&D and Product Design**\n",
    "        1. A researcher initiates a query for internal experiment data and external market trends to refine a new product design.\n",
    "        2. Retriever queries Fabric AI Skill for structured results (e.g., experiment data), and SharePoint for related research papers, engineering reports, and design notes.\n",
    "        3. Evaluator checks the alignment between internal test results and external market or regulatory feedback. Identifies any conflicting standards or data gaps. If needed, it reruns queries for additional sources.\n",
    "        4. The system compiles an AI-generated report summarizing key findings, highlighting risk factors, data gaps, and actionable recommendations.\n",
    "        5. The researcher can ask follow-up questions about materials, regulatory risks, or design improvements. \n",
    "\n",
    "        The user can keep asking questions until the Evaluator decides it is 'approved' (final answer) or more data is required.\n",
    "        \"\"\"\n",
    "        await chat.add_chat_message(message=system_message)\n",
    "        logger.info(f\"System Setup: {system_message}\")\n",
    "\n",
    "        # Updated user message introducing the high-level request\n",
    "        user_message = \"\"\"\n",
    "        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\n",
    "        \"\"\"\n",
    "        await chat.add_chat_message(message=user_message)\n",
    "        logger.info(f\"User Input: {user_message}\")\n",
    "\n",
    "        # 6. Real-time streaming of conversation\n",
    "        try:\n",
    "            last_input = user_message\n",
    "            async for content in chat.invoke():\n",
    "                agent_name = content.name or \"Unknown\"\n",
    "                agent_role = content.role.name\n",
    "                agent_output = content.content\n",
    "\n",
    "                # Log invocation\n",
    "                log_agent_invocation(agent_name, agent_role, last_input, agent_output)\n",
    "\n",
    "                # Print\n",
    "                print(f\"{agent_role} - {agent_name}: {agent_output}\")\n",
    "\n",
    "                last_input = agent_output\n",
    "\n",
    "            logger.info(f\"Workflow Complete? {chat.is_complete}\")\n",
    "\n",
    "        except HttpResponseError as err:\n",
    "            logger.error(f\"Error while streaming conversation: {err}\")\n",
    "\n",
    "        finally:\n",
    "            # 7. Optionally reset or cleanup if ephemeral\n",
    "            await chat.reset()\n",
    "            # If you'd like to delete ephemeral agent definitions, do so here\n",
    "            # e.g., await client.agents.delete_agent(DataRetrievalAgentID)\n",
    "            #       await client.agents.delete_agent(ValidationInsightsAgentID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 11:45:19,948 - micro - MainProcess - INFO     System Setup: \n",
      "        You are orchestrating a multi-step R&D conversation between two roles: \n",
      "        1) Retriever ‚Äì gathers internal data from Fabric/SharePoint and external references from Bing/Azure Search.\n",
      "        2) Evaluator ‚Äì cross-validates the retrieved data, identifies missing insights, and decides if it is 'approved' or if more data is needed.\n",
      "\n",
      "        **Demo Flow: AI-Powered R&D and Product Design**\n",
      "        1. A researcher initiates a query for internal experiment data and external market trends to refine a new product design.\n",
      "        2. Retriever queries Fabric AI Skill for structured results (e.g., experiment data), and SharePoint for related research papers, engineering reports, and design notes.\n",
      "        3. Evaluator checks the alignment between internal test results and external market or regulatory feedback. Identifies any conflicting standards or data gaps. If needed, it reruns queries for additional sources.\n",
      "        4. The system compiles an AI-generated report summarizing key findings, highlighting risk factors, data gaps, and actionable recommendations.\n",
      "        5. The researcher can ask follow-up questions about materials, regulatory risks, or design improvements. \n",
      "\n",
      "        The user can keep asking questions until the Evaluator decides it is 'approved' (final answer) or more data is required.\n",
      "         (178594159.py:main:156)\n",
      "INFO:micro:System Setup: \n",
      "        You are orchestrating a multi-step R&D conversation between two roles: \n",
      "        1) Retriever ‚Äì gathers internal data from Fabric/SharePoint and external references from Bing/Azure Search.\n",
      "        2) Evaluator ‚Äì cross-validates the retrieved data, identifies missing insights, and decides if it is 'approved' or if more data is needed.\n",
      "\n",
      "        **Demo Flow: AI-Powered R&D and Product Design**\n",
      "        1. A researcher initiates a query for internal experiment data and external market trends to refine a new product design.\n",
      "        2. Retriever queries Fabric AI Skill for structured results (e.g., experiment data), and SharePoint for related research papers, engineering reports, and design notes.\n",
      "        3. Evaluator checks the alignment between internal test results and external market or regulatory feedback. Identifies any conflicting standards or data gaps. If needed, it reruns queries for additional sources.\n",
      "        4. The system compiles an AI-generated report summarizing key findings, highlighting risk factors, data gaps, and actionable recommendations.\n",
      "        5. The researcher can ask follow-up questions about materials, regulatory risks, or design improvements. \n",
      "\n",
      "        The user can keep asking questions until the Evaluator decides it is 'approved' (final answer) or more data is required.\n",
      "        \n",
      "2025-03-20 11:45:19,951 - micro - MainProcess - INFO     User Input: \n",
      "        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\n",
      "         (178594159.py:main:163)\n",
      "INFO:micro:User Input: \n",
      "        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\n",
      "        \n",
      "2025-03-20 11:46:11,744 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"\\n        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\\n        \",\n",
      "    \"output\": \"### Product A: Characteristics and Architecture\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system developed by Contoso Enterprise. Below is a summary of its key characteristics and architecture:\\n\\n#### **1. Sensor Module**\\n- **Design & Construction**:\\n  - **Sensor Core**: Factory-calibrated electrochemical sensor measures interstitial glucose every 5 minutes.\\n  - **Protective Membrane**: Micro-porous, biocompatible membrane minimizes biofouling and interference.\\n  - **Adhesive and Patch**: Hypoallergenic adhesive patch supports long-term wear (up to 10 days) with an overpatch for additional durability during physical activities.\\n\\n#### **2. Transmitter and Communication Layer**\\n- **Low-Power Transmitter**: Converts analog sensor signals to digital data every 5 minutes, with a battery life supporting a full sensor session and a 12-hour grace period.\\n- **Data Connectivity**:\\n  - **Wireless Transmission**: Secure Bluetooth connectivity (AES-256 encryption) to paired devices.\\n  - **Data Buffering**: Stores up to 24 hours of data in case of temporary connection loss.\\n  - **Interoperability**: Supports open API for integration with third-party devices like smart insulin pens.\\n\\n#### **3. Software and Analytics**\\n- **Mobile Application and Receiver Interface**:\\n  - **Mobile App**: Real-time display of sensor readings and customizable alert settings.\\n  - **Dedicated Receiver**: Simplified interface for standalone use; supports data sharing via secure cloud.\\n- **Cloud-Based Data Management**:\\n  - **Advanced Analytics**: Generates comprehensive reports and includes an adaptive machine learning algorithm for personalized insights on insulin dosing and lifestyle adjustments in future updates.\\n\\n#### **4. Clinical Testing Trials**\\n- **Phase I \\u2013 Beta Testing**: \\n  - **Participants**: 40 adults with type 1 and insulin-dependent type 2 diabetes.\\n  - **Key Outcomes**: MARD of 8.7%, 90% rated the device as \\u201cpainless\\u201d, and data availability of 99.4%.\\n- **Phase II \\u2013 Pivotal Clinical Trial**:\\n  - **Sample Size**: 200 adult participants.\\n  - **Preliminary Results**: MARD of 8.5% in normoglycemia, no serious device-related adverse events.\\n\\nThe system\\u2019s design integrates state-of-the-art sensor technology, robust data transmission, and user-friendly interfaces, ensuring high accuracy, reliable data capture, and overall usability\\u30105:0\\u2020source\\u3011\\u30105:1\\u2020source\\u3011\\u30105:2\\u2020source\\u3011\\u30105:3\\u2020source\\u3011\\u30105:4\\u2020source\\u3011.\\n\\n### Market Insights and Competitor Analysis\\n\\nTo provide insights into the market for similar products and competitor analysis, I will now search for external references and our internal research team\\u2019s analysis on other products. \\n\\nI will proceed with the following steps:\\n1. Conduct a search for market trends and similar products.\\n2. Retrieve internal documents related to competitor analysis of other products.\\n\\nPlease hold on while I gather this information.\"\n",
      "} (178594159.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"\\n        What are the characteristics and architecture of Product A? Please research the market for similar products and gather insights from our research team. What other products have we done competitor analysis on?\\n        \",\n",
      "    \"output\": \"### Product A: Characteristics and Architecture\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system developed by Contoso Enterprise. Below is a summary of its key characteristics and architecture:\\n\\n#### **1. Sensor Module**\\n- **Design & Construction**:\\n  - **Sensor Core**: Factory-calibrated electrochemical sensor measures interstitial glucose every 5 minutes.\\n  - **Protective Membrane**: Micro-porous, biocompatible membrane minimizes biofouling and interference.\\n  - **Adhesive and Patch**: Hypoallergenic adhesive patch supports long-term wear (up to 10 days) with an overpatch for additional durability during physical activities.\\n\\n#### **2. Transmitter and Communication Layer**\\n- **Low-Power Transmitter**: Converts analog sensor signals to digital data every 5 minutes, with a battery life supporting a full sensor session and a 12-hour grace period.\\n- **Data Connectivity**:\\n  - **Wireless Transmission**: Secure Bluetooth connectivity (AES-256 encryption) to paired devices.\\n  - **Data Buffering**: Stores up to 24 hours of data in case of temporary connection loss.\\n  - **Interoperability**: Supports open API for integration with third-party devices like smart insulin pens.\\n\\n#### **3. Software and Analytics**\\n- **Mobile Application and Receiver Interface**:\\n  - **Mobile App**: Real-time display of sensor readings and customizable alert settings.\\n  - **Dedicated Receiver**: Simplified interface for standalone use; supports data sharing via secure cloud.\\n- **Cloud-Based Data Management**:\\n  - **Advanced Analytics**: Generates comprehensive reports and includes an adaptive machine learning algorithm for personalized insights on insulin dosing and lifestyle adjustments in future updates.\\n\\n#### **4. Clinical Testing Trials**\\n- **Phase I \\u2013 Beta Testing**: \\n  - **Participants**: 40 adults with type 1 and insulin-dependent type 2 diabetes.\\n  - **Key Outcomes**: MARD of 8.7%, 90% rated the device as \\u201cpainless\\u201d, and data availability of 99.4%.\\n- **Phase II \\u2013 Pivotal Clinical Trial**:\\n  - **Sample Size**: 200 adult participants.\\n  - **Preliminary Results**: MARD of 8.5% in normoglycemia, no serious device-related adverse events.\\n\\nThe system\\u2019s design integrates state-of-the-art sensor technology, robust data transmission, and user-friendly interfaces, ensuring high accuracy, reliable data capture, and overall usability\\u30105:0\\u2020source\\u3011\\u30105:1\\u2020source\\u3011\\u30105:2\\u2020source\\u3011\\u30105:3\\u2020source\\u3011\\u30105:4\\u2020source\\u3011.\\n\\n### Market Insights and Competitor Analysis\\n\\nTo provide insights into the market for similar products and competitor analysis, I will now search for external references and our internal research team\\u2019s analysis on other products. \\n\\nI will proceed with the following steps:\\n1. Conduct a search for market trends and similar products.\\n2. Retrieve internal documents related to competitor analysis of other products.\\n\\nPlease hold on while I gather this information.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - ValidationInsightsAgent: ### Product A: Characteristics and Architecture\n",
      "\n",
      "**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system developed by Contoso Enterprise. Below is a summary of its key characteristics and architecture:\n",
      "\n",
      "#### **1. Sensor Module**\n",
      "- **Design & Construction**:\n",
      "  - **Sensor Core**: Factory-calibrated electrochemical sensor measures interstitial glucose every 5 minutes.\n",
      "  - **Protective Membrane**: Micro-porous, biocompatible membrane minimizes biofouling and interference.\n",
      "  - **Adhesive and Patch**: Hypoallergenic adhesive patch supports long-term wear (up to 10 days) with an overpatch for additional durability during physical activities.\n",
      "\n",
      "#### **2. Transmitter and Communication Layer**\n",
      "- **Low-Power Transmitter**: Converts analog sensor signals to digital data every 5 minutes, with a battery life supporting a full sensor session and a 12-hour grace period.\n",
      "- **Data Connectivity**:\n",
      "  - **Wireless Transmission**: Secure Bluetooth connectivity (AES-256 encryption) to paired devices.\n",
      "  - **Data Buffering**: Stores up to 24 hours of data in case of temporary connection loss.\n",
      "  - **Interoperability**: Supports open API for integration with third-party devices like smart insulin pens.\n",
      "\n",
      "#### **3. Software and Analytics**\n",
      "- **Mobile Application and Receiver Interface**:\n",
      "  - **Mobile App**: Real-time display of sensor readings and customizable alert settings.\n",
      "  - **Dedicated Receiver**: Simplified interface for standalone use; supports data sharing via secure cloud.\n",
      "- **Cloud-Based Data Management**:\n",
      "  - **Advanced Analytics**: Generates comprehensive reports and includes an adaptive machine learning algorithm for personalized insights on insulin dosing and lifestyle adjustments in future updates.\n",
      "\n",
      "#### **4. Clinical Testing Trials**\n",
      "- **Phase I ‚Äì Beta Testing**: \n",
      "  - **Participants**: 40 adults with type 1 and insulin-dependent type 2 diabetes.\n",
      "  - **Key Outcomes**: MARD of 8.7%, 90% rated the device as ‚Äúpainless‚Äù, and data availability of 99.4%.\n",
      "- **Phase II ‚Äì Pivotal Clinical Trial**:\n",
      "  - **Sample Size**: 200 adult participants.\n",
      "  - **Preliminary Results**: MARD of 8.5% in normoglycemia, no serious device-related adverse events.\n",
      "\n",
      "The system‚Äôs design integrates state-of-the-art sensor technology, robust data transmission, and user-friendly interfaces, ensuring high accuracy, reliable data capture, and overall usability„Äê5:0‚Ä†source„Äë„Äê5:1‚Ä†source„Äë„Äê5:2‚Ä†source„Äë„Äê5:3‚Ä†source„Äë„Äê5:4‚Ä†source„Äë.\n",
      "\n",
      "### Market Insights and Competitor Analysis\n",
      "\n",
      "To provide insights into the market for similar products and competitor analysis, I will now search for external references and our internal research team‚Äôs analysis on other products. \n",
      "\n",
      "I will proceed with the following steps:\n",
      "1. Conduct a search for market trends and similar products.\n",
      "2. Retrieve internal documents related to competitor analysis of other products.\n",
      "\n",
      "Please hold on while I gather this information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 11:46:12,047 - micro - MainProcess - INFO     AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"### Product A: Characteristics and Architecture\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system developed by Contoso Enterprise. Below is a summary of its key characteristics and architecture:\\n\\n#### **1. Sensor Module**\\n- **Design & Construction**:\\n  - **Sensor Core**: Factory-calibrated electrochemical sensor measures interstitial glucose every 5 minutes.\\n  - **Protective Membrane**: Micro-porous, biocompatible membrane minimizes biofouling and interference.\\n  - **Adhesive and Patch**: Hypoallergenic adhesive patch supports long-term wear (up to 10 days) with an overpatch for additional durability during physical activities.\\n\\n#### **2. Transmitter and Communication Layer**\\n- **Low-Power Transmitter**: Converts analog sensor signals to digital data every 5 minutes, with a battery life supporting a full sensor session and a 12-hour grace period.\\n- **Data Connectivity**:\\n  - **Wireless Transmission**: Secure Bluetooth connectivity (AES-256 encryption) to paired devices.\\n  - **Data Buffering**: Stores up to 24 hours of data in case of temporary connection loss.\\n  - **Interoperability**: Supports open API for integration with third-party devices like smart insulin pens.\\n\\n#### **3. Software and Analytics**\\n- **Mobile Application and Receiver Interface**:\\n  - **Mobile App**: Real-time display of sensor readings and customizable alert settings.\\n  - **Dedicated Receiver**: Simplified interface for standalone use; supports data sharing via secure cloud.\\n- **Cloud-Based Data Management**:\\n  - **Advanced Analytics**: Generates comprehensive reports and includes an adaptive machine learning algorithm for personalized insights on insulin dosing and lifestyle adjustments in future updates.\\n\\n#### **4. Clinical Testing Trials**\\n- **Phase I \\u2013 Beta Testing**: \\n  - **Participants**: 40 adults with type 1 and insulin-dependent type 2 diabetes.\\n  - **Key Outcomes**: MARD of 8.7%, 90% rated the device as \\u201cpainless\\u201d, and data availability of 99.4%.\\n- **Phase II \\u2013 Pivotal Clinical Trial**:\\n  - **Sample Size**: 200 adult participants.\\n  - **Preliminary Results**: MARD of 8.5% in normoglycemia, no serious device-related adverse events.\\n\\nThe system\\u2019s design integrates state-of-the-art sensor technology, robust data transmission, and user-friendly interfaces, ensuring high accuracy, reliable data capture, and overall usability\\u30105:0\\u2020source\\u3011\\u30105:1\\u2020source\\u3011\\u30105:2\\u2020source\\u3011\\u30105:3\\u2020source\\u3011\\u30105:4\\u2020source\\u3011.\\n\\n### Market Insights and Competitor Analysis\\n\\nTo provide insights into the market for similar products and competitor analysis, I will now search for external references and our internal research team\\u2019s analysis on other products. \\n\\nI will proceed with the following steps:\\n1. Conduct a search for market trends and similar products.\\n2. Retrieve internal documents related to competitor analysis of other products.\\n\\nPlease hold on while I gather this information.\",\n",
      "    \"output\": \"### Product A: Characteristics and Architecture\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system developed by Contoso Enterprise. Below is a summary of its key characteristics and architecture:\\n\\n#### **1. Sensor Module**\\n- **Design & Construction**:\\n  - **Sensor Core**: Factory-calibrated electrochemical sensor measures interstitial glucose every 5 minutes.\\n  - **Protective Membrane**: Micro-porous, biocompatible membrane minimizes biofouling and interference.\\n  - **Adhesive and Patch**: Hypoallergenic adhesive patch supports long-term wear (up to 10 days) with an overpatch for additional durability during physical activities.\\n\\n#### **2. Transmitter and Communication Layer**\\n- **Low-Power Transmitter**: Converts analog sensor signals to digital data every 5 minutes, with a battery life supporting a full sensor session and a 12-hour grace period.\\n- **Data Connectivity**:\\n  - **Wireless Transmission**: Secure Bluetooth connectivity (AES-256 encryption) to paired devices.\\n  - **Data Buffering**: Stores up to 24 hours of data in case of temporary connection loss.\\n  - **Interoperability**: Supports open API for integration with third-party devices like smart insulin pens.\\n\\n#### **3. Software and Analytics**\\n- **Mobile Application and Receiver Interface**:\\n  - **Mobile App**: Real-time display of sensor readings and customizable alert settings.\\n  - **Dedicated Receiver**: Simplified interface for standalone use; supports data sharing via secure cloud.\\n- **Cloud-Based Data Management**:\\n  - **Advanced Analytics**: Generates comprehensive reports and includes an adaptive machine learning algorithm for personalized insights on insulin dosing and lifestyle adjustments in future updates.\\n\\n#### **4. Clinical Testing Trials**\\n- **Phase I \\u2013 Beta Testing**: \\n  - **Participants**: 40 adults with type 1 and insulin-dependent type 2 diabetes.\\n  - **Key Outcomes**: MARD of 8.7%, 90% rated the device as \\u201cpainless\\u201d, and data availability of 99.4%.\\n- **Phase II \\u2013 Pivotal Clinical Trial**:\\n  - **Sample Size**: 200 adult participants.\\n  - **Preliminary Results**: MARD of 8.5% in normoglycemia, no serious device-related adverse events.\\n\\nThe system\\u2019s design integrates state-of-the-art sensor technology, robust data transmission, and user-friendly interfaces, ensuring high accuracy, reliable data capture, and overall usability\\u30105:0\\u2020source\\u3011\\u30105:1\\u2020source\\u3011\\u30105:2\\u2020source\\u3011\\u30105:3\\u2020source\\u3011\\u30105:4\\u2020source\\u3011.\\n\\n### Market Insights and Competitor Analysis\\n\\n#### **Market Trends for Continuous Glucose Monitoring Systems**\\nThe continuous glucose monitoring (CGM) market is witnessing significant growth driven by increasing diabetes prevalence, advancements in sensor technologies, and rising awareness about diabetes management. Key trends include:\\n- **Integration with Insulin Delivery Devices**: CGM systems are increasingly being integrated with insulin pumps and smart pens to provide a comprehensive diabetes management solution.\\n- **AI and Machine Learning**: Enhanced data analytics and predictive algorithms are being incorporated to provide personalized insights and improve glycemic control.\\n- **Wearability and User Comfort**: Innovations are focusing on reducing sensor size, improving adhesive patches, and extending sensor wear duration to enhance user comfort and compliance.\\n\\n#### **Competitor Analysis**\\nOur internal research team has conducted competitor analysis on several leading CGM products, including:\\n- **Dexcom G6**:\\n  - **Accuracy**: MARD of approximately 9%.\\n  - **Wear Duration**: Up to 10 days.\\n  - **Key Features**: Real-time glucose monitoring, customizable alerts, and integration with various digital health platforms.\\n- **Abbott FreeStyle Libre 3**:\\n  - **Accuracy**: MARD of approximately 9.2%.\\n  - **Wear Duration**: Up to 14 days.\\n  - **Key Features**: Continuous glucose readings without fingersticks, small and discreet sensor, and mobile app integration.\\n- **Medtronic Guardian Connect**:\\n  - **Accuracy**: MARD of approximately 8.7%.\\n  - **Wear Duration**: Up to 7 days.\\n  - **Key Features**: Predictive alerts, real-time data sharing with caregivers, and integration with Medtronic insulin pumps.\\n\\nThese analyses help us benchmark Product A against leading competitors, ensuring our product remains competitive in terms of accuracy, user experience, and technological integration\\u30105:0\\u2020source\\u3011\\u301010:1\\u2020source\\u3011\\u301010:2\\u2020source\\u3011\\u301010:3\\u2020source\\u3011.\\n\\n### Conclusion\\nProduct A stands as a promising solution in the evolving landscape of diabetes management, with high accuracy, robust data transmission, and user-friendly interfaces. Continuous improvement in sensor wear duration, pediatric adaptations, and AI-driven insights will further enhance its market position and user satisfaction.\\n\\nIf you have any follow-up questions regarding materials, regulatory risks, or design improvements, please let me know.\"\n",
      "} (178594159.py:log_agent_invocation:98)\n",
      "INFO:micro:AGENT INVOCATION:\n",
      "{\n",
      "    \"agent_name\": \"ValidationInsightsAgent\",\n",
      "    \"role\": \"ASSISTANT\",\n",
      "    \"input\": \"### Product A: Characteristics and Architecture\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system developed by Contoso Enterprise. Below is a summary of its key characteristics and architecture:\\n\\n#### **1. Sensor Module**\\n- **Design & Construction**:\\n  - **Sensor Core**: Factory-calibrated electrochemical sensor measures interstitial glucose every 5 minutes.\\n  - **Protective Membrane**: Micro-porous, biocompatible membrane minimizes biofouling and interference.\\n  - **Adhesive and Patch**: Hypoallergenic adhesive patch supports long-term wear (up to 10 days) with an overpatch for additional durability during physical activities.\\n\\n#### **2. Transmitter and Communication Layer**\\n- **Low-Power Transmitter**: Converts analog sensor signals to digital data every 5 minutes, with a battery life supporting a full sensor session and a 12-hour grace period.\\n- **Data Connectivity**:\\n  - **Wireless Transmission**: Secure Bluetooth connectivity (AES-256 encryption) to paired devices.\\n  - **Data Buffering**: Stores up to 24 hours of data in case of temporary connection loss.\\n  - **Interoperability**: Supports open API for integration with third-party devices like smart insulin pens.\\n\\n#### **3. Software and Analytics**\\n- **Mobile Application and Receiver Interface**:\\n  - **Mobile App**: Real-time display of sensor readings and customizable alert settings.\\n  - **Dedicated Receiver**: Simplified interface for standalone use; supports data sharing via secure cloud.\\n- **Cloud-Based Data Management**:\\n  - **Advanced Analytics**: Generates comprehensive reports and includes an adaptive machine learning algorithm for personalized insights on insulin dosing and lifestyle adjustments in future updates.\\n\\n#### **4. Clinical Testing Trials**\\n- **Phase I \\u2013 Beta Testing**: \\n  - **Participants**: 40 adults with type 1 and insulin-dependent type 2 diabetes.\\n  - **Key Outcomes**: MARD of 8.7%, 90% rated the device as \\u201cpainless\\u201d, and data availability of 99.4%.\\n- **Phase II \\u2013 Pivotal Clinical Trial**:\\n  - **Sample Size**: 200 adult participants.\\n  - **Preliminary Results**: MARD of 8.5% in normoglycemia, no serious device-related adverse events.\\n\\nThe system\\u2019s design integrates state-of-the-art sensor technology, robust data transmission, and user-friendly interfaces, ensuring high accuracy, reliable data capture, and overall usability\\u30105:0\\u2020source\\u3011\\u30105:1\\u2020source\\u3011\\u30105:2\\u2020source\\u3011\\u30105:3\\u2020source\\u3011\\u30105:4\\u2020source\\u3011.\\n\\n### Market Insights and Competitor Analysis\\n\\nTo provide insights into the market for similar products and competitor analysis, I will now search for external references and our internal research team\\u2019s analysis on other products. \\n\\nI will proceed with the following steps:\\n1. Conduct a search for market trends and similar products.\\n2. Retrieve internal documents related to competitor analysis of other products.\\n\\nPlease hold on while I gather this information.\",\n",
      "    \"output\": \"### Product A: Characteristics and Architecture\\n\\n**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system developed by Contoso Enterprise. Below is a summary of its key characteristics and architecture:\\n\\n#### **1. Sensor Module**\\n- **Design & Construction**:\\n  - **Sensor Core**: Factory-calibrated electrochemical sensor measures interstitial glucose every 5 minutes.\\n  - **Protective Membrane**: Micro-porous, biocompatible membrane minimizes biofouling and interference.\\n  - **Adhesive and Patch**: Hypoallergenic adhesive patch supports long-term wear (up to 10 days) with an overpatch for additional durability during physical activities.\\n\\n#### **2. Transmitter and Communication Layer**\\n- **Low-Power Transmitter**: Converts analog sensor signals to digital data every 5 minutes, with a battery life supporting a full sensor session and a 12-hour grace period.\\n- **Data Connectivity**:\\n  - **Wireless Transmission**: Secure Bluetooth connectivity (AES-256 encryption) to paired devices.\\n  - **Data Buffering**: Stores up to 24 hours of data in case of temporary connection loss.\\n  - **Interoperability**: Supports open API for integration with third-party devices like smart insulin pens.\\n\\n#### **3. Software and Analytics**\\n- **Mobile Application and Receiver Interface**:\\n  - **Mobile App**: Real-time display of sensor readings and customizable alert settings.\\n  - **Dedicated Receiver**: Simplified interface for standalone use; supports data sharing via secure cloud.\\n- **Cloud-Based Data Management**:\\n  - **Advanced Analytics**: Generates comprehensive reports and includes an adaptive machine learning algorithm for personalized insights on insulin dosing and lifestyle adjustments in future updates.\\n\\n#### **4. Clinical Testing Trials**\\n- **Phase I \\u2013 Beta Testing**: \\n  - **Participants**: 40 adults with type 1 and insulin-dependent type 2 diabetes.\\n  - **Key Outcomes**: MARD of 8.7%, 90% rated the device as \\u201cpainless\\u201d, and data availability of 99.4%.\\n- **Phase II \\u2013 Pivotal Clinical Trial**:\\n  - **Sample Size**: 200 adult participants.\\n  - **Preliminary Results**: MARD of 8.5% in normoglycemia, no serious device-related adverse events.\\n\\nThe system\\u2019s design integrates state-of-the-art sensor technology, robust data transmission, and user-friendly interfaces, ensuring high accuracy, reliable data capture, and overall usability\\u30105:0\\u2020source\\u3011\\u30105:1\\u2020source\\u3011\\u30105:2\\u2020source\\u3011\\u30105:3\\u2020source\\u3011\\u30105:4\\u2020source\\u3011.\\n\\n### Market Insights and Competitor Analysis\\n\\n#### **Market Trends for Continuous Glucose Monitoring Systems**\\nThe continuous glucose monitoring (CGM) market is witnessing significant growth driven by increasing diabetes prevalence, advancements in sensor technologies, and rising awareness about diabetes management. Key trends include:\\n- **Integration with Insulin Delivery Devices**: CGM systems are increasingly being integrated with insulin pumps and smart pens to provide a comprehensive diabetes management solution.\\n- **AI and Machine Learning**: Enhanced data analytics and predictive algorithms are being incorporated to provide personalized insights and improve glycemic control.\\n- **Wearability and User Comfort**: Innovations are focusing on reducing sensor size, improving adhesive patches, and extending sensor wear duration to enhance user comfort and compliance.\\n\\n#### **Competitor Analysis**\\nOur internal research team has conducted competitor analysis on several leading CGM products, including:\\n- **Dexcom G6**:\\n  - **Accuracy**: MARD of approximately 9%.\\n  - **Wear Duration**: Up to 10 days.\\n  - **Key Features**: Real-time glucose monitoring, customizable alerts, and integration with various digital health platforms.\\n- **Abbott FreeStyle Libre 3**:\\n  - **Accuracy**: MARD of approximately 9.2%.\\n  - **Wear Duration**: Up to 14 days.\\n  - **Key Features**: Continuous glucose readings without fingersticks, small and discreet sensor, and mobile app integration.\\n- **Medtronic Guardian Connect**:\\n  - **Accuracy**: MARD of approximately 8.7%.\\n  - **Wear Duration**: Up to 7 days.\\n  - **Key Features**: Predictive alerts, real-time data sharing with caregivers, and integration with Medtronic insulin pumps.\\n\\nThese analyses help us benchmark Product A against leading competitors, ensuring our product remains competitive in terms of accuracy, user experience, and technological integration\\u30105:0\\u2020source\\u3011\\u301010:1\\u2020source\\u3011\\u301010:2\\u2020source\\u3011\\u301010:3\\u2020source\\u3011.\\n\\n### Conclusion\\nProduct A stands as a promising solution in the evolving landscape of diabetes management, with high accuracy, robust data transmission, and user-friendly interfaces. Continuous improvement in sensor wear duration, pediatric adaptations, and AI-driven insights will further enhance its market position and user satisfaction.\\n\\nIf you have any follow-up questions regarding materials, regulatory risks, or design improvements, please let me know.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT - ValidationInsightsAgent: ### Product A: Characteristics and Architecture\n",
      "\n",
      "**Product A** is an advanced integrated continuous glucose monitoring (iCGM) system developed by Contoso Enterprise. Below is a summary of its key characteristics and architecture:\n",
      "\n",
      "#### **1. Sensor Module**\n",
      "- **Design & Construction**:\n",
      "  - **Sensor Core**: Factory-calibrated electrochemical sensor measures interstitial glucose every 5 minutes.\n",
      "  - **Protective Membrane**: Micro-porous, biocompatible membrane minimizes biofouling and interference.\n",
      "  - **Adhesive and Patch**: Hypoallergenic adhesive patch supports long-term wear (up to 10 days) with an overpatch for additional durability during physical activities.\n",
      "\n",
      "#### **2. Transmitter and Communication Layer**\n",
      "- **Low-Power Transmitter**: Converts analog sensor signals to digital data every 5 minutes, with a battery life supporting a full sensor session and a 12-hour grace period.\n",
      "- **Data Connectivity**:\n",
      "  - **Wireless Transmission**: Secure Bluetooth connectivity (AES-256 encryption) to paired devices.\n",
      "  - **Data Buffering**: Stores up to 24 hours of data in case of temporary connection loss.\n",
      "  - **Interoperability**: Supports open API for integration with third-party devices like smart insulin pens.\n",
      "\n",
      "#### **3. Software and Analytics**\n",
      "- **Mobile Application and Receiver Interface**:\n",
      "  - **Mobile App**: Real-time display of sensor readings and customizable alert settings.\n",
      "  - **Dedicated Receiver**: Simplified interface for standalone use; supports data sharing via secure cloud.\n",
      "- **Cloud-Based Data Management**:\n",
      "  - **Advanced Analytics**: Generates comprehensive reports and includes an adaptive machine learning algorithm for personalized insights on insulin dosing and lifestyle adjustments in future updates.\n",
      "\n",
      "#### **4. Clinical Testing Trials**\n",
      "- **Phase I ‚Äì Beta Testing**: \n",
      "  - **Participants**: 40 adults with type 1 and insulin-dependent type 2 diabetes.\n",
      "  - **Key Outcomes**: MARD of 8.7%, 90% rated the device as ‚Äúpainless‚Äù, and data availability of 99.4%.\n",
      "- **Phase II ‚Äì Pivotal Clinical Trial**:\n",
      "  - **Sample Size**: 200 adult participants.\n",
      "  - **Preliminary Results**: MARD of 8.5% in normoglycemia, no serious device-related adverse events.\n",
      "\n",
      "The system‚Äôs design integrates state-of-the-art sensor technology, robust data transmission, and user-friendly interfaces, ensuring high accuracy, reliable data capture, and overall usability„Äê5:0‚Ä†source„Äë„Äê5:1‚Ä†source„Äë„Äê5:2‚Ä†source„Äë„Äê5:3‚Ä†source„Äë„Äê5:4‚Ä†source„Äë.\n",
      "\n",
      "### Market Insights and Competitor Analysis\n",
      "\n",
      "#### **Market Trends for Continuous Glucose Monitoring Systems**\n",
      "The continuous glucose monitoring (CGM) market is witnessing significant growth driven by increasing diabetes prevalence, advancements in sensor technologies, and rising awareness about diabetes management. Key trends include:\n",
      "- **Integration with Insulin Delivery Devices**: CGM systems are increasingly being integrated with insulin pumps and smart pens to provide a comprehensive diabetes management solution.\n",
      "- **AI and Machine Learning**: Enhanced data analytics and predictive algorithms are being incorporated to provide personalized insights and improve glycemic control.\n",
      "- **Wearability and User Comfort**: Innovations are focusing on reducing sensor size, improving adhesive patches, and extending sensor wear duration to enhance user comfort and compliance.\n",
      "\n",
      "#### **Competitor Analysis**\n",
      "Our internal research team has conducted competitor analysis on several leading CGM products, including:\n",
      "- **Dexcom G6**:\n",
      "  - **Accuracy**: MARD of approximately 9%.\n",
      "  - **Wear Duration**: Up to 10 days.\n",
      "  - **Key Features**: Real-time glucose monitoring, customizable alerts, and integration with various digital health platforms.\n",
      "- **Abbott FreeStyle Libre 3**:\n",
      "  - **Accuracy**: MARD of approximately 9.2%.\n",
      "  - **Wear Duration**: Up to 14 days.\n",
      "  - **Key Features**: Continuous glucose readings without fingersticks, small and discreet sensor, and mobile app integration.\n",
      "- **Medtronic Guardian Connect**:\n",
      "  - **Accuracy**: MARD of approximately 8.7%.\n",
      "  - **Wear Duration**: Up to 7 days.\n",
      "  - **Key Features**: Predictive alerts, real-time data sharing with caregivers, and integration with Medtronic insulin pumps.\n",
      "\n",
      "These analyses help us benchmark Product A against leading competitors, ensuring our product remains competitive in terms of accuracy, user experience, and technological integration„Äê5:0‚Ä†source„Äë„Äê10:1‚Ä†source„Äë„Äê10:2‚Ä†source„Äë„Äê10:3‚Ä†source„Äë.\n",
      "\n",
      "### Conclusion\n",
      "Product A stands as a promising solution in the evolving landscape of diabetes management, with high accuracy, robust data transmission, and user-friendly interfaces. Continuous improvement in sensor wear duration, pediatric adaptations, and AI-driven insights will further enhance its market position and user satisfaction.\n",
      "\n",
      "If you have any follow-up questions regarding materials, regulatory risks, or design improvements, please let me know.\n"
     ]
    },
    {
     "ename": "AgentInvokeException",
     "evalue": "Run failed with status: `RunStatus.FAILED` for agent `DataRetrievalAgent` and thread `thread_eT2qkRdpTxTq0n1z2YYA23JP` with error: Error: sharepoint_tool_server_error; Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAgentInvokeException\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main() \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 168\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    167\u001b[39m     last_input = user_message\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m chat.invoke():\n\u001b[32m    169\u001b[39m         agent_name = content.name \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         agent_role = content.role.name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\agents\\group_chat\\agent_group_chat.py:156\u001b[39m, in \u001b[36mAgentGroupChat.invoke\u001b[39m\u001b[34m(self, agent, is_joining)\u001b[39m\n\u001b[32m    153\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[33m\"\u001b[39m\u001b[33mFailed to select agent\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().invoke_agent(selected_agent):\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.role == AuthorRole.ASSISTANT:\n\u001b[32m    158\u001b[39m         task = \u001b[38;5;28mself\u001b[39m.termination_strategy.should_terminate(selected_agent, \u001b[38;5;28mself\u001b[39m.history.messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\agents\\group_chat\\agent_chat.py:149\u001b[39m, in \u001b[36mAgentChat.invoke_agent\u001b[39m\u001b[34m(self, agent)\u001b[39m\n\u001b[32m    146\u001b[39m channel: AgentChannel = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_or_create_channel(agent)\n\u001b[32m    147\u001b[39m messages: \u001b[38;5;28mlist\u001b[39m[ChatMessageContent] = []\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m is_visible, message \u001b[38;5;129;01min\u001b[39;00m channel.invoke(agent):\n\u001b[32m    150\u001b[39m     messages.append(message)\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.history.messages.append(message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\agents\\azure_ai\\azure_ai_channel.py:64\u001b[39m, in \u001b[36mAzureAIChannel.invoke\u001b[39m\u001b[34m(self, agent, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(agent, AzureAIAgent):\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent is not of the expected type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(AzureAIAgent)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m is_visible, message \u001b[38;5;129;01min\u001b[39;00m AgentThreadActions.invoke(\n\u001b[32m     65\u001b[39m     agent=agent,\n\u001b[32m     66\u001b[39m     thread_id=\u001b[38;5;28mself\u001b[39m.thread_id,\n\u001b[32m     67\u001b[39m     arguments=agent.arguments,\n\u001b[32m     68\u001b[39m     kernel=agent.kernel,\n\u001b[32m     69\u001b[39m     **kwargs,\n\u001b[32m     70\u001b[39m ):\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m is_visible, message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages\\semantic_kernel\\agents\\azure_ai\\agent_thread_actions.py:182\u001b[39m, in \u001b[36mAgentThreadActions.invoke\u001b[39m\u001b[34m(cls, agent, thread_id, arguments, kernel, model, instructions_override, additional_instructions, additional_messages, tools, temperature, top_p, max_prompt_tokens, max_completion_tokens, truncation_strategy, response_format, parallel_tool_calls, metadata, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run.last_error \u001b[38;5;129;01mand\u001b[39;00m run.last_error.message:\n\u001b[32m    181\u001b[39m         error_message = run.last_error.message\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AgentInvokeException(\n\u001b[32m    183\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun failed with status: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` for agent `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` and thread `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    184\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    185\u001b[39m     )\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Check if function calling is required\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run.status == \u001b[33m\"\u001b[39m\u001b[33mrequires_action\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(run.required_action, SubmitToolOutputsAction):\n",
      "\u001b[31mAgentInvokeException\u001b[39m: Run failed with status: `RunStatus.FAILED` for agent `DataRetrievalAgent` and thread `thread_eT2qkRdpTxTq0n1z2YYA23JP` with error: Error: sharepoint_tool_server_error; Internal Server Error"
     ]
    }
   ],
   "source": [
    "await main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creting Streamlit App "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import Necessary Modules\n",
    "# Import the required modules in your Python script:\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import streamlit as st\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import AgentGroupChat\n",
    "from semantic_kernel.agents.azure_ai import AzureAIAgent\n",
    "from semantic_kernel.agents.strategies import TerminationStrategy, KernelFunctionSelectionStrategy\n",
    "from semantic_kernel.functions import KernelFunctionFromPrompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the Approval Termination Strategy\n",
    "# Create a custom termination strategy to end the conversation based on specific criteria:\n",
    "\n",
    "class ApprovalTerminationStrategy(TerminationStrategy):\n",
    "    def __init__(self, agents, maximum_iterations=10):\n",
    "        super().__init__(maximum_iterations=maximum_iterations)\n",
    "        self.agents = agents\n",
    "\n",
    "    async def should_agent_terminate(self, agent, history) -> bool:\n",
    "        last_msg = history[-1]\n",
    "        return (last_msg.name in [a.name for a in self.agents]) and (\"approved\" in last_msg.content.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize the Kernel with Chat Completion\n",
    "# Set up the Semantic Kernel with an Azure OpenAI chat completion service:\n",
    "\n",
    "def _create_kernel_with_chat_completion() -> Kernel:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    kernel = Kernel()\n",
    "    AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "    AZURE_OPENAI_API_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "    AZURE_AOAI_CHAT_MODEL_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_MODEL_DEPLOYMENT\", \"gpt-4\")\n",
    "\n",
    "    kernel.add_service(\n",
    "        service=AzureChatCompletion(\n",
    "            deployment_name=AZURE_AOAI_CHAT_MODEL_DEPLOYMENT,\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            endpoint=AZURE_OPENAI_API_ENDPOINT,\n",
    "            api_version=AZURE_OPENAI_API_VERSION,\n",
    "        )\n",
    "    )\n",
    "    return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define the Selection Function Prompt\n",
    "# Create a prompt to determine the next participant in the conversation:\n",
    "\n",
    "RETRIEVER_NAME = \"ValidationInsightsAgent\"\n",
    "EVALUATOR_NAME = \"DataRetrievalAgent\"\n",
    "\n",
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\",\n",
    "    prompt=f\"\"\"\n",
    "Determine which participant takes the next turn in a conversation based on the most recent participant.\n",
    "State only the name of the participant to take the next turn.\n",
    "No participant should take more than one turn in a row.\n",
    "\n",
    "Choose only from these participants:\n",
    "- {RETRIEVER_NAME}\n",
    "- {EVALUATOR_NAME}\n",
    "\n",
    "Always follow these rules when selecting the next participant:\n",
    "- {RETRIEVER_NAME} retrieves the document or relevant data for the query.\n",
    "- After {RETRIEVER_NAME}, it is {EVALUATOR_NAME}'s turn to evaluate the content.\n",
    "- After {EVALUATOR_NAME}, the workflow may terminate if 'approved'.\n",
    "\n",
    "History:\n",
    "{{{{$history}}}}\n",
    "\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Initialize Agents and Chat\n",
    "# Set up the agents and the chat interface:\n",
    "\n",
    "async def initialize_agents():\n",
    "    creds = DefaultAzureCredential()\n",
    "    client = await AzureAIAgent.create_client(credential=creds)\n",
    "\n",
    "    ValidationInsightsAgentID = \"asst_kdFT72VdYH0YpoG3tJ5lmoFy\"\n",
    "    DataRetrievalAgentID = \"asst_Wo0GJ9MpmvkfRPNwllC7bYFS\"\n",
    "\n",
    "    dataretrieval_def = await client.agents.get_agent(agent_id=DataRetrievalAgentID)\n",
    "    validation_def = await client.agents.get_agent(agent_id=ValidationInsightsAgentID)\n",
    "\n",
    "    agent_retriever = AzureAIAgent(client=client, definition=dataretrieval_def)\n",
    "    agent_evaluator = AzureAIAgent(client=client, definition=validation_def)\n",
    "\n",
    "    chat = AgentGroupChat(\n",
    "        agents=[agent_retriever, agent_evaluator],\n",
    "        termination_strategy=ApprovalTerminationStrategy(\n",
    "            maximum_iterations=10,\n",
    "            agents=[agent_evaluator],\n",
    "        ),\n",
    "        selection_strategy=KernelFunctionSelectionStrategy(\n",
    "            function=selection_function,\n",
    "            kernel=_create_kernel_with_chat_completion(),\n",
    "            result_parser=lambda result: str(result.value[0]) if result.value else EVALUATOR_NAME,\n",
    "            agent_variable_name=\"agents\",\n",
    "            history_variable_name=\"history\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Build the Streamlit Interface\n",
    "# Create the Streamlit interface to interact with the agents:\n",
    "\n",
    "async def main():\n",
    "    st.title(\"Multi-Agent Chat Interface\")\n",
    "\n",
    "    if \"chat\" not in st.session_state:\n",
    "        st.session_state.chat = await initialize_agents()\n",
    "        st.session_state.history = []\n",
    "\n",
    "    user_input = st.chat_input(\"Enter your message:\")\n",
    "    if user_input:\n",
    "        st.session_state.history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        await st.session_state.chat.add_chat_message(message=user_input)\n",
    "\n",
    "        async for content in st.session_state.chat.invoke():\n",
    "            agent_name = content.name or \"Unknown\"\n",
    "            agent_role = content.role.name\n",
    "            agent_output = content.content\n",
    "\n",
    "            st.session_state.history.append({\"role\": agent_role, \"name\": agent_name, \"content\": agent_output})\n",
    "\n",
    "            st.chat_message(agent_role).write(f\"**{agent_name}:** {agent_output}\")\n",
    "\n",
    "        if st.session_state.chat.is_complete:\n",
    "            st.write(\"Conversation has been approved and terminated.\")\n",
    "            st.session_state.chat.reset()\n",
    "            st.session_state.history = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Run the Streamlit Application\n",
    "\n",
    "Save your script (e.g., app.py) and run it using Streamlit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run src/chatapp/app.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ai-agent-service-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
